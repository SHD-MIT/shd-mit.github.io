{"0": {
    "doc": "Cache Recitation",
    "title": "Cache Recitation",
    "content": "In the website fingerprinting lab, we learned how to use coarse grained microarchitectural measurements to infer system behavior. Starting in the cache attacks lab, we will be performing a much more fine grained analysis of cache contents to learn exact secrets using techniques like prime+probe and flush+reload. In today’s recitation, we are going to start by demystifying the website fingerprinting attack to better understand why the attack works when memory accesses are removed. Next, we will learn how CPU caches are implemented on Unicorn, the server you will be implementing your attacks on. Finally, we are going to learn how prime+probe works at a high level using a microarchitectural attack simulator. | We will be going over the Bigger Fish paper to learn more about the website fingerprinting attack. | Next, we will be learning about the Unicorn cache organization. | Finally, we will be using the simulator from Modeling Microarchitectural Side Channel Attacks for Fun and Profit. Specifically we will be going over Sections 2.1, 2.2, 2.4, 2.5, and 6.2. | . ",
    "url": "/2026/recitations/cache.html",
    "relUrl": "/recitations/cache.html"
  },"1": {
    "doc": "Cache Attacks",
    "title": "Cache Side Channel Attacks Lab",
    "content": "Due Date: Mar 3, 2026; Last Updated Date: Jan 30, 2026 . ",
    "url": "/2026/labs/cache.html#cache-side-channel-attacks-lab",
    "relUrl": "/labs/cache.html#cache-side-channel-attacks-lab"
  },"2": {
    "doc": "Cache Attacks",
    "title": "Table of Contents",
    "content": ". | Mid-checkpoint Date | Introduction | Part 1: Gathering Information (15%) . | Part 1.1: Determining Machine Architecture | Part 1.2: Timing a Memory Access | . | Part 2: Capture the Flag with Flush+Reload (25%) | Part 3: Capture the Flag with Prime+Probe (30%) . | Before Attacking: Cache Addressing | Using Hugepage | Implementing the Attack: Prime+Probe | . | Part 4: Leaking a Secret Key with Prime + Probe (5%) . | Implementing the Attack | . | Part 5: Dead Drop – An Evil Chat Client (25%) | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . Log in to our lab machine that you are assigned, one of {unicorn,dobby}.csail.mit.edu, via ssh on port 2222 by running ssh username@{unicorn,dobby}.csail.mit.edu -p 2222. You will complete this lab primarily in C. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to Gradescope. We provide a markdown template in the starter code (report.md). Mid-checkpoint Date . This lab is challenging, so we strongly encourage you to start early. We highly recommend completing Parts 1–2 by Feb 23. ",
    "url": "/2026/labs/cache.html#table-of-contents",
    "relUrl": "/labs/cache.html#table-of-contents"
  },"3": {
    "doc": "Cache Attacks",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Reverse engineer the cache configuration on our lab machine. | Solve three CTF (capture-the-flag) puzzles using cache-based side channels. | Build a covert channel to send and receive arbitrary messages using cache-based side channels. | . In this lab, you will learn how to interact and manipulate fine-grained cache states in real hardware. Real, commercial hardware is a black box to us. To be able to mount a cache attack, we need to leverage our computer architecture knowledge to infer how a cache behaves for a sequence of instructions. Making the attacker’s life more difficult, real-world caches are far more complex than the toy example caches that we learned in the classroom. After completing this lab, you will hopefully get a glimpse of the complexity of these hardware features. Getting Prepared Before You Start . You will program in C throughout this lab. C is a low-level language that gives you more control over the hardware compared to high-level languages. Programs written in C can be directly compiled into machine code, and directly executed on the hardware without other abstraction layers. When working on microarchitectural attacks, having a high degree of control over the exact instructions being executed is essential. If you are not familiar with C, we highly recommend participating in the “CTF of C Programming” recitation. You can also get yourself familiar with C syntax by looking at the recitation materials (link will be available soon). You will need to think about how the cache works while working on this lab. Our lab machine is huge (with 96 cores) and has a relatively complex cache hierarchy. We highly recommend you also attend the “Cache Attack” recitation, where we give an overview of the processor architecture of our lab machines. Knowing the overall organization may help you think and debug. You can also look up relevant information following the recitation materials (link will be available soon). Setting Up Your Environment . You will run your attacks using two CPU cores on the lab machine. Every student will get a different pair of CPUs such that your programs do not interfere with each other. Each pair of CPUs provided is a pair of SMT (aka, Simultaneous MultiThreading) cores. These two “logical cores” map to the same physical core and share multiple hardware resources associated with that core, such as private L1 and L2 caches. Configuration . After logging into the lab machine and cloning your repo, you must modify the SENDER_CPU and RECEIVER_CPU variables in cpu.mk to your assigned CPUs. You have to do so before running code for any portion of this lab! Only after you have configured these variables, you can remove the $error$ line from cpu.mk. Double check that you have set these values correctly. Do not use VS Code’s remote ssh plugin to connect to the server! This plugin can introduce a large degree of noise, and is likely to cause your attack to fail. ",
    "url": "/2026/labs/cache.html#introduction",
    "relUrl": "/labs/cache.html#introduction"
  },"4": {
    "doc": "Cache Attacks",
    "title": "Part 1: Gathering Information (15%)",
    "content": "Before we begin, think – what is the first step when planning to attack a system? We first need to gather information about the system’s attributes. This rule applies to attacking software, hardware, and even in real-life on non-computing systems! For example, if you wanted to plan a bank robbery, you would first need to figure out the floorplan of the bank, the locations of safes and security cameras, etc. In this part of the lab, you will see a few practical approaches people use to gain detailed microarchitecture information of commodity hardware. You will further get familiar with some common techniques and instructions that we can use to measure execution latencies on processors, which will help you mount your attacks later on. Part 1.1: Determining Machine Architecture . The simplest way to gather hardware information is to use existing public system interfaces and documentation. Here is a list of commands that can be used to determine machine architecture information on Linux. | lscpu: Provides information on the type of processor and some summary information about the architecture in the machine. | less /proc/cpuinfo: Provides detailed information about each logical processor in the machine. (Type q to exit.) | getconf -a | grep CACHE: Displays the system configuration related to the cache. This will provide detailed information about how the cache is structured. The numbers that are reported using this command use Bytes (B) as the unit. | . In addition, WikiChip is a good source of information, as it provides information specific to each processor and architecture. You can find a detailed architecture description of our lab machines (Intel Cascade Lake processors) here, which additionally provides the raw latency value for accessing different levels of caches. 1-1 Discussion Question . Fill in the blanks in the following table using the information you gathered about the cache configuration of the lab machine. You should be able to directly obtain the information for the first 3 blank columns using commands above. You will need to derive the number of sets using what you have learned about set-associative caches in 6.1910[6.004]. Raw latency can be obtained from the WikiChip document. The line size of L1 data cache has been filled in for you. | Cache | Cache Line Size | Total Size | Number of Ways (Associativity) | Number of Sets | Raw Latency | . | L1-Data | 64 Bytes |   |   |   |   | . | L2 |   |   |   |   |   | . | L3 |   |   |   |   |   | . Part 1.2: Timing a Memory Access . The information you can get from public sources can be limited, as hardware companies would not like to disclose all of their proprietary design details to general users and potential competitors. An alternative way to gather information is to reverse engineer the processor by running some very carefully designed instruction sequences on the processor and observing their behaviors. In this part, you will try to reverse engineer the latencies for accessing the cache hierarchy. Specifically, we would like to know how long it takes to access cache lines that are located in the (a) L1 data cache, (b) L2 cache, (c) L3 cache, and (d) the DRAM. The Reverse Engineering Plan . To measure the L1 latency, we can perform a load operation on a target address to bring the corresponding cache line into the L1 data cache. Then, we measure the access latency by counting the cycles it takes to re-access the same target address using measure_one_block_access_time. We have provided this code for you, and you can compile the starter code using the command make, and then run it with make run. Your task is to complete the main function in main.c to populate the three arrays dram_latency, l2_latency, and l3_latency. We suggest you start with measuring DRAM latency, since measuring DRAM latencies is the easiest. You can leverage the instruction clflush to place the target address to DRAM. Measuring L2 and L3 latencies is slightly more complex. To measure the L2 latency, we need to place the target address in the L2 cache. However, simply accessing the target address will make the address reside in the L1 cache. Therefore, need to access other addresses to evict the target address from the L1 cache. Thus, you first need to access the line to bring it into L1, then create cache conflicts to evict it into L2. When it comes to measuring the L3 latency, you need to similarly create cache conflicts to evict the cache line from both the L1 cache and the L2 cache. Helper Functions . Before you start, make sure you familiarize yourself with C syntax and several useful x86 instructions. Read the code in utility.h and understand the following functions. | rdtscp and rdtscp64: Read the current timestamp counter of the processor and return a 32-bit or 64-bit integer. | lfence: Perform a serializing operation. Ask the processor to first complete the memory loads before the lfence instruction, then start issuing memory loads after the lfence instruction. Other variants of fences exist, such as sfence and mfence. | measure_one_block_access_time: Measure the latency of performing one memory access to a given address. | clflush: Flush a given address from the cache, evict the line from the whole cache hierarchy so that later accesses to the address will load from DRAM. | print_results_plaintext and print_results_for_visualization: Print the collected latency data in different formats. The default Makefile compiles two binaries: main uses print_results_plaintext, while main-visual uses print_results_for_visualization. | . Pointer Arithmetic . Pointer arithemetic operations, such as new_ptr = old_ptr + 1, means moving the pointer forward by one element. For different types of pointers whose element size is different, the actual bytes being moved can be very different. For example, given a uint8_t pointer, since each element is 1 byte, +1 means moving the pointer foward by 1 byte. However, +1 of a uint64_t pointer means moving the pointer forward by 8 bytes. We highly suggest to use uint8_t pointers to make your address calculation easier and avoid introducing addressing mistakes. Further details about common C/C++ constructs can be found in the C Programming Recitation. Visualization Support . Microarchitectural side channels are notoriously noisy, and it is common to get inconsistent latency results from run to run. To combat noise, the most commonly used methodology is to repeat the experiments and plot the distribution of the observed latencies. We have provided two Python scripts to help you launch multiple measurements and visualize these measurements. To install python packages used in these two scripts, please run: . python3 -m pip install matplotlib tqdm . | run.py: A python script that will generate 100 runs from the main-visual binary. It will create a folder (if one doesn’t already exist) called data, and it will store all the generated samples there in json format. The script will overwrite the folder if it already exists. | graph.py: A python script that will plot the histogram of the samples collected from run.py. It will read the JSON files from the folder data and generate a pdf file of the histogram in a folder called graph. | . Expected Outcome . When grading we will not check the exact latency numbers generated by your code, since different implementations can yield different latency numbers. For example, it is unlikely that your L1 latency will match the L1 raw latency number from WikiChip. This is because our measurement involves extra latency introduced by the lfence instructions. Besides, other factors such as the frequency of the core and prefetch configurations of the cache can also affect the latency. If you want to check whether you are on the right track, you should look for the following patterns in your visualized plot. We also include an example plot below. | There are distinct peaks for DRAM, L3, and L2 latency. | The L1 and L2 latency do not need to be distinguishable. | . A reference memory latency distribution plot . 1-2 Exercise . Fill in the code in main.c to populate the arrays dram_latency, l2_latency, and l3_latency. DO NOT take latency measurements while also printing. Instead, measure then print. When debugging your code, it is tempting to write code like this, which we call “measuring while printing”. for i in l1_cache: # Observe some aspect of the cache state val = time_access(cache line i) # In the same measurement loop, print the observed value out! printf(\"The cache took %d cycles\", val) # Now we go to the next interation and measure again . Do not do this! We are no longer in the regular world, we are in the microarchitectural world, where each assembly instruction counts! . What do we mean by this? Under the hood, a “simple” call to printf involves executing a huge number of instructions. When you call printf, you are going to go to the libc library, doing some string processing, and eventually making a system call into the kernel (so, the entire CPU performs a context switch, and does who knows what else). Think about how many cache lines this call to printf will need to read/write – printing anything is a destructive action to the state of the cache. Instead, you should measure then print. We suggest structuring your code like this: . uint64_t measurements[NUM_THINGS_TO_MEASURE] # Measure for i in l1_cache: measurements[i] = time_access(cache line i) # Then, print :) print(measurements) . Tips for Reliably Triggering Cache Evictions . The following tips may help you if you get stuck when you could not observe differences between the L2 and L3 cache latency. A common pitfall is not properly evicting the target address from the L1/L2 cache due to various reasons. | Cache Line Size != Integer Size: To begin with, you should be careful with the the mismatch of access granularities. The smallest operational unit in cache is the cache line, which is larger than the size of an integer. Accessing two integers that fall into the same line (more precisely, that fall within the same cache line size aligned region of memory) will result in a cache hit, and won’t cause an eviction. So make sure to use eviction addresses that do not map to the same cache line when attempting to evict. | Advanced Cache Replacement Policy: The cache replacement policy in modern processors is more advanced than the simple policies that we learned in class, and is often not completely known to us. It may intelligently decide to keep a target address in the cache, rather than evicting it. To combat the advanced replacement policy, we suggest accessing the eviction buffer multiple times. | Virtual to physical address translation: Intuitively, we would imagine that given a cache, if we have a buffer whose size matches the cache size, then accessing each element in the buffer allows us to fully occupy every slot in the cache. However, this may not always be the case, due to virtual to physical address translation. Note that on our machine, the cache mapping is a function of physical address, while the software uses virtual address. Let’s consider a toy example where a 8KB directly-mapped cache which can hold two 4K pages. If we have a two-page-size buffer, after virtual address translation, we can end up with three posibilities: 1) the buffer covers the whole cache; 2) both pages map to the top half of the cache; and 3) both pages map to the bottom half of the cache. In this case, how can we reliably evict data from a certain cache level without the control of the address translation procedure? The common trick is to just use a buffer that is bigger than the cache itself – between 1.5x or even 4x of the cache size. Even though the eviction might still not be guaranteed, its likelihood is high enough. | . 1-3 Discussion Question . After completing your code, generate the histogram pdf file and include it in the lab report. 1-4 Discussion Question . Based on the generated histogram, report two thresholds, one to distinguish between L2 and L3 latency and the other to distinguish between L3 and DRAM latency. Submission and Grading . You will need to submit the code Part1-Timing/main.c to your assigned GitHub repository. Your code should be able to reproduce the histogram you submitted. You can determine whether your implementation is correct by check the description in expected outcome. Due to noise, we will run your code multiple times (5 times) and grade based on the best results. You should feel comfortable to submit your code as long as it can generate the expected results most of the time. ",
    "url": "/2026/labs/cache.html#part-1-gathering-information-15",
    "relUrl": "/labs/cache.html#part-1-gathering-information-15"
  },"5": {
    "doc": "Cache Attacks",
    "title": "Part 2: Capture the Flag with Flush+Reload (25%)",
    "content": "From now on, we are entering attack time. In this part of the lab, you will be attempting to extract secrets from a victim program. You will get a taste of solving a Capture-the-Flag (CTF) puzzle. The future labs will follow a similar pattern. Get to Know the Victim . We provide you with a victim program in Part2-FlushReload/victim, whose pseudocode is listed below. The victim program uses mmap to map a file into its own virtual address space to create a buffer. It then generates a random integer as the flag and uses the flag to index into the buffer. Your task is to learn the flag value by monitoring the victim’s memory accesses using a Flush+Reload attack. // Allocate a large memory buffer char *buf = get_buffer(); // Set the flag to random integer in the range [0, 1024) int flag = random(0, 1024); printf(flag); // Main loop while (true) { value = load(buf + flag * 128); } . The Attack Setup and Your Plan . We have set up the attack framework that enables your attacker program to share a memory region with the victim. It uses a technique called memory-mapped file, where two virtual addresses (one from your program’s address space and the other from the victim’s address space) are mapped to a same physical address, which contains a copy of a file on the hard drive. You can use the figure below to understand what is happening under the hood. The buf in the victim program and the buf in the attacker program point to the same physical address . Your attack should implement standard Flush+Reload. We are providing you with the attack skeleton and several practical tips. | Flush: Flush a cache line that might be accessed by the victim to DRAM using clflush. Be careful with the aforementioned cache line granularity issue. Note that cache size != integer size. | Wait: Wait a few hundred cycles for the victim to perform a flag-dependent memory load operations. Don’t use the system-provided sleep function to do this – similar to printf, this function will trigger a system call, potentially destroying cache states. | Reload: Re-access the cache line in the Flush step and measure the access latency to each of them. | Repeat these steps for all cache lines Use the threshold derived from Part 1 to decode the flag value. | . 2-1 Exercise . Complete the code in Part2-FlushReload/attacker.c to successfully extract the secret values from Part2-FlushReload/victim. To test your attack, you should first compile your code using make and generate a file for the shared buffer using python3 gen_file.py. Then use tmux, screen, or simply two SSH connections, and run make run_victim in one terminal and make run_attacker in another terminal. Make sure you are NOT executing ./victim or ./attacker directly because they will not launch the binary on your assigned cores. If you have problems running the victim binary, you may need to run chmod +x victim. Hardware Prefetchers . Modern processors can predict future memory accesses and prefetch data into the cache before it is used. Hardware prefetching is an effective performance optimization technique that is widely deployed in real-world processors. This feature can confuse your attack code. For example, regardless of what the flag value is, some Flush+Reload attack implementation may consistently observe a cache miss for the first reload operation, and cache hits for the rest of the reload operations, because the first load miss triggers hardware prefetching for the later addresses. Usually, the hardware prefetcher makes address prediction based on simple patterns, such as a linear, fixed-stride access pattern within a page. Therefore, you can bypass the prefetching effects by introducing randomness to your address access pattern. The prefethers are enabled on the lab machines. Make sure you have avoided aforementioned simple access patterns in your code. Tip for Reliably Flush+Reload . We suggest perform flush and reload a single line at a time, rather than flushing all the lines and reloading all the lines. 2-2 Discussion Question . In the victim’s pseudocode above, the victim attempts to load the data indexed by flag into the value variable. How can you change the victim’s code to load the desired data without leaking the flag to the attacker? . Submission and Grading . You will need to submit the code Part2-FlushReload/attack.c to your assigned GitHub repository. Your code should be able to reliably capture the flag. Due to system noise, we will grade this part by executing your code multiple times. Full credit will be awarded if your code works at least 4 out of 5 runs. ",
    "url": "/2026/labs/cache.html#part-2-capture-the-flag-with-flushreload-25",
    "relUrl": "/labs/cache.html#part-2-capture-the-flag-with-flushreload-25"
  },"6": {
    "doc": "Cache Attacks",
    "title": "Part 3: Capture the Flag with Prime+Probe (30%)",
    "content": "We will now solve a more challenging CTF puzzle, leaking the flag using a Prime+Probe attack. In this setup, the attacker and the victim no longer share memory, and thus Flush+Reload will not work. Instead, to make the attack work, you need to carefully manipulate cache states and trigger cache set-conflicts. Get to Know the Victim . We have created several victim binaries, victim-N, whose pseudocode is listed below. Each victim program generates a random number as the flag. Then it finds a collection of addresses that all map to the same L2 cache set whose set index matches this flag value. The value N denotes the number of cache lines being accessed by the victim, reflecting the strength of the side-channel signal. Intuitively, using a smaller N means the victim accesses fewer ways in a given cache set, and the generated side-channel signal is weaker, making attacks more difficult. We have provided the binary for victim-[16,4], where victim-16 accesses the full cache set and is easier to attack. // Allocate a large memory buffer char *buf = get_buffer(); // Set flag to random integer in the // range [0, NUM_L2_CACHE_SETS) int flag = random(0, NUM_L2_CACHE_SETS); printf(flag); // Find N addresses in buf that all map to the cache set // with an index of flag to create a partial eviction set char *eviction_set[N]; get_partial_eviction_set(eviction_set, flag); // Main loop while (true) { for (int i = 0; i &lt; N; i++) { // Access the eviction address (*(eviction_set[i]))++; } } . Before Attacking: Cache Addressing . Given the victim’s behavior described above, you will build a Prime+Probe covert channel targeting the L2 cache. Similar to previous parts, the addresses you are dealing with in your C code are virtual addresses while physical addresses (which you will not have access to within your code) are used when indexing into caches. This fact can be more problematic in this part because you might need to do more careful calculation on the addresses. For a review of virtual memory and address translation, please refer 6.191’s (6.004’s) lectures on Virtual Memory 1 and Virtual Memory 2. It is very tempting to “fudge” the numbers in this lab (e.g., hypertuning various parameters to make incremental changes to your attack’s performance). While this approach may work, we really don’t recommend this approach. Instead, take the time to sit down and calculate all the cache parameters before you move forward may save you more time. Think about the following questions: How many bits are part of the tag in a virtual address? The set index? The offset (within a cache line)? How is this level of the cache indexed (virtually or physically indexed?) Which bits are shared between virtual and physical addresses for both kinds of pages (regular and huge)? You should know the answers to all of these before you start coding! . Addresses look like this to the cache: . And look like this to the paging hierarchy: . You should know what each of these fields does, and how large they are at each level of the cache on the lab machine. 3-1 Discussion Question . Given a 64-bit virtual address, fill in the table below. In the last row, when we say an address bit is fully under the attacker’s control, we mean the address bit is not changed during virtual to physical address translation. |   | Using 4KB page | Using 2MB page | . | Which bits are page offset? |   |   | . | Which bits are used as page number? |   |   | . | Which bits are L2 set index? |   |   | . | Which bits of the L2 set index are fully under your control? |   |   | . Using Hugepage . The default page size used by most operating systems is 4K bytes. Linux supports Huge pages, allowing programs to allocate 2 MB of contiguous physical memory, ensuring 221 bytes of consecutive physical addresses. You can use the mmap system call as follows to get a buffer using 2MB pages. You can use the command man mmap to understand the semantics for each argument used by this function. void *buf= mmap(NULL, BUFF_SIZE, PROT_READ | PROT_WRITE, MAP_POPULATE | MAP_ANONYMOUS | MAP_PRIVATE | MAP_HUGETLB, -1, 0); if (buf == (void*) - 1) { perror(\"mmap() error\\n\"); exit(EXIT_FAILURE); } *((char *)buf) = 1; // dummy write to trigger page allocation . Besides, you can see if your huge page is being allocated or not by watching the status of /proc/meminfo. Namely, if you run cat /proc/meminfo | grep HugePages_, you should see the number of HugePages_Free decrease by 1 when your code is using one. Implementing the Attack: Prime+Probe . We outline the attack procedure below and provide a few tips. The most important rule is, do not try to implement everything then test. Modern processors often contain optimizations that make them behave differently from the simplified architectures taught in class. This lab requires experimentation to find working approaches and values. You should not expect your solution to work on the first attempt, so be sure to incrementally build up your solution and verify that each step is working before proceeding. | Eviction addresses collection: You need to find a group of eviction addresses for each cache set, so that when these eviction addresses are accessed, they can fully occupy a given cache set. This step requires a clear understanding of the cache addressing scheme. We highly suggest you calculate twice, code once. Trust us, sitting down to think through cache addressing before coding will save you time. | Prime: For each cache set, access its corresponding eviction addresses to place these addresses in the cache and fully occupy the cache set. Again, be careful with the mismatch of the size of an integer and a cache line. Repeatedly accessing the same cache line will only bring one line into the cache, far from being able to monitor the whole cache set. | Wait: Similar to the Flush+Reload attack, wait for a few hundred cycles. Do not use system call functions, such as sleep. | Probe: For each cache set, re-access the eviction addresses for each cache set and measure their access latency. You can use simple statistic analysis (e.g., median, average, maximum, or median/average/max after removing outliers) to decode the flag. | . 3-2 Exercise . Complete the code in attacker.c to successfully extract the secret values from victim-[16,4]. Compile your code using make. Then use tmux, screen, or simply two SSH connections, and run make run_victim-N in one terminal and make run_attacker in another terminal. If you have problems running the victim binaries, you may need to run chmod +x victim-N. Practical Coding Tips . If the receiver needs to measure the latency of multiple memory accesses, you should pay attention to the following features that can introduce substantial noise to your communication channel. | Randomizing the access pattern during probe: Similar to the Flush+Reload attack, accessing addresses with a fixed-stride pattern can trigger hardware prefetching and introduce confusing measurement results. The problem is that you do not know when you observe a cache hit, the line was always located inside the cache or it was brought into the cache by the prefetcher. Please avoid simple access patterns in your code. | Probe in the reverse direction: While least recently used (LRU) is the most common example of a cache replacement policy, practical processor implementations often use much more complex policies. You may need to experiment a bit to roughly figure out how eviction and measurement works on your processor. With Prime+Probe attacks, it is common to encounter cache-thrashing or self-conflicts, a situation in which the attacker primes the cache set and evicts their own data with subsequent accesses while probing. For example, consider a 4-way cache using LRU, if we access four pieces of data in the order of A, B, C, D. Here, A will be the oldest data and D will be the youngest. Assume the system has noise where a random application touches a line called X in this set, evicting A out of cache. Now we have B, C, D, X, where B is the oldest and X is the youngest. Think about what if we perform the probe operation and re-accessing A-D in the same order as we prime them, what will happen? We will trigger the cache-thrashing effects where accessing A will evict B, and the access to B will evict C. As this pattern continues, we end up with 4 cache misses. As you see, a small amount of noise makes us lose the capability of monitoring the given cache set. Prior work has studied better access patterns to bypassing the cache-thrashing effects. The idea is to access the eviction addresses in one direction in Prime and in the reverse direction in Probe. Following the example above, we will need to access the four addresses in the order of D, C, B, A during probe. More studies on cache attack access ordering have been discussed in Tromer et al. | Keep data on the stack: This is more a rule of thumb than a hard “law” of microarchitectural attacks. One of our prior TAs, Joseph Ravi, found that keeping as much of your measured data (i.e., the latencies of memory accesses) on the stack (instead of the heap) as you can reduces noise. Note that, writing your measured data to an array, this operation itself, can introduce noise to our attack. Since stack anyway is frequently accessed, putting the measured data array onto stack may introduce less interference. | . Submission and Grading . You need to submit the code Part3-PrimeProbe/attack.c to your assigned GitHub repository. We give credits if your code can reliably capture the flag in the following victims in 2 minutes, and when we say reliably, we mean your attack works at least 4 out of 5 runs. Your code needs to first work reliably targeting victim-16 to get 25% of the credits and then victim-4 to get the remaining 75%. As always, do not forget to include answers to the discussion questions in your lab report and submit the report to Gradescope. ",
    "url": "/2026/labs/cache.html#part-3-capture-the-flag-with-primeprobe-30",
    "relUrl": "/labs/cache.html#part-3-capture-the-flag-with-primeprobe-30"
  },"7": {
    "doc": "Cache Attacks",
    "title": "Part 4: Leaking a Secret Key with Prime + Probe (5%)",
    "content": "We have a new victim function in this part. In building an encryption function, we accidentally left a side channel open by making the function behave differently depending on the value of the secret key. Like in Part 3, the attacker and victim will not share memory, and we will leak the secret key using Prime + Probe. Get to Know the Victim . Our new victim randomly generates a two bit secret key, then iterates through the bits. If the bit is 1, the victim calls unique_function. Otherwise, unique_function will not be called. Then between all bits, the victim calls common_function. Unique_function accesses a collection of addresses that map to one hardcoded L2 cache set, and common_function accesses a collection of addresses that map to a different hardcoded L2 cache set. Your job is to leak the secret key by extending the Prime and Probe attack. void unique_function(char *eviction_set[16], char *buf) { // create the eviction set that maps to hardcoded index X get_partial_eviction_set(eviction_set, X); // access the secret addresses many times for (int counter = 0; counter &lt; 90000000; counter ++) { for (int i = 0; i &lt; 16; i++) { (*(eviction_set[i]))++; } } } void common_function(char *eviction_set[16], char *buf) { // create the eviction set that maps to hardcoded index Y get_partial_eviction_set(eviction_set, Y); // access the addresses many times for (int counter = 0; counter &lt; 90000000; counter ++) { for (int i = 0; i &lt; 16; i++) { (*(eviction_set[i]))++; } } } int main() { // Allocate a large memory buffer char *buf = get_buffer(); int flag = random(0, 3); printf(flag); char *eviction_set[16]; // go through the secret key bit by bit for (int i = 0; i &lt; 2; i++) { if (secret_key &amp; (1 &lt;&lt; i)) { unique_function(eviction_set, buf); } common_function(eviction_set, buf); } } . Implementing the Attack . Use the previous tips and what you’ve learned from Part 3 to discover the two cache sets accessed by unique_function and common_function. Then, use what you’ve now discovered about the two functions to build up an attack to leak each bit individually. To make this easier to implement, we’ve added an option to the victim to set the secret key value from the command line, or leave it as a random number between 0 and 3 inclusive. When we grade, we will run your solution with the random version of the victim. To run the random version of the victim use make run_victim, and to set the secret key manually use SECRET_KEY=[your number] make run_victim. Remember, the behavior of both unique_function and common_function are static, there is no randomization here. 4-1 Exercise . Complete the code in attacker.c to successfully extract the secret values from victim. Compile your code using make. Then use tmux, screen, or simply two SSH connections, and run make run_victim in one terminal and make run_attacker in another terminal. If you have problems running the victim binaries, you may need to run chmod +x victim. Building Up The Attack . Use Part 3 to first find the two data cache sets that unique_function and common_function access (each function only accesses one). The two functions access the same sets every time. It may be easier to find these one at a time. There is one value of the secret key that makes this more straightforward. Submission and Grading . You need to submit the code Part4-SecretKey/attacker.c to your assigned GitHub repository. We will give full credit if your attacker can print the random secret key in under 3 minutes. No partial credit will be given for this portion of the lab. ",
    "url": "/2026/labs/cache.html#part-4-leaking-a-secret-key-with-prime--probe-5",
    "relUrl": "/labs/cache.html#part-4-leaking-a-secret-key-with-prime--probe-5"
  },"8": {
    "doc": "Cache Attacks",
    "title": "Part 5: Dead Drop – An Evil Chat Client (25%)",
    "content": "If you find leaking an integer is not exciting enough, you can level it up to build a covert channel to send and receive arbitrary messages, like an evil chat client that can stealthily communicate without being monitored by privileged software, such as the OS. In this part, you can decide to build a chat client using either Prime+Probe or even some other fancy side channels. There are only very few requirements. | The sender and receiver must be different processes. | The sender and receiver may only use syscalls and the functions accessible from the provided util.h except for system() and clflush(). There is no way to set up a shared writable address space between the sender and receiver, nor is there a way to call any obviously-useful-for-chat functions such as Unix sockets. | If you would like to use some convenience code that stays within the spirit of the lab, please contact the course staff. Obviously, you may not use pre-packaged code from online for building covert channels (e.g., mastik). | . Expected Behaviour . The Dead Drop client should behave in the following way. Using tmux, screen, or simply two SSH connections, we can have two different terminals running on the same machine and run the following commands: . Terminal B: $ make run_receiver // you start the receiver process in a terminal Terminal B: Please press enter. // the receiver prompts you to press enter to start listening for messages Terminal A: $ make run_sender // you start the sender in another terminal Terminal A: Please type a message. Terminal B: $ // you press Enter in the receiver's terminal Terminal B: Receiver now listening. Terminal A: $ Hello, World! // you type a message and hit enter in the sender's terminal Terminal B: Hello, World! // receiver should generate the same message as you entered on the sender's side . Note that you should support messages containing arbitrary number of characters. For example, the message “Hello, World!” above contains 13 characters and is typed by user together. Then all 13 characters appear on the receiver side. To achieve this, your sender needs to signal the receiver that “the next character is coming” in some way. Partial credits will be awarded for solutions which only support a fixed number of characters in a message. Submission and Grading . You need to submit your code to your assigned GitHub repository. You code needs to first successfully send and receive the “Hello, World!” message to get 80% of the credits and then messages with arbitrary length and contents to get the remaining 20%. We do not accept code that directly prints the “Hello, World!” message in the receiver. Acknowledgments . Contributors: Miles Dai, Weon Taek Na, Joseph Ravichandran, Mengjia Yan, Peter Deutsch, Shixin Song, Kelly Xu. The original Dead Drop lab (Part 5 of this lab) was developed by Christopher Fletcher for CS 598CLF at UIUC. The starting code and lab handout are both heavily adapted from his work. ",
    "url": "/2026/labs/cache.html#part-5-dead-drop--an-evil-chat-client-25",
    "relUrl": "/labs/cache.html#part-5-dead-drop--an-evil-chat-client-25"
  },"9": {
    "doc": "Cache Attacks",
    "title": "Cache Attacks",
    "content": " ",
    "url": "/2026/labs/cache.html",
    "relUrl": "/labs/cache.html"
  },"10": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": "All content on this website, including the calendar, is subject to change. | Monday | Tuesday | Wednesday | Thursday | Friday | . | Feb 2 Lecture Overview note_stack | Feb 3 | Feb 4 Lecture Side Channel Overview note_stack | Feb 5 | Feb 6 | . | Feb 9 Recitation CTF of C Programming note_stack | Feb 10 | Feb 11 Lecture Deep Dive of Cache Side Channels note_stack | Feb 12 Lab 0 + Lab 1 Due | Feb 13 | . | Feb 16 No Class President's Day | Feb 17 Recitation Cache Attacks note_stack | Feb 18 Lecture Transient Execution Side Channels note_stack | Feb 19 | Feb 20 | . | Feb 23 Lecture Software-Hardware Contract note_stack | Feb 24 | Feb 25 Lecture Side-Channel Mitigations note_stack | Feb 26 | Feb 27 | . | Mar 2 Lecture Physical Attacks note_stack | Mar 3 Lab 2 Due | Mar 4 Recitation CTF of Physical Attacks | Mar 5 | Mar 6 | . | Mar 9 Lecture Rowhammer Attacks note_stack | Mar 10 | Mar 11 Lecture Rowhammer Mitigation + Reliability Solutions note_stack | Mar 12 Lab 3 Due | Mar 13 | . | Mar 16 Lecture Hardware Security Module (HSM) note_stack | Mar 17 | Mar 18 Lecture Hardware Support for Software Security note_stack | Mar 19 | Mar 20 | . | Mar 23 No Class Spring Break | Mar 24 No Class Spring Break | Mar 25 No Class Spring Break | Mar 26 No Class Spring Break | Mar 27 No Class Spring Break | . | Mar 30 Lecture Fuzzing and Bug Finding note_stack | Mar 31 | Apr 1 Recitation RISC-V System Programming | Apr 2 Lab 4 Due | Apr 3 | . | Apr 6 Lecture Formal Verification for Hardware Security note_stack | Apr 7 | Apr 8 Recitation Formal Verification Toolchain | Apr 9 Lab 5 Due | Apr 10 | . | Apr 13 Lecture Trusted Execution Environment (TEE) note_stack | Apr 14 | Apr 15 Discussion Modern Side-Channel Attacks | Apr 16 | Apr 17 | . | Apr 20 No Class Patriot's Day | Apr 21 No Class Drop Date | Apr 22 Discussion Physical Attacks | Apr 23 Lab 6 Due | Apr 24 | . | Apr 27 Discussion Hardware Support for Software Safety | Apr 28 | Apr 29 Discussion Fuzzing and Formal Verification | Apr 30 Lab 7 Due | May 1 | . | May 4 Discussion Extra Slot | May 5 | May 6 Exam Final Exam | May 7 | May 8 | . ",
    "url": "/2026/calendar.html",
    "relUrl": "/calendar.html"
  },"11": {
    "doc": "C Crash Course",
    "title": "C Crash Course Lab",
    "content": "Due Date: Feb 12, 2026; Last Updated Date: Jan 25, 2026 . This lab is designed to be an independent assessment of your low-level programming fundamentals. As such, course staff will not provide any help during office hours for this lab. Completing this lab independently is a prerequisite to remain in this course and helps us manage limited enrollment capacity. ",
    "url": "/2026/labs/ccc.html#c-crash-course-lab",
    "relUrl": "/labs/ccc.html#c-crash-course-lab"
  },"12": {
    "doc": "C Crash Course",
    "title": "Table of Contents",
    "content": ". | Introduction . | Setup | . | Common types of Bugs . | Memory Safety Bugs . | Spatial Memory Safety Bugs | Temporal Memory Safety Bugs | Memory Leaks | Uninitialized Types | Erroneous Return Values | Integer Overflows | Undefined Behavior | Race Conditions | . | . | Debugging Tips: . | Print Debugging | Sanitizer Debugging | Using an Actual Debugger | . | The Lab . | The Basics | Example Bug | Some hints | Additional Tester Features | Grading | Submission | . | Acknowledgments | . ",
    "url": "/2026/labs/ccc.html#table-of-contents",
    "relUrl": "/labs/ccc.html#table-of-contents"
  },"13": {
    "doc": "C Crash Course",
    "title": "Lab Details",
    "content": "Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . This lab is done on the Unicorn server - you will receive an email with login instructions. This can also be solved locally through the provided Dockerfile. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to Gradescope. ",
    "url": "/2026/labs/ccc.html#lab-details",
    "relUrl": "/labs/ccc.html#lab-details"
  },"14": {
    "doc": "C Crash Course",
    "title": "Introduction",
    "content": "Most of the labs in this course involve writing programs in the C programming language. This includes plenty of debugging too! Every year, we encounter many students who come to office hours due to a lack of understanding of basic C, so we decided to make this lab as a crash course. In this lab, you will help fix the bugs of a basic note taking library. We will run it through a series of test cases to check for bugs and functionality problems. While we don’t expect the lab to be trivial for most people, if you find yourself struggling significantly to get through this lab, you should consider if this course is fit for you. And please do not use LLMs to analyze shd-lib.c – this lab is designed to be assess your preparedness for later labs. LLMs are perfectly fine though if you are rusty on C and need a crash course. Setup . Please do the lab on the provided machines. This is very important, because I have set up the tests to layout the process heap in a specific way to maximize the chances of catching specific bugs (and we will grade in this same environment)! . You can now modify shd-lib.c (and only this, we will ignore all other diffs during submission) and then run the tester binary. Note that your modifications only rebuild the library, which the tester uses. We do not provide the source for the tester or any debugging symbols on purpose - feel free to reverse engineer it, but it’s pretty trivial to deduce the test cases from the library anyways. If you can reconstruct the tester binary to a reasonable degree and demonstrate this through a report with readable pseudo-C, we’ll give you full credit for this lab automatically. Use make libshd-lib.so to rebuild the library, and then make run to run the tester (or ./tester). You can also run it with SANITIZED=1 make libshd-lib.so to build with ASAN and UBSAN (we will elaborate on this later on). You will need to use make sanitized-run for this version (or ./sanitized_tester), which specifies the correct libraries to use for sanitizers. Finally, make check is what we will use for grading. There are many bugs that trigger silently (ie. no visible corruption), and we will use Valgrind to catch a subset of those. Feel free to write your own tester binary as well and link it to libshd-lib.so. You can add a Makefile rule and call make &lt;rule_name&gt;. This can be good practice for writing more C! For example: . LDFLAGS = -L. -lshd-lib -Wl,-rpath=. tester: custom.c libshd-lib.so $(CC) $(CFLAGS) custom.c -o tester $(LDFLAGS) . LLMs are really good for writing Makefiles too if you want to do some other setup. Lastly, some tips for using Makefiles. The filenames appearing after a rule name are the dependencies - make re-runs a rule if the file which correlates to a rule name has an earlier modification timestamp than its dependent filenames. make clean has been set up to clean the local build directories, make -B will force a re-make of everything regardless of modification timestamps, and make -j&lt;num&gt; will parallelize the build process with num cores (you shouldn’t need this at all for this lab). ",
    "url": "/2026/labs/ccc.html#introduction",
    "relUrl": "/labs/ccc.html#introduction"
  },"15": {
    "doc": "C Crash Course",
    "title": "Common types of Bugs",
    "content": "C is very prone to bugs. Despite the many existing solutions, C is still the lingua franca of low-level systems programming, and gives you the most precise control over generated machine code. In this lab, you should encounter most of these bugs unless otherwise stated: . Memory Safety Bugs . Spatial Memory Safety Bugs . Unlike most modern languages, C has no runtime bounds checking for array/buffer access. Combined with unchecked pointer arithmetic, one can really reference any offset from an object and potentially achieve arbitrary read or write. These issues are known as spatial memory violations. They can corrupt adjacent objects, stack return addresses, and other elements necessary for correct program execution. Some common bugs that fall under this category are known as OOB (out-of-bound) accesses and buffer overflows. While many of these seem trivial to fix, beware of string related operations. C represents strings as a null-terminated char array, and that final null byte can lead to a lot of off-by-one errors. Temporal Memory Safety Bugs . Unlike garbage-collected languages, memory is manually managed in C. Unlike smarter manual memory management languages like Rust or Ada (and really modern C++ too if you know how to use it correctly), C provides no compile time guarantees to act as guard rails for memory management. Temporal violations often involve de-referencing freed memory, which are known as use-after-frees. This can then lead to corruption within the allocator state or objects that are re-allocated in the same region (this is known as a type confusion bug). Double frees, in which memory is freed twice, will also trigger similar issues. This may seem like a silly issue for one to program, but will happen quite easily as code complexity increases. Memory Leaks . This closely relates to temporal memory safety bugs. Without a garbage collector, there is no runtime object liveness analysis. If you forget to manually free memory, your program will continue to grow in memory size. While perfectly fine for short-lived programs (and probably the correct thing to do for performance), this becomes a major problem for larger programs. Leak enough memory on Linux and you will trigger the OOM-killer, which starts going down your OS’s process list and terminating processes to free up memory. Our usage of Valgrind will specifically catch for this type of bug. Uninitialized Types . There is no default initialization value in C. If you don’t explicitly initialize a variable, its contents will be undefined (usually, the contents come from a previous value at that same location). This can lead to a source of bugs! An extremely common bug from prior years is not properly initializing a data array, and ending up confused as to how the sum of 0 data points for a certain index resulted in a random large number. Erroneous Return Values . C doesn’t really have a built-in exception system nor does it have the concept of a result/option monad like in Rust or Haskell for error checking. The type system thus causes an erroneous return value to share the same type as a successful return value (C has unions, but those unions have no enforced safety guarantees). A common case for this is in syscall relevant functions such as read - on success, it tells you the number of bytes that are read, but on failure, it returns a specific negative value. Another example more relevant to this lab are functions that return heap-allocated objects. On success, they will return a valid pointer, but on failure, it will return a null pointer. Technically, the address 0x0 can still be a valid address depending on system configuration, which makes null pointers especially problematic in certain scenarios… Tony Hoare calls this his billion dollar mistake. Integer Overflows . If you are familiar with a real programming language, then you already know this. If you come from Python, then pay attention. Integer primitives in real languages are backed by hardware registers, which are limited in size. Eventually, a register will overflow (Ex. adding 1 to 2^63-1 will overflow and bring the value back to 0). You should expect the natural number wrapping behavior for unsigned integers in C, but this overflow becomes undefined behavior for signed integers, which leads to our next point. There are also many other integer related quirks - take this quiz to see how much you know! . Undefined Behavior . This is a very large class of bugs. C lists many different things as undefined behaviors, which basically means the compiler can do whatever it wants, including wiping your whole hard drive, and make any assumptions it wants (usually for the purpose of code optimization). This can lead to very very surprising behavior! Technically many of the previously discussed bugs fall in the category of “undefined behavior.” . Race Conditions . You won’t encounter this in our lab. But this is a problem that plagues every language whenever concurrency and parallelism enters the picture. A subclass of this includes data races, which some strongly typed languages like Rust have solved. ",
    "url": "/2026/labs/ccc.html#common-types-of-bugs",
    "relUrl": "/labs/ccc.html#common-types-of-bugs"
  },"16": {
    "doc": "C Crash Course",
    "title": "Debugging Tips:",
    "content": "There are a few ways to debug in C. Print Debugging . The best way in my opinion is print debugging. Use printf to add print statements wherever you need them. You can easily deduce all the test cases as well with this technique. Note that our tester binary includes the following initial call: . setbuf(stdin, NULL); setbuf(stdout, NULL); setbuf(stderr, NULL); . Standard library level IO functions often buffer input - you might miss a print statement if you don’t end the text with a newline as the default is line-buffering (and will also affect the heap layout). These setbuf calls disable buffering. C print functions rely on format specifiers, and you can learn all about them https://man7.org/linux/man-pages/man3/fprintf.3.html. Generally, you only need %d for uint32_t (I highly recommend that everyone use the bitwidth typed integers in C from stdint.h instead of the default integer types in C), %lld for uint64_t, %x for uint32_t in unsigned hex, %llx for uint64_t in unsigned hex, %p for pointers, %c for chars, and %s for strings. For example, if foo is a pointer to some struct, bar is an uint32_t, and foobar is a string, you would do this: . printf(\"foo: %p bar: %x foobar: %s\", foo, bar, foobar); . Do not ever directly print a non-compile time constant string as the first argument in printf ever in C code. Doing so will get your codebase compromised thanks to a specifier known as %n that allows for arbitrary write into memory. Sanitizer Debugging . Recall ASAN and UBSAN from earlier. These are helpful tools that instrument your code to help catch most memory safety and undefined behavior bugs during runtime. You run the instrumented version and whenever a violation is detected, you receive a report with a backtrace. For example, the starter code will trigger the following backtrace on one of the first test cases./sanitized_tester ------------------------------------------------------------ Running BUG_CHECK_0 Test, notebook length: 10 ------------------------------------------------------------ read_page AddressSanitizer:DEADLYSIGNAL ================================================================= ==357005==ERROR: AddressSanitizer: SEGV on unknown address 0x607000013980 (pc 0x7f7d7371584e bp 0x7ffd21a66fc0 sp 0x7ffd21a66fa0 T0) ==357005==The signal is caused by a READ memory access. #0 0x7f7d7371584e in read_page /shd-lib.c:25 #1 0x5e37b6534bd9 (/sanitized_tester+0xaabd9) #2 0x5e37b6554c54 (/sanitized_tester+0xcac54) #3 0x5e37b6529301 (/sanitized_tester+0x9f301) #4 0x5e37b65133b7 (/sanitized_tester+0x893b7) #5 0x7f7d71c29d8f in __libc_start_call_main ../sysdeps/nptl/libc_start_call_main.h:58 #6 0x7f7d71c29e3f in __libc_start_main_impl ../csu/libc-start.c:392 #7 0x5e37b6513944 (/sanitized_tester+0x89944) AddressSanitizer can not provide additional info. SUMMARY: AddressSanitizer: SEGV /shd-lib.c:25 in read_page ==357005==ABORTING . You can catch a lot of bugs just with this technique. Using an Actual Debugger . This should be your last resort, but can be useful for pinpointing some hard to catch bugs. The debugger I recommend is GDB with GEF extensions. Vanilla GDB looks ugly, isn’t fun to use, and defaults to AT&amp;T assembly syntax. There are many GDB guides out there, but these are what I find useful (though GEF already automatically shows a lot of the information these commands can reveal). | bt: for dumping a stack backtrace | p $&lt;var&gt;: display the value of a variable (which can just be a register name or an address). You can also typecase the var in C syntax to get a pretty-print, but that is dependent on whether there is sufficient DWARF debug information. | disas &lt;address&gt;: disassembles the current function, or starting from an address if specified. | x/&lt;NUM&gt;&lt;specifier&gt;x &lt;address&gt;: Shows NUM specifier sized elements in hex starting from address. Specifiers include g for giant word (8 bytes), w for word (4 bytes), h for half-word (2 bytes), or b for byte. If you replace the x after the specifier with an i, you can get a disassembly dump as well. | b sym/b address: set a breakpoint at an address. You can also specify a conditional expression for conditional breakpoints. | watch: watchpoints are like breakpoints, but for value changes in the program. I really doubt you’ll ever need it in this class, but a useful tool to have | c: continue program execution | r: start program execution | s/n: step and next. Step goes to the next source line, entering function calls, while next goes to the next source line, skipping function calls. There are many different variations of this, so take a look here. One variation worth mentioning are the stepi and nexti variants, which operate at the instruction granularity. | search-pattern: a GEF specific extension that is a life-saver. This allows you to search for arbitrary memory patterns at arbitrary address ranges. | . ",
    "url": "/2026/labs/ccc.html#debugging-tips",
    "relUrl": "/labs/ccc.html#debugging-tips"
  },"17": {
    "doc": "C Crash Course",
    "title": "The Lab",
    "content": "The goal of this lab is to fix the bugs - passing the tester checks should satisfy most of that. The Basics . Refer very carefully to the comments in shd-lib.h for the spec. One thing to realize about the struct definitions is the array declaration in page_t: . typedef struct { size_t len; char content[]; } page_t; . Usually, variable length arrays are not allowed in structs, except when it is the last field. This is a very common pattern in networking or IPC code. You can allocate these types of elastic structs with the following pattern: malloc(sizeof(elastic_type) + additional_size). In general, this library provides notebook objects with a fixed amount of pages, which users can read, write, erase, grow, and append to. Example Bug . One really simple bug that you should catch immediately is the lack of bounds checking in all the notebook relevant operations. Users have to specify a page_nr for most of them, yet there are no checks to see whether the page_nr is even possible for this notebook’s pages array. Some hints . | As mentioned earlier, the null byte in C strings can be really finicky, especially when performing operations on them. | The first 6 bugs we discussed earlier all appear here (and technically the 7th, because all those bugs lead to undefined behavior) | I talked about reading the spec for shd-lib.h earlier, but what about malloc, free, and realloc | Remember the base size of flexible structs. | One really tricky bug comes directly from a real world bug. Look into the root cause of CVE-2022-0185 for the Linux kernel. Don’t worry, all you need is basic C knowledge and it’s a one line fix! | . Additional Tester Features . Since certain bugs more easily manifest themselves from a simpler heap state in these short test cases (before many deallocations occur), you can manually run the ./tester binary with a list of names of certain BUG_CHECKS to run through. For example: ./tester BUG_CHECK_3 BUG_CHECK_6 BUG_CHECK_9. 1-1 Exercise . Fix all the bugs in shd-lib.c so that the test cases can pass! . 1-2 Discussion Question . Write about 5 bugs that you found in this lab. A single sentence for each will suffice. Grading . The programming component makes up 90% of the points in this lab. Each test case is worth the same (with the final valgrind test being considered a single test case). Our grader does NOT take into consideration a passing test case that comes after a crashing test case. The discussion makes up 10% of the points in this lab. Submission . Push your code to the Github classroom, and submit your discussion responses to Gradescope. ",
    "url": "/2026/labs/ccc.html#the-lab",
    "relUrl": "/labs/ccc.html#the-lab"
  },"18": {
    "doc": "C Crash Course",
    "title": "Acknowledgments",
    "content": "Contributors: William Liu, Shixin Song, Mengjia Yan . ",
    "url": "/2026/labs/ccc.html#acknowledgments",
    "relUrl": "/labs/ccc.html#acknowledgments"
  },"19": {
    "doc": "C Crash Course",
    "title": "C Crash Course",
    "content": " ",
    "url": "/2026/labs/ccc.html",
    "relUrl": "/labs/ccc.html"
  },"20": {
    "doc": "CTF of C Programming",
    "title": "CTF of C Programming",
    "content": "Throughout the class, we’ll be heavily relying on the low-level C and C++ languages. Using C and C++ allows us to manipulate the hardware at a very fine granularity, allowing us to pull off very powerful microarchitectural attacks in later labs. This is in contrast with higher-level languages, such as python, which make reasoning about the exact instructions executed by a program difficult. In this recitation we’ll primarily focus on learning how to write code in C, since C++ is a superset of C’s syntax (with limited exceptions). x . ",
    "url": "/2026/recitations/cpp.html",
    "relUrl": "/recitations/cpp.html"
  },"21": {
    "doc": "CTF of C Programming",
    "title": "Table of Contents",
    "content": ". | Crash Course | Pointers . | Declaration, Address-of, Dereference | Casting | A Pointer Points to Another Pointer | . | Commonly Used Data Structures . | Arrays | Strings | . | Useful for the Cache Lab . | Dynamically Allocated Memory | . | Useful for Rowhammer Lab . | C++ Maps (std::map) | . | Capture the Flag (CTF) | . ",
    "url": "/2026/recitations/cpp.html#table-of-contents",
    "relUrl": "/recitations/cpp.html#table-of-contents"
  },"22": {
    "doc": "CTF of C Programming",
    "title": "Crash Course",
    "content": "We’ll first walk through a quick code example to get you familiar with the format of C. #include &lt;stdio.h&gt; #define MAGIC_NUM 5 void sayHello(int helloNum) { printf(\"Hello World! The addition sum is: %d\\n\", helloNum); } int main(void) { int result = 1 + MAGIC_NUM; sayHello(result); return 0; } . A few things to note about this code: . | #include and #define are pre-processor directives, which are resolved prior to compilation. | #include tells the pre-processor to include the contents of the listed file (e.g. stdio.h) when compiling this file. | #define tells the pre-processor to replace all instances of the listed term with the following value (e.g. MAGIC_NUM is replaced with 5 everywhere in the code prior to compilation) | . | C is a relatively strongly typed language, especially compared to Python, requiring variables to be explicitly declared with their type (e.g. int). | printf prints a message to console. You can include variables in your printout by including a format specifier such as %d for integers. | Warning: printf is fairly heavy duty, so be cautious when calling it when measuring microarchitectural behaviours! | . | . ",
    "url": "/2026/recitations/cpp.html#crash-course",
    "relUrl": "/recitations/cpp.html#crash-course"
  },"23": {
    "doc": "CTF of C Programming",
    "title": "Pointers",
    "content": "Declaration, Address-of, Dereference . An extremely powerful tool used in C programs to interact with memory are pointers. Pointers are variables that contain a memory address, rather than a value directly. void example_method() { int a = 1234; // (1) int *b = &amp;a; // (2) *b = 9876; // (3) } . In this code, we declare an integer variable a and assign value 1234 to it. Next, we decleare a pointer variable, name it b, and assign the address of a to it, meaning we make pointer b points to the location of a. Let’s first understand three pointer-related operations. | Pointer declaration: To declare a pointer and give it a name, you need to use the type written as int *. More generally, it is written as the target data type followed by a star, such as char *, void *, etc. In the code above, we define a pointer named b and tell the compiler that it points to an integer. | Obtaining address: Every variable in C is stored in a location in memory, and thus each of them has an address. We use &amp; to obtain the address of a variable, and &amp; is called the address-of operator. As shown, we obtain the address of the variable a by writing &amp;a. | Dereference a pointer: Given a pointer, we can read or write the location pointed to by the pointer by dereferencing it. As shown, we write to the location pointed to by b by writing *b = 9876. Because b points to a, so after executing the last line of the code, if you read variable a, you will see it is now equal to 9876. | . Pointer declaration vs. Pointer dereference . Pointer declaration and pointer dereference both involve using the * notation. Make sure you understand what the * means each time you see it. For example, int *b = &amp;a; is the same as int *b; b = &amp;a;. Here, * means pointer declaration, and the assignement (i.e., =) initializes the pointer, NOT the value that the pointer points to. Next, let’s visualize the memory layout for the code above so you can get a better view. Reach to the course staff if you find the figure below difficult to understand. Casting . Occasionally you may be required to change the data type of a variable. For instance, you may want to access a specific address at a given 64-bit integer value. To do this, you can cast a variable into another as such: . void example_method() { uint64_t x = 0x12345678; // x is a 64-bit unsigned integer uint8_t *y = (uint8_t *) x; // change the type of x to make it a pointer (treat it as an address) uint8_t z = *y; // access the data pointed to by pointer y. // z now contains the data from address 0x12345678 } . A Pointer Points to Another Pointer . We can define a pointer that points to a location that holds another pointer. int a = 1234; int *b = &amp;a; int **c = &amp;b; . In the code above, int ** should be interpreted as (int *)*, meaning a pointer that points to a location holds a int *, which is also a pointer. You can dereference the pointer c in two ways. In both cases, val will be 1234. | int val = **c; | int* ptr = *c; int val = *ptr; | . ",
    "url": "/2026/recitations/cpp.html#pointers",
    "relUrl": "/recitations/cpp.html#pointers"
  },"24": {
    "doc": "CTF of C Programming",
    "title": "Commonly Used Data Structures",
    "content": "Arrays . C arrays are much like arrays in other languages! . void example_method() { int a[2]; // array declaration a[0] = 0; a[1] = 1; // access array element like in other languages printf(\"The first element of a is: %d\\n\", a[0]); printf(\"The second element of a is: %d\\n\", a[1]); printf(\"The first element of a is: %d\\n\", *(a)); // treat the array identifier as a pointer printf(\"The second element of a is: %d\\n\", *(a + 1)); } . Observe that the array variable (i.e. a) is just a pointer to the first element in the array (remember that C arrays start at 0). Specifically, ptr[index] treats ptr as an array and retrieves the entry at index index. This is the same as *(ptr+index). Pointer arithemetic operation under the hood . In a[1] and *(a + 1), the value 1 does not mean 1 byte. Instead it means 1 element. For example, if ptr points to address 0xFF00, then which address does ptr+1 point to? The answer is not 0xFF01. Instead it should be 0xFF00 + sizeof(int) = 0xFF04, as the size of an int is 4 bytes. Under the hood, the compiler is doing the pointer arithemetic computation for us by converting the 1 to 4 bytes based on the pointer type. Cheatsheet for Pointer size and Data Size . | int: 4 bytes | char: 1 byte | uint64_t means 64-bit unsigned integer: 8 bytes. | a pointer (int *, char *, void *): depends on your machine. On a 64-bit machine, no matter what data type it points to, a pointer is 64 bits, i.e., 8 bytes. | . If you incur a new data type and want to find out its size, you can printf(\"the size is: %lu\\n\", sizeof(x)) where x is the variable with the data type that you want to query about. Note that, when you cast a pointer, the address this pointer points to does not change, but the size may change, and the meaning of the associated arithemetic operation will also change. Strings . In memory, a string of “Hi!” looks like this . | Address | 0x0 | 0x1 | 0x2 | 0x3 | 0x4 | 0x5 | . | Data | ‘H’ | ‘i’ | ’!’ | ‘\\0’ | - | - | . In C, strings are just character arrays in disguise! . void example_method() { char string[6] = \"Hi!\"; printf(\"String stored: %s\\n\", string); // Print it character-by-character int i = 0; while(string[i] != '\\0') { printf(\"Character %d of string: %c\\n\", i, string[i]); i++; } } . Since a string is encoded as a fixed length array (e.g. 6 characters in our case), we need a way to indicate the end of the text. We use the null terminator (e.g. 0x00) to denote the end of the string (this is automatically inserted for you when you write “Hi!”). The above character-by-character code is actually quite dangerous! Think about what happens if you accidentally forget the null terminator here. ",
    "url": "/2026/recitations/cpp.html#commonly-used-data-structures",
    "relUrl": "/recitations/cpp.html#commonly-used-data-structures"
  },"25": {
    "doc": "CTF of C Programming",
    "title": "Useful for the Cache Lab",
    "content": "Dynamically Allocated Memory . You may have noticed that we were statically sizing our data structures in the previous sections. Sometimes you may want to allocate a dynamic amount of memory at runtime. This can be done using malloc() and free(): . void example_method() { int *array = malloc(2*sizeof(int)); // request a region that can hold 2 `int` if (array == NULL) { printf(\"malloc failed! \\n\"); return -1; } array[0] = 1; array[1] = 2; free(array); // return the memory region so others can resue it } . On success, malloc returns a pointer to the beginning of some newly allocated memory. To avoid a memory leak, make sure to deallocate dynamically allocated memory regions after you’re done with them using free(). ",
    "url": "/2026/recitations/cpp.html#useful-for-the-cache-lab",
    "relUrl": "/recitations/cpp.html#useful-for-the-cache-lab"
  },"26": {
    "doc": "CTF of C Programming",
    "title": "Useful for Rowhammer Lab",
    "content": "For later labs in the course, some advanced knowledge of C/C++ constructs may be required. We list some notes below for your reference. C++ Maps (std::map) . C++ is a slight departure from C – it is a higher-level multi-paradigm programming language which shares a majority of its syntax with C, and is quite interoperable with C (apart from some minor exceptions). C++ maps are very similar to Python dictionaries, with key-value pairs being assigned in a very similar fashion. A full description of this data structure can be found here. An example of using C++ maps is shown below. std::map&lt;uint64_t, uint64_t&gt; cpp_map; uint64_t key = 0xDEAD; uint64_t value = 0xBEEF; // Add or modify a key-value pair cpp_map[key] = value; // Retrieve a value for a key uint64_t key2 = 0xBAAD; uint64_t value2 = cpp_map[key2] if (value2 == 0){ assert(\"Key does not exist!\\n\"); } . ",
    "url": "/2026/recitations/cpp.html#useful-for-rowhammer-lab",
    "relUrl": "/recitations/cpp.html#useful-for-rowhammer-lab"
  },"27": {
    "doc": "CTF of C Programming",
    "title": "Capture the Flag (CTF)",
    "content": "With knowledge of these constructs, let’s try some CTF challenges! Check Piazza Post to get started. ",
    "url": "/2026/recitations/cpp.html#capture-the-flag-ctf",
    "relUrl": "/recitations/cpp.html#capture-the-flag-ctf"
  },"28": {
    "doc": "Website Fingerprinting",
    "title": "Website Fingerprinting Lab",
    "content": "Due Date: Feb 12, 2026; Last Updated Date: Jan 19, 2026 . ",
    "url": "/2026/labs/fingerprinting.html#website-fingerprinting-lab",
    "relUrl": "/labs/fingerprinting.html#website-fingerprinting-lab"
  },"29": {
    "doc": "Website Fingerprinting",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 1: Warm-up (20%) . | Hello World (Optional) | Timing Measurement | . | Part 2: Side Channel Attacks with JavaScript (60%) . | The Sweep Counting Attack | Part 2.1: Cache Trace Collection + Processing | Part 2.2: Automated Attacks with Machine Learning | . | Part 3: Root Cause Analysis (20%) | Takeaways | Contributors | . ",
    "url": "/2026/labs/fingerprinting.html#table-of-contents",
    "relUrl": "/labs/fingerprinting.html#table-of-contents"
  },"30": {
    "doc": "Website Fingerprinting",
    "title": "Lab Details",
    "content": "Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . This lab is done on your own computer, and should be (micro)architecture agnostic. If you don’t have a device to use, please reach out to the TA. You will complete this lab primarily in Python and JavaScript. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to Gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2026/labs/fingerprinting.html#lab-details",
    "relUrl": "/labs/fingerprinting.html#lab-details"
  },"31": {
    "doc": "Website Fingerprinting",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Launch an end-to-end side-channel attack to conduct website fingerprinting. | Try to understand the root cause of this attack. | . What is website fingerprinting? . In a website fingerprinting attack, an attacker tries to distinguish which website a victim has accessed on their machine. Website fingerprinting attacks can allow an attacker to gather a lot of user information, such as political views, religious beliefs, and sexual orientation. There exist many variants of website fingerprinting attacks, which we can classify into two categories (based on the resources that the attacker can access): on-path attacks and co-located attacks. An on-path attacker executes on a different machine from the victim. The attacker observes all network packets sent and received by the victim’s machine and infers the website based on the timing and size of the observed network packets. In contrast, a co-located attacker executes on the same machine and shares microarchitectural resources with the victim, including caches, DRAM, and GPUs. In the case of a low-privileged attacker, this co-location can be achieved by running attacker-controlled JavaScript code in a different browser tab. We focus on co-located attacks in this lab. Example of co-located attack setup (source) . What is the plan? . You will implement a variant of cache-occupancy side-channel attacks, called Sweep Counting Attack. This attack was originally described in the following two papers. Reading these two papers is not required to complete the lab, however they discuss several other attack techniques that you may find inspiring. | Robust Website Fingerprinting Through the Cache Occupancy Channel: Section 4.1, Page 8, Website Memorygrams. | Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel Defenses: Section 3.1, Page 5, Sweep Counting. | . You will demonstrate the attacks mounted from inside a web browser (a restricted execution environment). A browser usually cannot access fine-grained timers, cache-flushing instructions, or manipulate low-level memory. As such, after you complete this lab, you will hopefully see how versatile side channels are. Our plan of attack involves 1) writing JavaScript code to collect side-channel traces; and 2) using machine-learning techniques to analyze the traces we collect. Knowledge of the internal machine-learning techniques and mechanisms is not required. Instead, the goal is to allow you to use ML as a black-box tool. The attack you’ll develop in this lab should work in any web browser, including Chrome, Firefox, Safari, and even the Tor browser. Discussion Question (Optional) . Report your browser version, CPU type, cache size, RAM amount, and OS. We use this information to learn about the attack’s behavior on different machines. ",
    "url": "/2026/labs/fingerprinting.html#introduction",
    "relUrl": "/labs/fingerprinting.html#introduction"
  },"32": {
    "doc": "Website Fingerprinting",
    "title": "Part 1: Warm-up (20%)",
    "content": "In this part, you will familiarize yourself with the development environment and determine the timer resolution offered by JavaScript. Code Structure . | warmup.js: A JavaScript file with two functions, measureOneLine and measureNLines, which you will complete. | warmup.html: A webpage that displays the return values of the two functions. | . Hello World (Optional) . As a warm-up exercise, we will guide you through JavaScript development by writing a simple Hello World program. If you’re familiar with JavaScript, feel free to skip to Timing Measurement. Otherwise, here we provide a brief overview of JavaScript and the developer tools you’ll need for this lab. By including &lt;script src=\"warmup.js\"&gt;&lt;/script&gt; on line 31 of warmup.html, your browser downloads, runs, and executes the script’s contents immediately upon loading warmup.html. You can test this by adding a simple print function like console.log(\"Hello World!\"). You can then view the console by right-clicking the page, selecting Inspect (Cmd-Opt-I on MacOS or F12 on Windows/Linux), and then selecting Console. In Safari, you may need to unlock inspect mode with Safari &gt; Preferences &gt; Advanced &gt; Show Develop Menu. You can use console.log to debug your JavaScript code. JavaScript’s basic syntax is fairly similar to other languages you might be familiar with, such as C or Java. If you need to review JavaScript’s syntax while completing this lab, feel free to refer to various online resources. Exercise (Optional) . Add a console.log statement with a message of your choice, anywhere in warmup.js. Then, open warmup.html in your web browser and check the console to ensure that your message is displayed. Timing Measurement . Before we can execute a timing side-channel attack, we need to determine the quality (i.e., resolution) of the timer. The JavaScript’s timer (in milliseconds) can be accessed via the performance.now() API. This API yields different resolutions depending on the browser – the resolution is 0.1 ms in Chrome 92, and 1ms in Firefox 91. In warmup.js we provide measureOneLine(), an example of how we can measure the access latency of a single memory access using performance.now(). You should see the following output when you open warmup.html in a browser (you may occasionally see some non-zero entries). Website Fingerprinting Lab Warmup 1 Cache Line: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] N Cache Lines: [] . Your first task is to determine the timing resolution of performance.now() by measuring the latency of accessing multiple cache lines. Report the observed value for accessing N cache lines, where N ranges from 1 to 10,000,000. Feel free to access the memory in sequential order, as we are trying to get a rough idea about the timing resolution. You can ignore any potential effects of hardware prefetching. Since you may not get consistent results each time due to system noise, perform the measurement 10 times and report the median access latency. A cache line != A single element in an array . A cache line is different from an element in an array because they have different sizes. The cache line size of your machine is likely 64 or 128 Bytes. If you are not sure, you can use getconf -a | grep CACHE if you are running Linux or use sysctl -a | grep cachelinesize if you are running MacOS. Once you figure out the cache line size, you will want to access an array with a specified stride to make sure each access targets a different cache line. Generally, if you have an x86_64 processor, your cache line size will be 64 bytes. If you are on an ARM core MAC, your cache line will be 128 bytes. 1-1 Exercise . Complete measureNLines() such that it measures the access time of N cache lines 10 times and pushes each measurement to the end of the result array. These values will be displayed on warmup.html when you refresh the page. 1-2 Discussion Question . Use the values printed on the webpage to find the median access time and report your results as follows. | Feel free to find the median value by hand (you are not required to implement the code to do statistic calculation). | In the case that your browser complains about the buffer size that you request is too large (with an “out-of-memory” error), you can fill in the corresponding entry with “N/A”. | . | Number of Cache Lines | Median Access Latency (ms) | . | 1 |   | . | 10 |   | . | 100 |   | . | 1,000 |   | . | 10,000 |   | . | 100,000 |   | . | 1,000,000 |   | . | 10,000,000 |   | . 1-3 Discussion Question . According to your measurement results, what is the resolution of your performance.now()? In order to measure differences in time with performance.now(), approximately how many cache accesses need to be performed? . Submission and Grading . You need to submit part1/warmup.js to your assigned GitHub repository. You should not modify any other files. ",
    "url": "/2026/labs/fingerprinting.html#part-1-warm-up-20",
    "relUrl": "/labs/fingerprinting.html#part-1-warm-up-20"
  },"33": {
    "doc": "Website Fingerprinting",
    "title": "Part 2: Side Channel Attacks with JavaScript (60%)",
    "content": "The Sweep Counting Attack . In a cache-occupancy attack, the attacker leverages the fact that the attacker and victim share the same cache hierarchy. As such, an attacker can monitor its own cache access latency to estimate how much of the cache is occupied by the victim and infer the victim’s behavior. For example, consider an attacker which accesses each element of a Last Level Cache (LLC) sized buffer prior to the victim’s execution. When the victim subsequently performs a lot of memory accesses, it will evict the attacker’s buffer from the cache, and the attacker will observe a longer latency when it re-accesses the buffer. As such, the attacker’s own memory access time is roughly proportional to the number of cache lines the victim accessed. The sweep counting attack is a variant of these cache-occupancy attacks, particularly suited for the case when the attacker is restricted to using low-resolution timers. The attacker allocates a Last Level Cache (LLC) sized buffer and sequentially accesses each cache line in the buffer (like what you have done in Part 1). We call one round of scanning the buffer “one sweep over the LLC.” Then, the attack works by counting how many sweeps over the cache can fit into a single time window whose length is P ms. P ms is on the order of a few milliseconds, and it is a parameter chosen by you. You will repeatedly perform sweep counting for 5 seconds, so that the counters you gather can form a trace with the length as K, where K = 5000/P. Part 2.1: Cache Trace Collection + Processing . Let’s start with implementing the sweep counting attack to collect cache traces in JavaScript. In this attack, the victim code and attacker code resides in two separate JavaScript environments. They can be within two different browser tabs, or entirely separate web browsers on the same machine. The attacker tab will create two threads: a main thread that handles user interactions (e.g., clicking website buttons) and a worker thread that executes your provided code in the background. Note that the worker thread runs even if the attacker tab is not in the foreground. Setting Up The Web Server . To run the worker thread, modern web browsers require that you load the page from a server (rather than simply opening index.html as a file). To get around this issue, you can develop your code by running a simple web server using the following commands, run from the part2/ folder. Make sure you’re using Python3 for this step (and the rest of the lab). $ cd part2 $ python3 -m http.server Serving HTTP on :: port 8000 (http://[::]:8000/) ... Web browsers typically cache the worker thread upon loading the page, so you will need to change your browser’s settings to load updates you make to worker.js. Follow the instructions here in order to do this. If this doesn’t work for you, you can force a refresh of the service worker by opening your worker script at http://localhost:8000/worker.js, holding down shift while clicking the refresh button in your browser’s toolbar, and manually checking that the file’s contents match what you expect. Trace Collection . Open http://localhost:8000 in your preferred web browser. Pressing Collect Trace will begin a countdown, which you can use to prepare your experiment (i.e., switching to a new window). At the end of the countdown, the worker will trigger record(), which will be written by you in worker.js. The output of this function is displayed as a 1D heatmap for convenience. You can click this button multiple times without refreshing the window in order to collect multiple traces. Clicking Download Traces will allow you to download all of the traces collected in a JSON format. You will implement the sweep counting attack inside the record() function. Feel free to refer to the description of the attack at the beginning of Part 2. If you have difficulty in making the attack work, you can also refer to the pseudocode in There’s Always a Bigger Fish: A Case Study of a Misunderstood Timing Side Channel Figure 2. Trace Processing . You can process these downloaded traces in Python with code such as the following: . import json import numpy as np with open(\"traces.json\", \"r\") as f: # Load contents from file as JSON data data = json.loads(f.read()) # Convert 2D array into Numpy for data processing traces = np.array(data[\"traces\"]) # Labels are only available with the automation script. # Use the line below in part 2.2 onward to access them. # labels = data[\"labels\"] # Example data analysis print(traces.mean()) . Such traces can be used to distinguish different system events. The below image shows three traces that were collected under the following circumstances: . | Do nothing while the trace is collected | Add random system activity, moving the mouse during trace collection | Open nytimes.com in a new window during trace collection | . 2-1 Exercise . Complete the record() function in worker.js. Experiment with different P values and collect traces for the three scenarios above for the best value of P you find. Your traces will not exactly match those in the provided example, but they should be visually distinguishable from one another. 2-2 Discussion Question . Report important parameters used in your attack. For each sweep operation, you access N addresses, and you count the number of sweep operations within a time interval P ms. What values of N and P do you use? How do you choose N? Why do not you choose P to be larger or smaller? . 2-3 Discussion Question . Take screenshots of the three traces generated by your attack code and include them in the lab report. Part 2.2: Automated Attacks with Machine Learning . It is tedious and unreliable to launch the victim website manually. To automate the attack process, we provide an automation script (automate.py) based on the Selenium browser automation framework for you to use. Installing Drivers . To complete this section, you will need to install Flask, Selenium, and SciKit-Learn. Make sure you are using Python 3 and install these modules with python3 -m pip install flask selenium scikit-learn. If you do not want to change your defualt Python environment, you can use Python’s support for Virtual Environment . Selenium should automatically install the latest drivers for the browser(s) you have installed. If you are encountering running Selenium, try manually installing the driver using option 3. Using the Automation Script . You can test the automation script by collecting a few traces while your victim opens different websites using the following commands: . $ python3 automate.py --part 2 --domains google.com,nytimes.com --num_traces_per_domain 4 --out_filename traces.out . Detailed descriptions of the arguments used by the automation script can be found by executing python automate.py --help: . usage: automate.py [-h] [--browser {chrome,firefox,safari}] [--domains DOMAINS] [--num_traces_per_domain NUM_TRACES_PER_DOMAIN] [--trace_length TRACE_LENGTH] --out_filename OUT_FILENAME --part {2,3} optional arguments: -h, --help show this help message and exit --browser {chrome,firefox,safari} Browser to run automation in. --domains DOMAINS Comma-separated list of domain names to collect traces from. Defaults to google.com,youtube.com,baidu.com,facebook.com --num_traces_per_domain NUM_TRACES_PER_DOMAIN Number of traces to collect per domain. --trace_length TRACE_LENGTH The length of each recorded trace, in milliseconds. required arguments: --out_filename OUT_FILENAME Name of the output file to save traces to. --part {2,3} Set to the part of the lab you're working on. We recommend starting with a few traces from google.com and nytimes.com. Google is a lightweight website with mostly static content, while NYTimes is a heavyweight website that loads many assets, making them easy to distinguish. 2-4 Discussion Question . Use the Python code we provided in Part 2.1 to analyze simple statistics (mean, median, etc.) on the traces from google.com and nytimes.com. Report the statistic numbers. Using Machine Learning for Classification . Let’s now design a more advanced attacker. Instead of collecting four traces on two websites, we’re going to collect 20 traces on four different websites. As we’re collecting five-second traces, this will take about 7 minutes to run. Pick four of your favorite websites (school appropriate / G-rated) to classify between, pass them to the domains argument, and leave your computer alone until it’s done (to avoid introducing unnecessary noise to your attack). $ python automate.py --part 2 --domains website1.com,website2.com,website3.com,website4.com --num_traces_per_domain 20 --out_filename traces.out . Once the script has finished, you should divide your traces into a training set with 16 traces from each site, and a testing set with 4 traces from each site. The training set is used to train a machine learning model, and the testing set is used to evaluate its accuracy once training is complete. We recommend using the train_test_split function from the scikit-learn library, with test_size=0.2. Then, train a RandomForestClassifier (or another classification model of your choice from scikit-learn) on your training set. Finally, use your model to predict labels for the testing set, and check your model’s accuracy with scikit-learn’s classification_report function. An example classification report is shown below. precision recall f1-score support https://www.baidu.com 1.00 1.00 1.00 4 https://www.google.com 1.00 1.00 1.00 4 https://www.facebook.com 1.00 0.75 0.86 4 https://www.youtube.com 0.80 1.00 0.89 4 accuracy 0.94 16 macro avg 0.95 0.94 0.94 16 weighted avg 0.95 0.94 0.94 16 . 2-5 Exercise . Complete the eval() function in eval.py. In this function you should: . | Load your traces into memory | Split your data into a training and test set | Train a classification model on your training set | Use your model to predict labels for your test set | Print out your model’s accuracy using classification_report | . Use your eval() implementation to analyze the traces that you collected for four websites and print the classification result. Remember to include the traces part2/traces.out in the Github repo to get full credit for this exercise. Exercise (Optional) . Try different machine learning models to see whether you can improve on the accuracy of your previous scheme. 2-6 Discussion Question . Include your classification results in your report. Submission and Grading . You need to submit the code you changed (mainly part2/worker.js and part2/eval.py)and traces (part2/traces.out) to your GitHub repository. The accuracy (i.e. the accuracy f1-score reported in the classification report) can be affected by the websites you choose as well as your web brower versions. Anything higher than 60% accuracy will recieve full credit. In most cases, you should easily be able to achieve 80% accuracy. If your accuracy is lower than 60%, try some websites with more distinguishable content, or try an older version of the web brower. We observe Chrome 98 or earlier works well for MacOS and Chromium 113 works well for Ubuntu. If you still have trouble, reach out to TAs. ",
    "url": "/2026/labs/fingerprinting.html#part-2-side-channel-attacks-with-javascript-60",
    "relUrl": "/labs/fingerprinting.html#part-2-side-channel-attacks-with-javascript-60"
  },"34": {
    "doc": "Website Fingerprinting",
    "title": "Part 3: Root Cause Analysis (20%)",
    "content": "Machine-learning-assisted side-channel attacks are very powerful as they are able to find correlations across traces and can tolerate medium to heavy amounts of noise. A key challenge with using machine learning, however, is that it doesn’t provide us insight as to why an attack works. Given that JavaScript is a high-level language, we do not have full control or knowledge of the instructions being executed on the processor, nor do we have a good idea of where our signal is actually coming from! . In this part, you will try a slightly modified attack to learn about the pros and cons of ML-driven attacks. So far, we have implemented the sweep counting attack, a variant of the cache-occupancy attack. As the name of the attack suggests, this attack leaks information via cache interference. But what if we remove the cache accesses in the code? Will the attack still work? . 3-1 Exercise . Copy your record() function from part2/worker.js to part3/worker.js and modify record() by removing all memory accesses in your code. After removing the memory accesses, all that will remain in loop body is an add operation for incrementing a counter. Therefore, what you end up doing is counting the number of times you perform the add operation within a time window of length P ms. Then re-collect the traces for the four sites you previously examined and report the accuracy. Remember to include the traces part3/traces.out in the Github repo to get full credit for this exercise. 3-2 Discussion Question . Include your new accuracy results for the modified attack code in your report. 3-3 Discussion Question . Compare your accuracy numbers between Part 2 and 3. Does the accuracy decrease in Part 3? Do you think that our “cache-occupancy” attack actually exploits a cache side channel? If not, take a guess as to possible root causes of the modified attack. Note: Without detailed investigation, you will not be able to verify your answer to this question. We will give full credit as long as the reasoning behind your guess is logical. If you’re curious as to the reasons why, we recommend reading the paper There’s Always a Bigger Fish: A Case Study of a Misunderstood Timing Side Channel. We will also discuss this paper in one of the recitation sessions. Submission and Grading . You need to submit your code (part3/worker.js) and the traces (part3/traces.out) to your GitHub repository. Anything higher than 60% accuracy will recieve full credit. ",
    "url": "/2026/labs/fingerprinting.html#part-3-root-cause-analysis-20",
    "relUrl": "/labs/fingerprinting.html#part-3-root-cause-analysis-20"
  },"35": {
    "doc": "Website Fingerprinting",
    "title": "Takeaways",
    "content": "Congratulations on finishing the website fingerprinting lab. We hope your very first experience with the side-channel attack in this class went well. After completing this lab, it would be valuable to recap and think about what you have learned. As the developers of the lab, we hope that, in addition to giving you a taste of attack engineering, the lab can enlighten you with the following takeaway message: Side channels are versatile in modern systems, and with the help of machine learning techniques, they become easier to pull off. However, finding the root cause of a side channel now presents as a new challenge. ",
    "url": "/2026/labs/fingerprinting.html#takeaways",
    "relUrl": "/labs/fingerprinting.html#takeaways"
  },"36": {
    "doc": "Website Fingerprinting",
    "title": "Contributors",
    "content": "Jack Cook, Mengjia Yan, Joseph Ravichandran and Peter Deutsch. ",
    "url": "/2026/labs/fingerprinting.html#contributors",
    "relUrl": "/labs/fingerprinting.html#contributors"
  },"37": {
    "doc": "Website Fingerprinting",
    "title": "Website Fingerprinting",
    "content": " ",
    "url": "/2026/labs/fingerprinting.html",
    "relUrl": "/labs/fingerprinting.html"
  },"38": {
    "doc": "For Instructors",
    "title": "Looking to use our course materials in your course?",
    "content": "There are two things you won’t want to miss: . | Our lab handouts can be found here. | The lab starter code and deployment instructions can be found here. | . ",
    "url": "/2026/forInstructors.html#looking-to-use-our-course-materials-in-your-course",
    "relUrl": "/forInstructors.html#looking-to-use-our-course-materials-in-your-course"
  },"39": {
    "doc": "For Instructors",
    "title": "Get in touch!",
    "content": "Reach out to our team at hw-sec-lab-dev at mit.edu before using our code in your course. We can provide you the instructor’s solutions, a starter gradebook, and grading scripts. ",
    "url": "/2026/forInstructors.html#get-in-touch",
    "relUrl": "/forInstructors.html#get-in-touch"
  },"40": {
    "doc": "For Instructors",
    "title": "For Instructors",
    "content": " ",
    "url": "/2026/forInstructors.html",
    "relUrl": "/forInstructors.html"
  },"41": {
    "doc": "Home",
    "title": "Secure Hardware Design (Spring 2026)",
    "content": "Learn to attack processors… and learn to defend them! . ",
    "url": "/2026/#secure-hardware-design-spring-2026",
    "relUrl": "/#secure-hardware-design-spring-2026"
  },"42": {
    "doc": "Home",
    "title": "Welcome to 6.5950/6.5951 (previously 6.S983 and 6.888)!",
    "content": "6.5950/6.5951 is a research-oriented course on secure hardware design. 6.5950/6.5951 will help you understand the critical security problems in modern hardware and common limitations of existing security solutions. Through a mix of lectures and paper discussions, we will learn the principles of various attacks and how to design effective hardware mitigations and hardware/software co-design solutions. Previous years’ websites. Feel free to post your anonymous feedback here during the semester. ",
    "url": "/2026/#welcome-to-6595065951-previously-6s983-and-6888",
    "relUrl": "/#welcome-to-6595065951-previously-6s983-and-6888"
  },"43": {
    "doc": "Home",
    "title": "Meeting Location and Times",
    "content": "Required Lectures: Mondays and Wednesdays from 1:00pm to 2:30pm in Room E25-111. Note that participation is required at scheduled time; take this course only if you will generally be able to participate! . Lecture videos can be found on Panopto. We will use Piazza for all course-related discussion. ",
    "url": "/2026/#meeting-location-and-times",
    "relUrl": "/#meeting-location-and-times"
  },"44": {
    "doc": "Home",
    "title": "Assignments and Grading",
    "content": "Starting Spring 2026, 6.5950/6.5951 now includes a cumulative, in-class exam. This differs from previous offerings of the course which had no formal assessments. Please plan accordingly. 6.5950/6.5951 will have an in-class exam for the Spring 2026 term. Your grade is based on three components: . | Lab Assignments (80% for graduate version, 90% for undergraduate version): There will be 8 lab assignments. You will be asked to implement your own attacks that work on real machines (not simulators). You must complete all labs to pass this course. After the final lab has been released, we will release a graded (for completion), end-of-term survey for you to fill out. Please take the time to fill out the survey, as it will help us improve the course for future students. | Exam (10% for graduate and undergraduate version): There will be a cumulative, in-class exam on May 6th. | Paper Discussion (10% for graduate version): Each student taking the graduate version will be assigned a particular conference paper and presentation partner. You are expected to review relevant materials, write a presentation, and lead the class discussion for that topic. Although we will not be formally tracking attendance, we expect regular attendance and participation from all students (both undergraduate and graduate). | . Grade distribution follows the following categories: . | A: [90, 100] | B: [80, 90) | C: [70, 80) | F: [0, 65) | . ",
    "url": "/2026/#assignments-and-grading",
    "relUrl": "/#assignments-and-grading"
  },"45": {
    "doc": "Home",
    "title": "Staff",
    "content": "Professor Mengjia Yan Email: mengjia at csail.mit.edu Office: 32-G840 Office Hours: Friday 2:30pm–3:30pm (32-G840) . TA Kosi Nwabueze, Vincent Ulitzsch, Kelly Xu Email: shd-staff at mit.edu Office: 32-G786 Office Hours: Kelly: Tuesdays 11:30am–1:30pm (32-G7 Lobby) Kosi: Wednesdays 2:30pm–4:30pm (32-G7 Lobby) . Course Assistant Taylor Braun Email: shd-staff at mit.edu . ",
    "url": "/2026/#staff",
    "relUrl": "/#staff"
  },"46": {
    "doc": "Home",
    "title": "Prerequisites",
    "content": "6.5950/6.5951 is primarily intended for seniors, M.Eng, and PhD students who want to learn about how to design hardware processors with security as the primary goal. You should have a good understanding of basic computer architecture (i.e., a strong grasp of the material taught in 6.004) and experience with the C programming language. 6.5950/6.5951 is a 12-unit (3-0-9) subject. It is listed as an AUS/AAGS and TQE course. ",
    "url": "/2026/#prerequisites",
    "relUrl": "/#prerequisites"
  },"47": {
    "doc": "Home",
    "title": "Late Policy",
    "content": "Throughout the semester, you have 120 free late hours. You can use these free late hours if you are sick, have a busy week, or need more time to complete the lab. There are two ways that you could lose points due to late submissions. Firstly, after using all free late hours, there is 1% penalty per additional late hour. Secondly, if a single lab is submitted more than 120 hours late (even if part of them are free late hours), no credit will be awarded for that lab. Please note that long weekends (Feb 14–16, Apr 18–20) and spring break (Mar 21–29) are excluded from late hour calculations. In addition, extensions without penalty may be granted on a case-by-case basis with support from S3. Please email the staff to request an extra extension. If there are medical issues that require further accommodation, please contact the staff. ",
    "url": "/2026/#late-policy",
    "relUrl": "/#late-policy"
  },"48": {
    "doc": "Home",
    "title": "Collaboration Policy",
    "content": "Laboratory exercises should be completed individually, and the work you hand in must be your own. Copying another person’s work or allowing your work to be copied by others is a serious academic offense and will be treated as such. As a general rule, follow the MIT Academic Integrity Policy and, when in doubt, ask the course staff. Violations of this policy will be treated severely. Examples of permitted collaboration . | Allowed: Talk to a friend about a lab assignment and discuss at a high level how to go about completing the assignment. | Allowed: Ask a staff member for help if you are confused or stuck. | Allowed: After you’ve completed and submitted your own lab, help a friend debug their code solely by looking at their code and trying to identify problems with it. | . Examples of prohibited collaboration . | Not Allowed: Help a friend debug their code by bringing up your solution and comparing the two to identify differences. | Not Allowed: Using code from a friend who previously took the class as a starting point for completing your labs and then making some modifications to that code. | Not Allowed: Working together so closely that you are basically typing in your solutions side by side. | Not Allowed: Copying any portion of someone elses work even if you make some modifications to it. | Not Allowed: Sharing any portion of your code with someone else. | Not Allowed: Get help from a friend who is looking at their solutions while helping you. | . See the MIT Academic Integrity Policy. ",
    "url": "/2026/#collaboration-policy",
    "relUrl": "/#collaboration-policy"
  },"49": {
    "doc": "Home",
    "title": "Generative AI Policy",
    "content": "The use of generative AI tools, such as large language models (LLMs), is permitted for lab assignments. However, we caution that overuse may detract from your learning and your understanding of the concepts these labs are designed to teach. We recommend approaching these tools as collaborators to discuss high-level concepts rather than as a means to obtain direct solutions. Additionally, since exercises are finely tuned to specific hardware setups, AI agents may be unable to interact with or provide accurate support for many exercises. ",
    "url": "/2026/#generative-ai-policy",
    "relUrl": "/#generative-ai-policy"
  },"50": {
    "doc": "Home",
    "title": "Warning",
    "content": "You’ll learn how to attack computer systems in this class in order to better understand how to design defenses. Please don’t attack other people’s computers or information without their prior permission. As well as being a bad idea, it may be illegal or a violation of MIT network rules and can get you into serious trouble. ",
    "url": "/2026/#warning",
    "relUrl": "/#warning"
  },"51": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/2026/",
    "relUrl": "/"
  },"52": {
    "doc": "Infrastructure",
    "title": "Infrastructure",
    "content": "This handout covers the basics of using Git for labs, plus editor suggestions for working on lab machines over SSH. ",
    "url": "/2026/infrastructure.html",
    "relUrl": "/infrastructure.html"
  },"53": {
    "doc": "Infrastructure",
    "title": "Code editors",
    "content": "Most of the labs in this course are completed on the lab machines, which you will connect to through SSH. Therefore, we recommend using a code editor that supports remote editing over SSH. While there is a bit of a learning curve, we recommend Vim as it provides a better editing experience than nano. We disallow using VS Code remote edit on lab machines (especially for Cache Attacks, Rowhammer, and Spectre labs). Certain labs have fragile setups when it comes to cache states and other microarchitectural resources, which you will share with dozens of other students. In order to prevent interference with other students’ experiments, we do not allow remote editing on these labs. Vim . Vim is a good default choice for editing directly on lab machines (it’s more capable than nano, but has a learning curve). | Learn basics: run vimtutor | Show line numbers: add the following line to ~/.vimrc on the machine you’re using: | . set number . ",
    "url": "/2026/infrastructure.html#code-editors",
    "relUrl": "/infrastructure.html#code-editors"
  },"54": {
    "doc": "Infrastructure",
    "title": "Git",
    "content": "We use Git for retrieving starter code and submitting the code portion of labs. We also recommend using Git throughout the lab to keep checkpoints you can return to later. Setup . | Install Git: Follow the official instructions at https://git-scm.com/book/en/v2/Getting-Started-Installing-Git. | GitHub access / SSH keys: Follow the same steps described in the Labs page under “Submission Instructions → GitHub” (or see the upstream reference here). | . Using Git . For this class, the main Git tasks are cloning the repository, committing your work locally, and pushing to GitHub. Clone . git clone git@github.com:&lt;YOUR_USERNAME&gt;/&lt;YOUR_REPOSITORY&gt;.git . If you are using GitHub Classroom, replace the above with the repository link provided by the course staff (see the Labs submission instructions). Stage changes (git add) . Stage modified files so they are included in the next commit: . git add &lt;MODIFIED_FILES&gt; . We recommend staging everything when you’re ready to checkpoint: . git add . This prevents accidentally forgetting to add files that have been changed. Create a snapshot (git commit) . Create a commit to checkpoint your current state: . git commit -m \"describe what you changed\" . The git commit command snapshots the state of your code, and the commit message provides a way to tag the snapshot. We recommend committing frequently with descriptive commit messages to allow for easy rollbacks and a record of your code to help with your own lab progress. Submit (git push) . Push your local commits to GitHub: . git push . We can only grade what is in your remote repository. Make sure you push before the deadline. Typical workflow . git clone &lt;REPO_LINK&gt; # clone the lab initially cd &lt;REPO_DIR&gt; # navigate to the repository directory # edit files... git add . # stage all changes git commit -m \"finish part A\" # create a snapshot of your code git push # push your changes for submission . ",
    "url": "/2026/infrastructure.html#git",
    "relUrl": "/infrastructure.html#git"
  },"55": {
    "doc": "Labs",
    "title": "Labs",
    "content": "There will be 8 laboratory exercises given throughout the semester related to lecture content. | Lab | Difficulty | Due Date | . | 0. C Crash Course (5%) | Easy | Thu, Feb 12 | . | 1. Website Fingerprinting (10%) | Easy | Thu, Feb 12 | . | 2. Cache Attacks (20%) | Hard | Tue, Mar 3 | . | 3. Spectre Attacks (15%) | Med | Thu, Mar 12 | . | 4. Rowhammer (15%) | Med | Thu, Apr 2 | . Your lab grade accounts for 80% (graduate version) or 90% (undergraduate version) of your final grade, with each lab weighted according to the ratios shown in the table above. Each lab is due at 11:59 PM. In addition, once the final lab has been released, we will release a graded (for completion), end-of-term survey for you to fill out. Please take the time to fill out the survey, as it will help us improve the course for future students. Before starting a lab, please review the Infrastructure page to familiarize yourself with the tools and resources you will need. ",
    "url": "/2026/labs.html",
    "relUrl": "/labs.html"
  },"56": {
    "doc": "Labs",
    "title": "Submission Instructions",
    "content": "Labs will be submitted via GitHub Classroom, and accompanying reports will be submitted via Gradescope. You must submit the lab report, which contains your answers to the discussion questions, to Gradescope (not GitHub) before the due date. Failure to do so will result in a flat -10% deduction from your lab grade. GitHub . To access and submit lab materials, you will need to have a github.com account. For each lab, we will create a new repository for you on GitHub Classroom. To access the repository: . Check Piazza posts for the invitation link of Github Classroom. To clone the starter code from the repository: . git clone &lt;GITHUB CLASSROOM REPOSITORY LINK&gt; . However, if you have never used github on the machine you are running (i.e., either your own machine or our servers), you need following steps to authorize the machine to access GitHub: . | If you are using our server, connect using ssh (i.e., ssh username@&lt;servername&gt;.csail.mit.edu) | ssh-keygen -t rsa -b 4096 (note that if you already have an ssh key, you can skip this) | Press return until the command finishes. | cat ~/.ssh/id_rsa.pub (feel free to use an existing key if you have one) | Copy this and create a new ssh key on your GitHub account (instructions if you need help). | git clone &lt;GITHUB CLASSROOM REPOSITORY LINK&gt; | . To push your changes (submitting your work): . git add FILES_YOU_CHANGED git commit -m \"WHAT YOU CHANGED\" git push . GitHub classroom will snapshot the state of your repository at the due date (at 23:59:59), which we will use to grade your submission. Your repository will not be locked after that point, feel free to continue to push if we have allowed an extension for you. Gradescope . Each lab contains exercises and discussion questions. Type your answers to discussion questions in the markdown template provided in the starter code of each lab (report.md). Convert the markdown file to PDF (e.g., you can simply open the file on github.com and print it to PDF with your web browser) and upload the PDF file to Gradescope (prior to the submission deadline). ",
    "url": "/2026/labs.html#submission-instructions",
    "relUrl": "/labs.html#submission-instructions"
  },"57": {
    "doc": "Labs",
    "title": "Development Environment",
    "content": "For all our labs (and recitations, except lab 1), we will setup a user account for you on our lab machines, where the development environment has been properly setup. These machines are accessed over SSH. Check your email to recieve your username and a temporary password. Please change your password after your first log-in. If you forget your password, please email shd-staff@mit.edu to request a password reset. To help curb excessive password reset requests, we will institute a policy that penalizes your total lab grade by 1% for every password reset request. Alternative Docker Environment . Most our labs highly depend on the configurations of our physical machines (e.g., cache organization, DRAM model) and cannot be done locally on your own machine. However, for some labs, it is possible run the lab locally and we will provide a Docker file in the repository to setup your environment. To use Docker, you need to first understand two concepts: . | Docker Image: An image file storing all the pre-installed libraries (e.g., compilers, python libraries). | Docker Container: A running environment that is provisioned with a Docker image and contains all the modifications you have made (e.g., install a new library). | . Then, you can use Docker with follwing steps: . | Download the Docker engine here. | In the root folder of a repository, where file Dockerfile and docker-compose.yml exist, use the command below to build the Docker image, use the image to create a container, and run the container: docker compose up -d . | Enter the container and run bash with (env below is the name of the container that we specify in docker-compose.yml): docker compose exec env bash . | For your convenience, we mount the repository folder on your host machine into a folder named /gitRepo in the container (defined in docker-compose.yml). You could enter the folder and start to run the code: cd /gitRepo . | If you want to continue with the lab in another time, you could exit the container with ctrl-d. Then, pause and resume the container with: docker compose stop # Pause docker compose up -d # Resume . | When you are done with the lab, you could delete the container and the image with (Both commands will delete any modification you made to the container): docker compose down # Delete container but keep the image docker compose down --rmi all # Delete both container and image . | . You can find more document on using Docker Compose to manage Docker images and containers here. ",
    "url": "/2026/labs.html#development-environment",
    "relUrl": "/labs.html#development-environment"
  },"58": {
    "doc": "Lecture Readings",
    "title": "Lecture Readings",
    "content": "* Indicates the resource requires MIT library login . | | Background Reviews and Related Books | Research Papers (mentioned in class) | Fun Readings and Videos | . | Overview | 6.191 [6.004] slides: . | L01 The Digital Abstraction | L12 Memory Hierarchy | L13 Caches | L15 Pipelined Processors: Data and Control Hazards | L16 Operating Systems | L17 Virtual Memory 1 | L18 Virtual Memory 2 | L22 Modern Processor Architecture | . | . | . | USENIX ATC '21/OSDI '21 Joint Keynote Address-It's Time for Operating Systems to Rediscover Hardware | . | . | Side Channel Overview | . | . | DAWG: A Defense Against Cache Timing Attacks in Speculative Execution Processors (Section I) | A retrospective on the VAX VMM security kernel. 1991 (Section VI-E) | . | . | Side Channel Security Youtube Channel | . | . | Deep Dive of Cache Side Channels | . | . | FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack | Last-Level Cache Side-Channel Attacks are Practical | Attack Directories, Not Caches: Side Channel Attacks in a Non-Inclusive World | . | . | EntryBleed: Breaking KASLR under KPTI with Prefetch | . | . | Transient Execution Side Channels | . | 6.5900 [6.823] L06 Complex Pipelining Scoreboarding (Recording) (covered in the lecture, but if want to get more details about out-of-order execution) | . | . | On the Spectre and Meltdown Processor Security Vulnerabilities | Meltdown: Reading Kernel Memory from User Space | Spectre Attacks: Exploiting Speculative Execution | Speculative Load Hardening: A Spectre Variant #1 Mitigation Technique | MDS: Microarchitectural Data Sampling | . | . | . | Software-Hardware Contract | . | . | Hardware-Software Contracts for Secure Speculation | ARM. DIT, Data Independent Timing | Intel. Data Operand Independent Timing Instruction Set Architecture (ISA) Guidance | FaCT: A DSL for Timing-Sensitive Computation | Secure, Precise, and Fast Floating-Point Operations on x86 Processors | BearSSL. Constant-time Crypto | . | . | . | Side-Channel Mitigations | . | . | Hardware-Software Contracts for Secure Speculation | Branch History Injection: On the Effectiveness of Hardware Mitigations Against Cross-Privilege Spectre-v2 Attacks | InvisiSpec: Making Speculative Execution Invisible in the Cache Hierarchy | Speculative interference attacks: breaking invisible speculation schemes | . | . | . | Physical Attacks | . | 6.191 [6.004] L01 The Digital Abstraction | 6.191 [6.004] L06 Sequential Circuit | The Hardware Hacking Handbook* (Chapter 1, 5, 8, 13; The whole book includes many practical tips on how to carry out physical attacks by yourself) | Hacking the Xbox | . | . | Power Analysis Attacks: Revealing the Secrets of Smart Cards. 2007* | Building a high-performance, programmable secure coprocessor. 1999 (Section 4) | . | . | Talk on Supply Chain Attacks &amp; Verifiability | . | . | Rowhammer Attacks | . | Memory systems: cache, DRAM, disk.* (Chapter 10 DRAM Memory System Organization) | . | . | Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors | Flip Feng Shui: Hammering a Needle in the Software Stack | CLKSCREW: Exposing the Perils of Security-Oblivious Energy Management | Hertzbleed: Turning Power Side-Channel Attacks Into Remote Timing Attacks on x86 | The Story of Rowhammer - Keynote at Secure Hardware, Architectures, and Operating Systems Workshop (SeHAS) at the HiPEAC 2021 Conference | . | . | Exploiting the DRAM rowhammer bug to gain kernel privileges. Google Project Zero | . | . | Rowhammer Mitigation + Reliability Solutions | . | . | Graphene: Strong yet Lightweight Row Hammer Protection | REGA: Scalable Rowhammer Mitigation with Refresh-Generating Activations | Hydra: Enabling Low-Overhead Mitigation of Row-Hammer at Ultra-Low Thresholds via Hybrid Tracking | Revisiting Residue Codes for Modern Memories | OpenTitan Website | OpenTitan Github | OpenTitan Talk in CHES 2022 | . | . | . | Hardware Security Module (HSM) | . | Intel SGX Explained (Section 3.1-3.3, 4.1, 4.4-4.5) | Principles of Secure Processor Architecture Design* (Chaper 5 Hardware Root of Trust) | . | . | Building the IBM 4758 Secure Coprocessor. 2001 | Apple Platform Security (Page 5-96) | . | . | . | Hardware Support for Software Security | . | SoK: Eternal War in Memory | . | . | Smashing the Stack for Fun and Profit | An Introduction to CHERI | The Arm Morello Board | Virtual memory primitives for user programs. 1991 | Memory protection keys | Qualcomm. Pointer Authentication on ARMv8.3 Design and Analysis of the New Software Security Instructions | Armv8.5-A Memory Tagging Extension | Intel. Control-flow Enforcement Technology Specification (Section 1-3) | Control-flow integrity principles, implementations, and applications. 2005 | . | . | xkcd. HeartBleed Explanation | . | . | Fuzzing and Bug Finding | . | . | Computational aspects of the Pentium affair. 1995 | Fuzzing Hardware Like Software | SPECS: A Lightweight Runtime Mechanism for Protecting Software from Security-Critical Processor Bugs | Bug Attacks | HardFails: Insights into Software-Exploitable Hardware Bugs | The Art, Science, and Engineering of Fuzzing: A Survey | Branch History Injection: On the Effectiveness of Hardware Mitigations Against Cross-Privilege Spectre-v2 Attacks | SiliFuzz: Fuzzing CPUs by proxy | . | . | Breaking the x86 Instruction Set. BlackHat | Intel Pentium FPU glitch. 1994 | A Stitch In Time Saves Nine: A Stitch In Time Saves Nine: A Case Of Multiple OS Vulnerability | Riding the Fuzzing Hype Train (RAID'21 Keynote) | . | . | Formal Verification for Hardware Security | . | . | The Complexity of Theorem-Proving Procedures. 1971 | A Machine Program for Theorem-Proving. 1962 | GRASP: A Search Algorithm for Propositional Satisfiability. 1999 | End-to-End Verification of ARM Processors with ISA-Formal. 2016 | . | . | . | Trusted Execution Environment (TEE) | . | Intel SGX Explained (Section 5 SGX Programming Model) | . | . | SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments | AMD Secure Encrypted Virtualization (SEV) | Protecting VM Register State With SEV-ES | AMD SEV-SNP | Keystone: An Open Framework for Architecting Trusted Execution Environments | RISC-V Privileged Instructions (Section 3.6) | Arm Confidential Compute Architecture (Arm Website) | Intel Trust Domain Extensions (TDX) | . | . | . ",
    "url": "/2026/lectureReadings.html",
    "relUrl": "/lectureReadings.html"
  },"59": {
    "doc": "Paper Discussion",
    "title": "Paper Discussion",
    "content": "In each discussion session, we will discuss 5 papers around one particular topic. The discussion of each paper will be led by 2 students (who take the graduate version of the course, i.e., 6.5950). Throughout the semester, each student will only lead the discussion once. The papers to be discussed are selected from top security and computer architecture conferences, covering broad hardware security topics representing the state of the art. For the presenters, please check Piazza posts for knowing when you will present which paper. As you prepare for the presentation, make sure to refer to our detailed paper reading guidance for how to read a hardware security paper, what is required for the presentation, and how your presentation will be graded. For the audience, we encourage you to pick a paper to read before each discussion session and ask questions during the Q&amp;A of that paper, as well as other papers. Based on the quality of the questions, we will give bonus points toward your final grades. ",
    "url": "/2026/paperDiscussion.html",
    "relUrl": "/paperDiscussion.html"
  },"60": {
    "doc": "Paper Discussion",
    "title": "Papers",
    "content": "Below is a list of papers that were discussed in last year’s offering of the course. We will release the list of papers for this year’s offering on the week of March 17, before spring break. Modern Side-Channel Attacks (April 15) . | Theory and Practice of Finding Eviction Sets . | Port Contention for Fun and Profit . | Hertzbleed: Turning Power Side-Channel Attacks into Remote Timing Attacks on x86 . | Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution . | Phantom: Exploiting Decoder-detectable Mispredictions . | Augury: Using Data Memory-Dependent Prefetchers to Leak Data at Rest . | Opening Pandora’s Box: A Systematic Study of New Ways Microarchitecture Can Leak Private Data . | . Physical Attacks (April 22) . | PThammer: Cross-User-Kernel-Boundary Rowhammer through Implicit Accesses . | RowPress Vulnerability in Modern DRAM Chips . | ProTRR: Principled yet Optimal In-DRAM Target Row Refresh . | CLKSCREW: Exposing the Perils of Security-Oblivious Energy Management . | SRAM Has No Chill: Exploiting Power Domain Separation to Steal On-Chip Secrets . | One Glitch to Rule Them All: Fault Injection Attacks Against AMD’s Secure Encrypted Virtualization . | Pentimento: Data Remanence in Cloud FPGAs . | . Hardware Support for Software Safety (April 27) . | The CHERI capability model: Revisiting RISC in an age of risk . | PACMem: Enforcing Spatial and Temporal Memory Safety via ARM Pointer Authentication . | Secure Program Execution via Dynamic Information Flow Tracking . | Leaky Cauldron on the Dark Land: Understanding Memory Side-Channel Hazards in SGX . | Speculative Probing: Hacking Blind in the Spectre Era . | WHEN GOOD KERNEL DEFENSES GO BAD: Reliable and Stable Kernel Exploits via Defense-Amplified TLB Side-Channel Leaks . | SecureCells: A Secure Compartmentalized Architecture . | . Fuzzing and Formal Verification (April 29) . | SiliFuzz: Fuzzing CPUs by Proxy . | Cascade: CPU Fuzzing via Intricate Program Generation . | SpecDoctor: Differential Fuzz Testing to Find Transient Execution Vulnerabilities . | SPECS: A Lightweight Runtime Mechanism for Protecting Software from Security-Critical Processor Bugs . | Revizor: Testing Black-Box CPUs against Speculation Contracts . | Complete Information Flow Tracking from the Gates Up . | Security Verification of Low-Trust Architectures . | . ",
    "url": "/2026/paperDiscussion.html#papers",
    "relUrl": "/paperDiscussion.html#papers"
  },"61": {
    "doc": "Paper Readings Guidance",
    "title": "How to read a research paper?",
    "content": "We believe learning how to read a research paper is an important component of this class. There exists many materials describing how to read a paper. The following two recommended readings discussed a “three-pass approach”, and talked about what questions you should think about while reading a research paper. If you have never read a research paper before, we suggest you go through these two articles first to get a rough idea of how to approach a paper. They also provide useful note-taking tips. References . | How to Read a Paper; S. Keshav; ACM SIGCOMM Computer Communication Review; 2007. | How to Read an Engineering Research Paper; William G. Griswold. | . We provide an adapted and succinct version of how to read a hardware security paper for the SHD course below. The first pass: . For your first pass, read the following items and skip the others: . | Title and abstract | The introduction section | Section and subsection titles (just the titles, not the content) | Related work section and the conclusion. | . After this pass, you should be able to answer the following questions: . | Category: What type of paper is this? Is it an attack paper, a defense paper, or an analysis paper? | Context (background and related work): . | We might have discussed some background materials in class. Try to think about whether there exists any background gap for the other students in the class to understand this paper: what background materials we have NOT covered which you have to include in your presentation. | Get an idea about existing work that this paper relates to. This step is to get you prepared for critical thinking of this paper. If it is an attack paper, what are the other existing attacks that target the same threat model? If it is a defense paper, what are the other existing defenses that share a similar security goal as this paper? | . | Contributions: What are claimed as the paper’s main contributions? | . The second pass: . Read the paper with greater care, but ignore details such as proofs. The goal is to grasp the main content of the paper. Here are a few tips on how to zoom in. | Look carefully at the figures, diagrams, and other illustrations in the paper. If you can thoroughly understand the important figures in the main section, you are on the right track. If you find things are fuzzy, you will then need to read the text that explain these figures/diagrams multiple times to decipher the content. | A useful tip is to look for videos related to this paper online (sometimes conferences post lightning talks or full talks of the accepted papers on Youtube or conference websites). Observe how the authors explain their work. This will help you understand the key contributions better. Moreover, seeing how the idea being presented in a different format other than pure text will help you structure and design your presentation slides. Just be aware that, conference presentations usually focus on highlighting the contributions, and rarely talk about limitations of the work. | . As you read through the paper, attempt to answer the following questions (from Griswold’s article and adapted for hardware security papers): . | What are the background and motivations for this work? Put the work into context, try to relate to materials that we have covered in class, fill any knowledge gap that is needed for your classmates to understand the work. | What is the proposed idea of this paper? Here it is very important for you to distinguish between high-level ideas and implementation details. Within the limited amount of presentation time, you need to pick the key components of the idea proposed by this paper and focus on the most important things to share with your fellow classmates. | What is the work’s evaluation of the proposed solution? What argument, implementation, and/or experiment makes the case for the value of the ideas? It should be roughly easy to identify the evaluation section and read through what the authors did to validate their idea. | What are future directions for this research? What questions are you left with? What is your take-away message from this paper? . | We recommend the students try to connect the paper with their own background (if any) | We like to hear critiques from the students. Last year, a team did their presentation by almost toasting the paper for 10 minutes. We (the course staff and the students) all enjoyed that presenation a lot. Unfortunately, we cannot share the recording of that particular presentation with you. | . | . The third pass (optional for this course): . | The key to the third pass is to attempt to virtually re-implement the paper: that is, making the same assumptions as the authors, re-create the work. By comparing this re-creation with the actual paper, you can easily identify not only a paper’s innovations, but also its hidden failings and assumptions. This is usually needed when you are reviewing the paper as a program committee member. | You should identify and challenge every assumption in every statement. During this pass, you should also jot down ideas for future work. | . ",
    "url": "/2026/paperReadingGuidance.html#how-to-read-a-research-paper",
    "relUrl": "/paperReadingGuidance.html#how-to-read-a-research-paper"
  },"62": {
    "doc": "Paper Readings Guidance",
    "title": "How will we run the discussion session?",
    "content": "During each paper discussion session, we will keep track of the time for each paper. If you run out of time, you will be interrupted and end up not finishing your presentation. So make sure to practice your presentation ahead of time. | Presentation: 10 min . | Paper summary (motivation, proposed idea, evaluation): ~7 min | Paper critiques (strengths, weaknesses, your thoughts, your thoughts on future work): ~3 min | . | Class Q&amp;A: 2 min | . Timing is very tight – please come to class on time! . ",
    "url": "/2026/paperReadingGuidance.html#how-will-we-run-the-discussion-session",
    "relUrl": "/paperReadingGuidance.html#how-will-we-run-the-discussion-session"
  },"63": {
    "doc": "Paper Readings Guidance",
    "title": "How will your presentation be graded?",
    "content": "Now comes what you care the most, i.e., how we will grade the presentation. First, let’s clarify the grading procedure. Your presentation will be rigorously graded by four persons: the instructors and the three TAs. Every judge’s score weights equally. The average score will be your final grade. Second, we look for three aspects of the presentation. | Your understanding of the paper, based on the content of your slides. | The clarity of the explanation for technical concepts and details, based on the design of your slides. | The oral presentation quality. | . The judges will give letter grades for items 1 and 2. The letter grades are S, A, B, D. | S: spectacular, award level | A: good, but not impressive | B: fair, can be improved | D: I do not think the presenters put much efforts into it… | . The final grade is computed by multiplying the score for the slide content and the score for the design of slides. As such, if you put enough efforts in understanding the paper and putting together the slides, you should get a satisfying score. You may notice that we do not count item 3 (the oral presentation quality) into your grade. The reason is that we want the paper discussion session to be a welcoming environment for the students to practice public speech and learn from each other. We understand that some students may be shy, and international students might have some language barriers. Therefore, the course staff have made the decision to not include the oral part into grading. Instead, we will give out some small prizes (which has nothing to do with course grades) to award excellent presentations. ",
    "url": "/2026/paperReadingGuidance.html#how-will-your-presentation-be-graded",
    "relUrl": "/paperReadingGuidance.html#how-will-your-presentation-be-graded"
  },"64": {
    "doc": "Paper Readings Guidance",
    "title": "Content of Slides (Understanding the paper)",
    "content": "We have the following requirements for the content of the slides. | Background and motivation: the presentation should include sufficient background for the audience to understand the technical content. Try to connect to the materials that we have covered in class. Fill in any knowledge gap. | Key contribution: the presentation should provide an intuitive high-level summary of the key contributions, assited with illustrative examples/explanations to guide the audience to thoroughly understand the proposed techniques. A good presentation should pick out the most important things and spend sufficient time going through to convey the concepts or techniques to the audience. | Evaluation: summarize the main evaluation results, explain why the authors can get such results, and highlights important takeaway messages. | Critiques: comment on the strengths and weaknesses of the paper, focusing on the technical aspects. | . ❌ What should you avoid when summarizing a paper? . We have collected a few bad examples so you can also check to makes sure to avoid these pitfalls. Background and motivation: . | Delve into the main contribution directly without providing the background of the work. The audience is left clueless about why the authors even need to pay the efforts to write this paper. | Forget to explain some important terminology or acronym, since you are too familiar with them as your spend a few hours reading the paper. But your classmates have not read the paper, so they will be confused throughout the presentation if you repeately use terms they can only guess the meaning of. | . Key contribution: . | In the slide, copy the concise and high-level description the authors put in the introduction section or the first paragraph of the main section, without providing extra explanation of what this sentence mean. | Try to cover content from every section in the paper. This is not feasible. Note these technical papers are usually dense, and no one can have the capability to digest a 12-page paper within 10 minutes. Often, less is more. So you need to spend a lot of time carefully thinking and picking which sections should be included in your presentation. | Refer to undefined terms. Sometimes the authors may want to come up with fancy names or acronomy for some components of their design or technique. You should not indulge yourself to use them freely, meaning mentioning them without providing a definition, since your classmates will get lost. Overall, the articulation of the proposed technique should be self-contained. | Show a pseudocode or a figure without explaining what the setup is and what this code/figure does. A useful thumb of rule is that, anything you decide to include in the slides, you should talk through them so the audience can fully grasp what they mean, rather than “oh… the only impression I have is that there are some code…” | . Evaluation: . | Go through every figure/plot in the evaluation section. This is not a good idea, since not all the evaluation results matter equally. Most of these papers went through a tough peer review process, where the reviewers may suggest extra experiments for the authors to further validate the design to make the paper more complete. You need to pick the important ones to present. | Only present the results without explaining why the authors obtain the results, how the results support the contributions of the papers, and what lessons we can learn from these results. | . Critiques: . | The paper is not well written. This is not a very useful comment for the audience since they will not read the paper. Better to focus on technical comments. | . ",
    "url": "/2026/paperReadingGuidance.html#content-of-slides-understanding-the-paper",
    "relUrl": "/paperReadingGuidance.html#content-of-slides-understanding-the-paper"
  },"65": {
    "doc": "Paper Readings Guidance",
    "title": "Design of Slides (Explaining the paper)",
    "content": "We provide the following excellent examples for your inspiration. Both teams won the TA-chosen presentation awards in prior years. What you can easily see from the videos is that both teams leveraged figures and animations to assist the concepts they try to convey. | LLC is Practical by Baltasar Dinis and Rem Yang (slides, video) | Flip Feng Shui by Daniël Trujillo (slides, video) | . To help you prepare your presentation, we also provide a few bad examples crafted by the TAs. | SRAM Has No Chill (slides) | HertzBleed (slides) | . ",
    "url": "/2026/paperReadingGuidance.html#design-of-slides-explaining-the-paper",
    "relUrl": "/paperReadingGuidance.html#design-of-slides-explaining-the-paper"
  },"66": {
    "doc": "Paper Readings Guidance",
    "title": "Paper Readings Guidance",
    "content": " ",
    "url": "/2026/paperReadingGuidance.html",
    "relUrl": "/paperReadingGuidance.html"
  },"67": {
    "doc": "Recitations",
    "title": "Recitations",
    "content": "Here are some resources for our various recitation activities throughout the semester. ",
    "url": "/2026/recitations.html#recitations",
    "relUrl": "/recitations.html#recitations"
  },"68": {
    "doc": "Recitations",
    "title": "CTF of C Programming",
    "content": "Capture the flag competition to solve some beginner/advanced C and C++ language problems. ",
    "url": "/2026/recitations.html#ctf-of-c-programming",
    "relUrl": "/recitations.html#ctf-of-c-programming"
  },"69": {
    "doc": "Recitations",
    "title": "Cache Attack",
    "content": "The research paper (and slides) behind the Website Fingerprinting Lab, guidance on paper presentation in discussion sessions, and walking through the cache organization of our lab machine (Figure 1&amp;2 in this paper). ",
    "url": "/2026/recitations.html#cache-attack",
    "relUrl": "/recitations.html#cache-attack"
  },"70": {
    "doc": "Recitations",
    "title": "Recitations",
    "content": " ",
    "url": "/2026/recitations.html",
    "relUrl": "/recitations.html"
  },"71": {
    "doc": "Rowhammer",
    "title": "Rowhammer Lab",
    "content": "Due Date: Apr 2; Last Updated Date: Feb 18 . ",
    "url": "/2026/labs/rowhammer.html#rowhammer-lab",
    "relUrl": "/labs/rowhammer.html#rowhammer-lab"
  },"72": {
    "doc": "Rowhammer",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 0: Lab Infrastructure . | Debug HTCondor | . | Part 1: Bridging the Virtual and Physical Address Spaces (10%) . | Translating Virtual to Physical Addresses | Translating in the Other Direction | . | Part 2: DRAM Geometry - Finding Bank Conflicts (20%) | Part 3: DRAM Geometry - Bank XOR-Function (20%) . | The XOR Bank Mapping Function | . | Part 4: It’s Rowhammer Time! (20%) | Part 5: Mitigation using Error Correcting Codes (30%) . | Understanding ECC: Types and Design Choices | Implementing ECC: Hamming(22,16) | . | Behind the Scene: How this lab infrastructure was developed? | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . You will complete this lab primarily in C and C++. Refer to the recitation materials if needed. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to Gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2026/labs/rowhammer.html#table-of-contents",
    "relUrl": "/labs/rowhammer.html#table-of-contents"
  },"73": {
    "doc": "Rowhammer",
    "title": "Introduction",
    "content": "In this lab, you will complete two tasks: . | Mount a Rowhammer attack on a real machine, taking the theory we learned in class to practice. | Study what we can do to protect against Rowhammer. | . To begin, imagine DRAM as a matrix of cells. The core of Rowhammer is to access the cells that are adjacent to each other in a specific pattern. In lecture, we studied how to design a reasonable access pattern to perform double-sided Rowhammer, and you may think the attack sounds easy to pull off. Unfortunately, it is not. The most tricky part of the attack is dealing with address translations, and figuring out how exactly we can access the bit cells needed. Note that all the addresses that a programmer (e.g., you) can manipulate are virtual addresses, which need to be translated to physical addresses, and then to DRAM cell coordinates. Virtual Address → Physical Address → DRAM Cell Coordinate . Since each step isn’t trivial, we’ve designed the lab to guide you to build your attack step by step, handling one of the translations at a time. At the end of this lab, you will not only have a working Rowhammer attack, but also gain a deeper understanding of the complex addressing mechanism that is widely used in modern systems. ",
    "url": "/2026/labs/rowhammer.html#introduction",
    "relUrl": "/labs/rowhammer.html#introduction"
  },"74": {
    "doc": "Rowhammer",
    "title": "Part 0: Lab Infrastructure",
    "content": "Due to the intrinsic physical requirements of the Rowhammer vulnerability, your experiments will be run on our special lab machines. These machines have been verified to reliably be vulnerable to Rowhammer, and your lab answers will be specific to these machines’ configuration. The experiments also require to exclusively use the whole DRAM. To achieve this, we will use HTCondor to time-shared the lab machines, running one experiment at a time. You will ssh to unicorn.csail.mit.edu, develop and build your code on it, and use HTCondor on it to remotely launch your code on one of the vulnerable machines (csg-exp{6,7,9} and arch-sec-{5-8}). Note that you will not be directly accessing these vulnerable machines, since this may interfere with another student’s experiments. Configuration . Your assigned machine information has been emailed to you. Before moving past this point, edit launch.condor and update the Requirements line to match the specific machine assigned to you. Make sure you exclude the .csail.mit.edu suffix when filling it. Use HTCondor . You will use HTCondor to launch your attack code, using the following commands to interact with HTCondor: . | ./launch.sh [BINARY FILE]: run the specified binary file bin/[BINARY FILE] on your assigned remote machine. The output will be placed in log/[BINARY FILE].out, and any errors generated by your code will be placed in log/[BINARY FILE].error. | cat log/[BINARY FILE].out: Check the output of your job by opening the corresponding output file. | cat log/[BINARY FILE].error: Print all the errors experienced by your job by opening the corresponding error file. | . Here is an example of using HTCondor to run a program that prints Hello World. $ make $ ./launch.sh part0 Submitting job(s). 1 job(s) submitted to cluster XX. All jobs done. $ cat log/part0.out Hello World! . Before continuing, run the Condor commands as above, and ensure that you can interact with your assigned machine correctly. If things do not work as expected, read the next subsection for debugging tips or reach out to TAs. Debug HTCondor . By default, ./launch.sh will wait for the binary finishing the execution. However, it might hang forever either because the binary itself hangs forever or becuase condor fails to schedule the binary to remote machines. In either case, you can type Ctrl+c to exit from ./launch.sh and using following commands to figure out what’s going wrong: . | condor_q: Check the status of your job, including its ID and its Status. You can see more debugging information with the condor_q -better-analyze [ID] or cat log/[BINARY FILE].log. | condor_rm [ID]: Kill your job specified by the ID. Make sure you killed (or finished) all your jobs before launching new ones. Note that we config Condor to kill your jobs automatically after they have executed for 10 minutes, to allow other students to use the machine. | . Here is an example that Condor cannot schedule a job becuase you forget to fill your machine name into launch.sh. $ make $ ./launch.sh part0 Submitting job(s). 1 job(s) submitted to cluster 6522. ^C $ condor_q -- Schedd: arch-sec-1.csail.mit.edu : &lt;128.30.65.18:9618?... @ 02/19/24 18:42:02 OWNER BATCH_NAME SUBMITTED DONE RUN IDLE TOTAL JOB_IDS shd24-xxx ID: 6522 2/19 18:41 _ _ 1 1 6522.0 $ condor_q -better-analyze 6522 ... No successful match recorded... $ condor_rm 6522 . ",
    "url": "/2026/labs/rowhammer.html#part-0-lab-infrastructure",
    "relUrl": "/labs/rowhammer.html#part-0-lab-infrastructure"
  },"75": {
    "doc": "Rowhammer",
    "title": "Part 1: Bridging the Virtual and Physical Address Spaces (10%)",
    "content": "We start with bridging the gap between the virtual and physical address spaces. Specifically, you will implement two functions: Firstly, a function that translates a virtual address to its corresponding physical address. Secondly, a function translating in the opposite direction, i.e., given a physical address, determining its corresponding virtual address. Code Skeleton . The source code for this lab can be found in src/, and is separated into folders corresponding to different parts of the lab. | src/params.hh: Defines several key parameters, including the size of a hugepage (e.g. 2MB), the size of a DRAM row, etc. | src/verif.hh: Contains declarations for functions which will help you check your solutions, and will be used for grading. The implementation of these functions are in bin/libverif.so. Don’t bother decompiling - the library has been obfuscated so that it will take more effort to reverse engineer than solving as intended! | src/shared.hh and src/shared.cc: Contain functions which are shared across different parts of the lab. You will complete these functions in Part 1. | . You can compile the code by running the command make at the root of the repository, which will create five executable files (part[0-5]) in the bin/ folder. Note that you will need to re-run make each time you change your code to re-compile it. For example, observe the initial behavior of the initial codebase: . $ make $ ./launch.sh part1 Submitting job(s). 1 job(s) submitted to cluster XX. All jobs done. $ cat log/part1.out virt_to_phys test failed! . Before continuing, run make and make sure your codebase compiles successfully and returns the same output as above. Linux’s pagemap interface . The machines in this lab used paged virtual memory (if you need a refresher on this topic, check out 6.191’s (6.004’s) lectures on Virtual Memory 1 and Virtual Memory 2). Linux provides the pagemap interface that allows userspace programs to examine page tables and related information. For a running process, its pagemap can be accessed by reading the file /proc/self/pagemap. This pagemap file is binary-encoded, containing a sequence of 64-bit values. Each 64-bit value corresponds to a virtual page (assuming a page size of 4KB), where the N-th 64-bit value corresponds to the N-th virtual page. The figure below indicates the semantics for each page entry. Example Page Map Entry . Bit 63 indicates whether the page presents in memory or not. If the page is present in memory, Bits 0-54 of the entry is the physical page number (PPN). The remaining (metadata) bits have their own meaning, which are not relevant for this lab. If you’re curious, more information can be found in the corresponding Linux kernel documentation page. Note . As a countermeasure of Rowhammer, /proc/self/pagemap is not allowed to be accessed by non-sudo user since Linux 4.0 (released in 2015). However, we definitely do not want to give you sudo permission on our lab machine! Thankfully (for us), our TA, William Liu, developed a workaround through a kernel module, detailed in the section at the end of this handout. Translating Virtual to Physical Addresses . We can leverage the pagemap interface to perform the virtual address to physical address translation. In the virt_to_phys function in shared.cc, you will translate a given virtual address to its corresponding physical address. You will implement this function assuming the page size is 4KB. At a high-level, your virt_to_phys function will do the following: . | Given a virtual address, derive the address’ virtual page number (VPN). | (provided) Read pagemap to find the corresponding page table entry. | (provided) Extract the physical page number (PPN) from the page table entry. | Compute the physical address from the physical page number (PPN). | . 1-1 Exercise . Complete the virt_to_phys function in src/shared.cc assuming 4KB page size. Test your code by running ./launch.sh part1. You should see virt_to_phys test passed! . When you bit-shift the 55-bit PPN, you may notice that the upper bits cannot fit in a 64-bit address. You can ignore this effect, since the upper three bits of the PPN field are unused on our system. Tips for Programming in C/C++ . | Be cautious when you try to set every bit in a row to 1. You need to pay extra attention to the size of the variable. For example, uint8_t x = 1 means x=8'b00000001, consisting of seven 0s and only one 1s. | When you are writing your code, you may need to convert between integers (uint64_t) and pointers (uint8_t *) and vice-versa. You may find C++’s reinterpret_cast useful in performing these conversions: uint64_t addr = 0xDEADBEEF; // A 64bit integer // Cast the 64bit integer to a pointer volatile uint8_t * addr_ptr = reinterpret_cast&lt;volatile uint8_t *&gt;(addr); uint8_t tmp = *addr_ptr; // Read using the casted pointer . | Throughout your code, we suggest always using uint64_t rather than int, since ints can result in silent overflows when shifted by large values. | Be mindful that the order of operations in C++ may not be what you expect. For instance, a &lt;&lt; 12 - 1 is different from (a &lt;&lt; 12) - 1. If in doubt, use parenthesis. | . Translating in the Other Direction . You will find it handy if you can perform address translation in the opposite direction, from physical to virtual addresses. The idea is to construct a reverse page table, i.e., a map that records the mapping relationship from physical page numbers (PPN) to virtual page numbers (VPN). In shared.cc, PPN_VPN_map serves as the reverse page table. It is a dictionary implemented using C++’s std::map syntax, with physical page numbers as keys and virtual page numbers as values. For more information related to C++ and examples of how to use the std::map object, refer to the recitation materials. Your task is to complete the function setup_PPN_VPN_map (in shared.cc) to populate the PPN_VPN_map data structure. You can assume the page size is 2MB as opposed to 4KB. The populated reverse page table should cover a 2GB region following the pointer mem_map. 1-2 Discussion Question . In a 64-bit system using 4KB pages, which bits are used to represent the page offset, and which are used to represent the page number? . How about for a 64-bit system using 2MB pages? Which bits are used for page number and which are for page offset? . In a 2GB buffer, how many 2MB hugepages are there? . Demystifying 2MB vs. 4KB Page Sizes . You are asked to use 4KB page to probe the pagemap interface, but 2MB page to build the reverse page table. You may wonder – why do we use inconsistent page sizes and will it not introduce bugs? . In our setup, we ask the OS to give us the 2GB region using hugepages (2MB page size) inside the allocate_pages function. We use hugepages to simplify the address translation step (using 2MB pages allows us to more easily determine the DRAM bank of an address later on in this lab). The pagemap interface is designed, however, to assume 4KB pages, with each 64-bit entry corresponding to one 4KB page. As we know that for address translation, we take the VPN and translate it to PPN, but keep the page offset unchanged. So a virtual address and its corresponding physical address always have the same page offset. When considering 2MB and 4KB pages, we can consider a 2MB page to consist of 512 4KB pages. For these 4KB pages, the lower 9 bits of their VPNs are counted as page offset for a 2MB page. Therefore, when being translated between virtual and physical address, these 9 bits do not need to be changed. One quirk with C++ maps is that C++ will return 0 (i.e., NULL) instead of throwing an error if you try to retrieve a value which isn’t in the map. You can force an exception with .at. You will only encounter addresses with non-zero virtual page numbers in this lab, so you may want to check for lookups which return zero! . 1-3 Exercise . Complete the setup_PPN_VPN_map function in src/shared.cc to populate the reverse page table. Test your code by running ./launch.sh part1. You should see PPN_VPN test passed! . 1-4 Exercise . Complete the phys_to_virt function in src/shared.cc: given a physical address, determine its corresponding virtual address. You will need to use the reverse page table PPN_VPN_map that you have constructed. Test your code by running ./launch.sh part1. You should see phys_to_virt test passed! . Submission and Grading . Relevant files to submit to GitHub: src/shared.cc . ",
    "url": "/2026/labs/rowhammer.html#part-1-bridging-the-virtual-and-physical-address-spaces-10",
    "relUrl": "/labs/rowhammer.html#part-1-bridging-the-virtual-and-physical-address-spaces-10"
  },"76": {
    "doc": "Rowhammer",
    "title": "Part 2: DRAM Geometry - Finding Bank Conflicts (20%)",
    "content": "Part 2-3 and Part 4 of this lab have no dependencies between each other. If you want to build up to the setup behind a Rowhammer attack, proceed in the lab order. If you want to flip bits, proceed to Part 4. To perform Rowhammer in real life on a specific victim row, you would have to locate attack rows by reverse engineering the physical address to DRAM coordinate mapping. Note that adjacent rows of memory might not be a constant stride apart in the physical memory space. Why is this the case? . This added complexity is introduced due to the geometry of the DRAM. Consider a DRAM coordinate of a bit cell is a tuple of &lt;DIMM id, Channel id, Rank id, Bank id, Row id, Column id&gt; (see details in the lecture slides). Recall that for two rows to be physically adjacent to one another in a DRAM chip, they must have the same &lt;DIMM id, Channel id, Rank id, Bank id&gt;, and their &lt;Row id&gt; should differ by 1. In most DRAMs, each of the &lt;DIMM id, Channel id, Rank id, Bank id&gt; is derived by XORing a selection of bits from the physical address. These XOR functions, i.e., which bits are used to perform the XOR operation, are proprietary information and are not typically provided by CPU vendors. In our lab machines, the &lt;DIMM id, Channel id, Rank id&gt; are determined by higher bits and the addresses in a 4GB region share the same of these ids. Our lab machines have 16 banks, making the &lt;Bank id&gt; a 4-bit value. Each bit in these 4 bits is computed by XORing some of the bits 13-16 with some of the bits 17-20. The bits involved in the derivation of the &lt;Row id&gt; and &lt;Bank id&gt; are listed below and also visualized in the figure. | &lt;Row id&gt;: bits 17-31 | &lt;Column id&gt;: bits 0-12 | &lt;Bank id&gt;: (unknown) each bit comes from XORing some of bits 13-16 (the exact number of bits being XORed can range from 0 to 4) with some of bits 17-20 | . Physical address bits involved in Row/Bank ID generation . 2-1 Discussion Question . Given a victim address 0x752C3000, what is the value of its &lt;Row id&gt;? The value of its &lt;Column id&gt;? . For this same victim address, when the exact XOR function being used for computing the &lt;Bank id&gt; is unknown, list all possible attacker addresses that stays in the row below the victim address (i.e., the attacker’s &lt;Row id&gt; is 1 more than the victim’s) while sharing the same &lt;Column id&gt; and &lt;Bank id&gt;. Hint: there should be 16 such addresses total. Bank-conflict Side Channel . How can we determine whether two addresses map to the same bank or not without knowing the proprietary XOR function? The answer is to use our favorite tool in 6.5950: timing side channels! . As discussed in the lecture, a DRAM bank can only serve one memory request at a time, but multiple accesses to different banks can be served simultaneously, allowing for bank-level parallelism. So, if you issue two memory requests to the same bank back-to-back, one of the requests needs to wait for the other to complete before being served, resulting in longer latency - this is known as a row buffer conflict. In contrast, if the two memory requests target two different banks, they can be served in parallel, resulting in a shorter latency. Here are two possible timing strategies you might consider employing: . | Detecting row buffer conflicts: Given two physical addresses x and y, make sure both of the addresses are not cached. First, access address x from DRAM (filling the row buffer with x’s row). Next, access address y from DRAM, which will close the row buffer opened by x if it maps to the same bank. Finally, access address x again from DRAM and measure its access latency (making sure it was flushed from the cache beforehand). If x and y are mapped to the same bank but different rows, then this access will result in a row buffer miss and should take a longer time to complete. | Detect bus contention and row buffer conflicts: Given two physical addresses x and y, again make sure both of the addresses are not cached. Access the two addresses back-to-back without memory fences in between and measure their collective access latency. If the two addresses are mapped to the same bank and different rows, they will cause memory bus contention in addition to row buffer conflicts, and thus will result in even longer latency. | . 2-2 Exercise . In src/shared.cc implement measure_bank_latency, which measures a (potential) bank collision between two addresses. The staff-provided main function in part2.cc will call your measure_bank_latency with two different address pairs. The first address pair will map to the same bank, and the second address pair will map to different banks. 2-3 Discussion Question . Report the statistics produced by your code when running part2, and describe how you can use the difference in these statistics to distinguish between the pairs. Note that you can toggle between using the print_results and print_to_json functions for the final statistical results, and you can toggle the number of SAMPLES. Submission and Grading . Relevant files to submit to GitHub: src/shared.cc . ",
    "url": "/2026/labs/rowhammer.html#part-2-dram-geometry---finding-bank-conflicts-20",
    "relUrl": "/labs/rowhammer.html#part-2-dram-geometry---finding-bank-conflicts-20"
  },"77": {
    "doc": "Rowhammer",
    "title": "Part 3: DRAM Geometry - Bank XOR-Function (20%)",
    "content": "The XOR Bank Mapping Function . Since you can now determine whether two addresses are mapped to the same bank, you can reverse engineer the bank mapping function by completing the last two steps: 2) collecting a large number of addresses and binning them into multiple groups so that the addresses in the same group are mapped to the same bank; 3) trying all possible bank mapping functions to find one that does not violate your binning results. To make the lab easier, instead of asking you to search the entire possible function space via brute force or perform some form of statistical analysis, we will give you 3 candidate functions and ask you to figure out which one is correct. The 3 candidate functions for constructing the Bank ID are listed below (assuming 0-indexing on an address A): . F0: {A16 ^ A18, A13 ^ A19, A15 ^ A18, A14 ^ A20} F1: {A15 ^ A19, A14 ^ A18, A13 ^ A17, A16 ^ A20} F2: {A13 ^ A18, A14 ^ A17, A16 ^ A19, A15 ^ A20} . Our approach to solving this is the following . | Allocate a large memory region by calling function allocate_pages. | Select many addresses that are mapped uniformly across different rows. You want to be careful with the stride such that you hit the banks uniformly | Bin these addresses into 16 groups where each group corresponds to one bank in the function bin_rows. You will need to use the function measure_bank_latency and the threshold (the THRESHOLD) you have derived. | Compute the bank ID of all the addresses using each of the candidate functions and check whether the computed bank IDs for the addresses in the same group are consistent or not. We provided most of the statistical analysis code already, but feel free to adjust them if needed. We recommend that you just fine-tune the CONSISTENCY parameter (more on this later). | . If the correct function is chosen, the computed bank ids for the addresses in the same group should be the same. However, there may exist some noise in the binning process, and you may observe that the binning results are not 100% accurate. Therefore, you should check the ratio of addresses that have a consistent bank ID in each group. We define the consistency rate as the proportion of addresses in a bin which map to the most common bank ID in that bin. For instance, if a 4-element bin has addresses mapping to banks [1,1,3,1], the consistency rate of that bin is 75%. Generally, when using the correct mapping function, the consistency rate should be at or above 98%, as around 98% of the addresses in the same group will have the same bank id, with the remaining 2% having different bank ids. 3-1 Exercise . Implement bank ID binning with bin_rows. The rest of the analysis code is already completed for you, but you can make modifications if you really want to. Make sure that the correct function index is printed in the end. 3-2 Discussion Question . Based on the XOR function you reverse-engineered, determine which of the 16 candidate addresses you derived in Discussion Question 2-1 maps to the same bank. The XOR function can also be reverse-engineered via other types of timing side channels. If curious, you can read DRAMA to see how this can be done. Submission and Grading . Please remove any extra print statements added. We will deduct two points for extra print statements. Do not remove the print statements provided at the start of the lab. Relevant files to submit to GitHub: src/part3/part3.cc . ",
    "url": "/2026/labs/rowhammer.html#part-3-dram-geometry---bank-xor-function-20",
    "relUrl": "/labs/rowhammer.html#part-3-dram-geometry---bank-xor-function-20"
  },"78": {
    "doc": "Rowhammer",
    "title": "Part 4: It’s Rowhammer Time! (20%)",
    "content": "As we mentioned before, to make Rowhammer work, we need to manipulate addresses to go through two translation steps: Virtual Address → Physical Address → DRAM Coordinates. The previous part of the lab teaches you on how to reverse engineer the second translation step. In the real world, you would then utilize that to start finding victim and attacker rows. However, in past years, we find that students experience a lot of instability and unnecessary grunt work when sent off to discover their own addresses. To save your efforts, we have pre-profiled the lab machines and located victim and attacker rows, and we directly provide the physical addresses of the startings of these rows to you (see table below, as well as file src/part4/part4.cc). With these information, you can use your reverse page table PPN_VPN_map to find the corresponding virtual addresses. Your task in this part is to implement a double-sided Rowhammer attack and try the attack on these addresses. | Victim | Row Above (A) | Row Below (B) | Distant Row (C) | Same Row ID, Diff. Bank (D) | . | 0x75380000 | 0x753A2000 | 0x7536E000 | 0x75308000 | 0x75382000 | . Attack Outline . You will implement the Rowhammer attack strategy inside the hammer_addresses function (in src/part4/part4.cc). The main function (in part4.cc) contains code to call your hammer_addresses function to perform the attack, collect statistics and report the number of observed bitflips. You should not modify the main function. Getting Rowhammer to work can be quite tricky. When writing your code in C/C++, you have to think very carefully about what DRAM operations will be triggered by the code and what cells are being accessed with your code. For our specific DRAM configuration, a row is of size 2^13 = 8KB and its physical address is aligned at 8KB. Here is a high-level description of the attack you will implement. | Prime the victim and attacker rows. Set the victim row to all 0’s, and set the attacker rows to all 1’s. | Theoretically, Rowhammer works when we access neighboring rows with a specific pattern and should work regardless of the content inside the attacker and victim rows. However, according to prior work, setting the attacker’s rows to all 1’s and victim’s row to all 0’s can result in a higher probability of triggering bitflips. | When priming rows, ensure that you’re writing the values to the entire row, and not priming outside of row boundaries. If you’re observing bit-flips in your victim row 100% of the time, it is likely that you accidentally wrote 1’s to the victim row when you meant to prime the attacker row. | . | Hammer two rows, repeatedly alternatively accessing two attack rows in DRAM 5 million times. | To access a row, you only need to access one address belonging to that row. Think about how the row buffer works. | Once you access a row, it will be fetched in the cache and later accesses will hit the cache. Thus, you will need to come up with a way to ensure that accesses to these two rows always reach DRAM. | . | Probe the victim row, compare the read results with the primed values (aka, all 0’s), and check whether any bit in the row has been flipped to a 1. | It can be tricky to determine whether a bitflip is observed due to an implementation bug or the actual Rowhammer effect. You should test your code to make sure that without the hammering step (e.g., only priming), the probe observes no bitflips. | . | . 4-1 Exercise . Complete the hammer_addresses function in src/part4/part4.cc. The main function in part4.cc will use hammer_addresses to hammer 3 attacker row pairs (i.e., A/B, A/C, and A/D, the address of A, B, C, and D are showned in the table above) 100x, and report how often the attack succeeds (i.e. observes at least one bit flip in the victim row). If you setup rowhammer correctly, you should achieve an extremely high rate of bitflips for one hammering configuration. If you aren’t experiencing this, consider that you might have to clean up something in the memory hierarchy after the priming step. 4-2 Discussion Question . Include the bitflip observation statistics in the table below. Then answer the following questions: . Do your results match your expectations? Why might some attacker pairings result in more flips than others? Do you expect any of the pairs to never cause a flip? . | Hammering Pairs | A/B | A/C | A/D | . | Number of Successes (100 trials) |   |   |   | . Submission and Grading . Relevant files to submit to GitHub: src/part4/part4.cc. ",
    "url": "/2026/labs/rowhammer.html#part-4-its-rowhammer-time-20",
    "relUrl": "/labs/rowhammer.html#part-4-its-rowhammer-time-20"
  },"79": {
    "doc": "Rowhammer",
    "title": "Part 5: Mitigation using Error Correcting Codes (30%)",
    "content": "Now that we’ve learned how to cause bit-flips in the wild, let’s now explore a potential defense to Rowhammer: Error Correcting Codes (ECC). Error correcting codes, as the name suggested, can help correct errors. More precisely, they are encoding schemes that add redundancy to stored data and use the redundancy to detect and correct errors when they occur. There exist variety of ECCs with different capabilities and storage overhead. For this part, you do not need to use condor. You can run your code on the unicorn server or simply on your own machine by directly running cd bin and ./part5. libverif.so will be used for verifying your solutions again. Note that you must run it inside the bin directory, otherwise there would be an error while loading shared libraries. Understanding ECC: Types and Design Choices . We study the three most commonly seen ECCs. | Repetition Codes: The simplest code is the repetition code, which duplicates each bit in the data multiple times. | Examples: a 2-repetition code protecting the value 1011 is stored as 1011 1011, and a 3-repetition code would be stored as 1011 1011 1011. | Error detection: straightforward. | . | Single Parity Bit: If we’re concerned about storage overhead, we can detect errors by calculating the parity of the data by XORing the data bits together. | Examples: the parity bit for 1011 is 1, and the parity bit for 1001 is 0. | Error detection: A single bit flip in the data results in the parity bit changing. To detect bit flips, we can re-calculate the corrupted data’s parity and compare it against the previously calculated parity bit stored with the data. If more than one bit flips, this scheme may or may not detect it. | . | Hamming Codes: Hamming codes use multiple parity bits to deal with bit errors. Given a scheme protecting N bits with K parity bits, we call it Hamming(N+K, N). | Examples: The most common Hamming code is Hamming(7,4), i.e., 4 data bits protected by 3 parity bits. A graphical depiction of the parity encoding (p1 to p3) for the 4 data bits (d1 to d4) is shown below. As indicated by the green circle, the first parity bit p1 considers the parity of data bits 1, 2, and 4, and is calculated by XORing d1,2,4 together. Similarly, the purple circle indicates that the second parity bit p2 is calculated by XORing d1,3,4. You can infer how the last parity bit p2 is calculated from the red circle. | Error detection: Within each circle, we can perform the same parity check as in the “Single Parity Bit” scheme. By using parity bits in such an overlapping fashion, the Hamming(7,4) code can detect one or two bit flips (even though it cannot tell exactly how many bits flip). By assuming only one bit flips, it can further correct it. | . Hamming(7,4) Code Example (Source) . | . 5-1 Discussion Question . Given the ECC type descriptions listed above, fill in the following table (assuming a data length of 4). For detection/correction, answer “X” only if it can always detect/correct X number of errors, with no corner case exceptions. For detecting more than 1 error, the scheme is not required to tell exactly how many errors exist. We’ve filled in the first column for you. |   | 1-Repetition (No ECC) | 2-Repetition | 3-Repetition | Single Parity Bit | Hamming(7,4) | . | Code Rate (Data Bits / Total Bits) | 1.0 |   |   |   |   | . | Max Number of Errors Can Detect | 0 |   |   |   |   | . | Max Number of Errors Can Correct | 0 |   |   |   |   | . Implementing ECC: Hamming(22,16) . Let’s try to implement a Hamming coded ECC that is used in real hardware for protecting DRAMs. These ECCs are introduced primarily to defend against soft errors. Hamming(22,16) can correct single errors and detect double errors (SECDED). It uses six parity bits (P0-P5) to protect sixteen data bits (D0-D15). The equations for the first five parity bits (P0-P4) are shown below (and also described on Page 2 of this hardware documentation). P0 = D15 ⊕ D13 ⊕ D11 ⊕ D10 ⊕ D8 ⊕ D6 ⊕ D4 ⊕ D3 ⊕ D1 ⊕ D0 P1 = D13 ⊕ D12 ⊕ D10 ⊕ D9 ⊕ D6 ⊕ D5 ⊕ D3 ⊕ D2 ⊕ D0 P2 = D15 ⊕ D14 ⊕ D10 ⊕ D9 ⊕ D8 ⊕ D7 ⊕ D3 ⊕ D2 ⊕ D1 P3 = D10 ⊕ D9 ⊕ D8 ⊕ D7 ⊕ D6 ⊕ D5 ⊕ D4 P4 = D15 ⊕ D14 ⊕ D13 ⊕ D12 ⊕ D11 . The last parity bit, P5, protects both the data and the other parity bits, and is computed by XOR-ing all of the data bits (D0-D15) and the other parity bits (P0-P4). We refer to P5 as the overall parity bit. To start, implement the parity encoding operation in src/part5/part5.cc. For your convenience, we’ve provided the following helper types/functions in src/ecc.hh: . | struct hamming_struct: A C++ struct which contains a data and parity pair. The bit 0 (i.e., lowest bit) of data is D0, the bit 1 of data is D1, … The bit 0 of parity is P0, the bit 1 of parity is P1, … | struct hamming_result: Stores an error type (one of NO_ERROR/SINGLE_ERROR/DOUBLE_ERROR/PARITY_ERROR) and computed syndrome (explained later). | getBit(data, pos): Returns the value of the bit at position pos within data. | flipBit(data, pos): Flips the bit at position pos within data. | isParityBit(bitNum): Returns whether bitNum corresponds to a parity bit in the Hamming(22,16) encoding. | extractEncoding(encoded): Takes a 22-bit encoded ECC value, and extracts the parity and data bits (returned in a hamming_struct). | embedEncoding(hamming_struct): Takes in a hamming_struct and returns the combined ECC value. | parity_eqs array in part5.cc: Describes the parity equations in an array representation. | . 5-2 Exercise . Complete genParity() to calculate the parity bits (P0-P5) for an input piece of data that needs protection. You should see a message telling you that your parity value is correct when you run ./bin/part5 (make sure to compile your implementation using make!). Now, let’s consider how error detection and error correction are performed in Hamming(22,16). Given a single-bit error, Hamming(22,16) can detect whether the error has happened and locate the bit that has been flipped. Basically, taking a piece of 22-bit value with Hamming(22,16) protection, we can compute something called a syndrome. The encoding scheme is designed so that the syndrome corresponds to the location of the single error. The syndrome is computed by XORing two 5-bit values. The first is the “extracted parity bits” P0-P4 stored in the 22-bit value. The second is the “reconstructed parity bits” P0-P4 from the data bits D0-D15. In addition, an overall parity bit is computed by XORing all 22 bits together. Based on the syndrome and overall parity bit, Hamming(22,16) can detect and correct bit flips in both the data bits and the parity bits. See the table below for detailed information. | Syndrome | Overall Parity | Error Type | Notes | . | 0 | 0 | No Error |   | . | !=0 | 1 | Single Error | Correctable. Syndrome holdes incorrect bit position. | . | !=0 | 0 | Double Error | Uncorrectable. | . | 0 | 1 | P5 Error | P5 is in error and can be corrected. | . 5-3 Discussion Question . When a single bit flip is detected, describe what action should be conducted to correct this error with Hamming(22,16). With all the information above, let’s complete the function findHammingErrors() which takes in an encoded ECC value and determines whether there is an error. This function should return the error type and the syndrome. Finally, complete the function verifyAndRepair() which uses the information gained from findHammingErrors() to determine a good course of action. If there is no error, or an unrecoverable error, verifyAndRepair() should return the original value. If there is a single bit error (including parity errors), verifyAndRepair() returns the data with the error corrected. 5-4 Exercise . Complete findHammingErrors() and verifyAndRepair(). You should see All tests passed! reported. 5-5 Discussion Question . Can the Hamming(22,16) code we implemented always protect us from rowhammer attacks? If not, describe how a clever attacker could work around this scheme. Submission and Grading . Your src/part5/part5.cc will be graded automatically, checked against 5 random inputs. As always, submit your discussion questions as a PDF to Gradescope. ",
    "url": "/2026/labs/rowhammer.html#part-5-mitigation-using-error-correcting-codes-30",
    "relUrl": "/labs/rowhammer.html#part-5-mitigation-using-error-correcting-codes-30"
  },"80": {
    "doc": "Rowhammer",
    "title": "Behind the Scene: How this lab infrastructure was developed?",
    "content": "As you have seen in Part 1, using the virtual to physical addresses mapping information provided by Linux’s pagemap interface is a critial step to make the rowhammer attack work. Without a surprise, this interface has been banned from non-sudo users since Linux 4.0 (released in 2015), as a quick countermeasure against rowahmmer attacks. However, throughout the lab, you are never granted sudo permission on the machine. Then how did you smoothly access this interface during the lab? . This comes from our special setups on the machines: A special kernel module is installed to bypass this permission check. The source code of it can be found in driver folder of the starter code of the lab. And we would be happy to give you a tour on how it is developed – how we navigate through the linux source code, identify the location of the permission check of pagemap interface, and hijack the checking result. Per documentation, one requires CAP_SYS_ADMIN capabilities on Linux to access /proc/self/pagemap. We found this permission check located at Line 1624 of fs/proc/task_mmu.c file in Linux v5.15.97 source code (code here). The code does the permission check using file_ns_capable function and saves the checking result in the show_pfn field of the pm variable (whose type is struct pagemapread). How to force this check to always return true? We could change the Linux source code and recompile it, but we do not want to – It is too muddy to config our lab machines with a Linux kernel fully compiled by ourselves. Instead, we developed the rh_driver kernel module to solve this problem, which can be installed to or uninstalled from Linux easily, while the machine is on. It uses a Linux feature known as kprobes, which allows one to “dynamically break into any kernel routine and collect debugging and performance information non-disruptively”. If we break at when the file_ns_capable function returns, we can change the return value to bypass the permission check. We use two kprobes to achieve this: . | The first kprobe (file_ns_capable_pre function in driver/rh_driver.c) determines whether file_ns_capable function is called for the permission check specifically for our pagemap interface (i.e., is called from Line 1624 of fs/proc/task_mmu.c). It checks whether the return address on the stack is within a threshold range to pagemap_read function and whether the second and third arguments match the code from source. We think this heuristic is good enough. If this check pass, we insert the second kprobe. | The second kprobe (target_post function in driver/rh_driver.c) modifies the return of file_ns_capable function to be true. | . Finally, now you can access /proc/self/pagemap without any additional privileges – exciting for us as course staff, though perhaps less exciting for a student in computer security class. ",
    "url": "/2026/labs/rowhammer.html#behind-the-scene-how-this-lab-infrastructure-was-developed",
    "relUrl": "/labs/rowhammer.html#behind-the-scene-how-this-lab-infrastructure-was-developed"
  },"81": {
    "doc": "Rowhammer",
    "title": "Acknowledgements",
    "content": "Contributors: Peter Deutsch, Miguel Gomez-Garcia, Mengjia Yan, William Liu. ",
    "url": "/2026/labs/rowhammer.html#acknowledgements",
    "relUrl": "/labs/rowhammer.html#acknowledgements"
  },"82": {
    "doc": "Rowhammer",
    "title": "Rowhammer",
    "content": " ",
    "url": "/2026/labs/rowhammer.html",
    "relUrl": "/labs/rowhammer.html"
  },"83": {
    "doc": "Spectre Attacks",
    "title": "Spectre Attacks Lab",
    "content": "Due Date: Mar 12; Last Updated Date: Feb 17 . ",
    "url": "/2026/labs/spectre.html#spectre-attacks-lab",
    "relUrl": "/labs/spectre.html#spectre-attacks-lab"
  },"84": {
    "doc": "Spectre Attacks",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 0: Lab Infrastructure | Part 1: Leaking Kernel Memory via Flush+Reload (20%) | Part 2: Basic Spectre (50%) | Part 3: Advanced Spectre (30%) | Behind the Scene: How this lab infrastructure was developed? | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . To connect via ssh, run ssh username@arch-sec-4.csail.mit.edu. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to Gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2026/labs/spectre.html#table-of-contents",
    "relUrl": "/labs/spectre.html#table-of-contents"
  },"85": {
    "doc": "Spectre Attacks",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Understand how Spectre works across privilege boundaries. | Solve three CTF (capture-the-flag) puzzles with increasing difficulty levels. You will start with implementing the basic Spectre attack. We will then test your understanding of how hardware works by challenging you to implement an advanced Spectre in the last part of this lab. | . ",
    "url": "/2026/labs/spectre.html#introduction",
    "relUrl": "/labs/spectre.html#introduction"
  },"86": {
    "doc": "Spectre Attacks",
    "title": "Part 0: Lab Infrastructure",
    "content": "Interacting with Linux Kernel . The highlight of this lab is that you will implement your own version of the famous Spectre attack and use it to leak secrets from the Linux kernel, across privilege boundaries. It presents a good opportunity for you to understand the existing technique used to isolate kernelspace from userspace. Our virtual address space is divided into the kernelspace and the userspace. Unprivileged application code resides in the userspace as shown in the figure below. There are several restrictions on the userspace code. The userspace code cannot directly access kernelspace data or directly branch into the kernelspace and execute kernel code. For example, the load 0xABCD (a kernelspace virtual address) operation will trigger a page permission check failure, or segmentation fault as reported when running a C program. Similarly, executing the instruction jump 0x1234 will also panic with a segmentation fault. So how can the userspace code interact with the kernelspace and still ensure privilege isolation? The right way is to use kernelspace exposed API interface. When calling a correct kernelspace API, the code jumps to the kernelspace entrypoint (the only place in the kernel allows transition from userspace). The entrypoint code performs tons of work for context switch and then jumps to the requested API function. In our lab infrastructure, we provide a custom Linux kernel module (blue box) sitting in the kernelspace. This kernel module provided a limited interface for userspace code to call into. The module is embedded with vulnerable Spectre gadgets, operates on some secret data (red box), and uses secret data as addresses to access the shared buffer (green box). Read the section at the end of this handout for more details about how the lab infrastructure is designed. Obviously, your code, residing in the userspace, will not be able to directly access the secret buffer in the kernelspace. Fortunately, we know that the kernelspace and userspace code, when they execute, share all the microarchitectural structures. Lab Infrastructure Setup . The Secret . The secret in each part is a string of the form MIT{some_secret_value}. The string can be up to 64 bytes, including the NULL terminator. You can consider the secret complete once you leak the NULL terminator. The characters in the string may NOT be printable ASCII. Your code should be able to leak arbitrary 8-bit secrets byte by byte. Do not make any assumption about the secret other than it is a NULL terminated string of length up to 64 bytes (including the NULL terminator). The secrets will not change from run to run (they are constant for the lifetime of the kernel module). During grading, we may use different secret values to evaluate your implementation. Code Skeleton . | inc/labspectre.h and src-common/spectre_lab_helper.c provide a set of utility functions for you to use. | src-common/main.c is used in all three parts. The main function sets up a shared memory region (shared_memory corresponding to the green box in the figure above) of size SHD_SPECTRE_LAB_SHARED_MEMORY_SIZE bytes, which is shared between the userspace and kernel. It also sets up a file descriptor for communicating with the kernel module. The technique behind this communication is called procfs write handling, detailed in the section at the end of this handout. | inc/labspectreipc.h contains bindings for the interface to the kernel module from userspace. You do not need to understand this, as our provided code handles the communication with the kernel. | part1-src/attacker-part1.c is the file you will modify in Part 1. The method call_kernel_part1 can be used for calling into the kernel module. The code for Part2 and Part 3 follow the exact same pattern. | . Compile, Test, and Autograde . This lab will be autograded. After you hand in your code, we will embed different secret strings in the kernel and rerun your code to see whether it effectively leaks these strings. If your code works reliably with the autograder, you should expect no surprise with your grades. Instructions for compiling the code and running the autograder are below. From the root directory, use make to compile the project. The binaries part[1-3] will be produced in the same directory (run them by calling ./part[1-3]. The results of your code will be printed to the console – on success you should see the secret leaked from kernel memory printed to the console. An example of the expected output is below: . $ ./part1 MIT{part1_secret_value} . You can invoke the autograder with ./check.py X, where X is the part to check. An example of the expected output is below: . $ ./check.py 1 Checking part 1 ... You passed 950 of 1000 runs (95.0%) Success! Good job . You can check all parts at once with make and then ./check.py all . ",
    "url": "/2026/labs/spectre.html#part-0-lab-infrastructure",
    "relUrl": "/labs/spectre.html#part-0-lab-infrastructure"
  },"87": {
    "doc": "Spectre Attacks",
    "title": "Part 1: Leaking Kernel Memory via Flush+Reload (20%)",
    "content": "In this part you will set up a cache-based side channel to leak information from the kernel using Flush+Reload. Get to Know the Victim . The pseudocode for the kernel victim code of Part 1 is shown below. def victim_part1(shared_mem, offset): secret_data = part1_secret[offset] load shared_mem[4096 * secret_data] . The victim function takes a pointer shared_mem and an integer offset as input. Both variables are passed from the userspace and determined by the attacker, e.g., you. The variable shared_mem points to the starting of the shared memory region, the green box in the figure above. First, the code loads a secret byte from a secret array named part1_secret, located inside kernelspace. The byte to leak is chosen by the attacker-controlled offset. When the offset is 0, the first secret byte will be loaded; when offset is 1, the second byte will be loaded, and so on. Next, the victim multiplies the secret byte with 4096 and uses the result as an index into the shared memory array. For example, if the secret data was the character ‘A’ (0x41), then the first cache line of the 0x41’th page in the shared memory region will be loaded into the cache. Your Attack Plan . Recall that the secret is a string up to 64 characters long (including the NULL terminator). The attacker can leak the secret one byte at a time using Flush+Reload. Reuse your attack strategy from the Part 2 in the cache lab here, with the only difference at step 1, that is, the attacker needs to call the victim code to perform the secret-dependent memory access. Without losing generality, we summarize the attack outline for you below. | Flush the memory region from the cache using clflush. | Call the victim method using the desired offset to leak the secret byte. | Reload the memory region, measure the latency of accessing each address, and use the latency to derive the value of the secret. When the value is 0x00 (i.e. NULL), the attack is complete. | . 1-1 Discussion Question . Given the attack plan above, how many addresses need to be flushed in the first step? . Allowed Code . You can define your own helper methods as you desire. You can use any method in inc/labspectre.h as well as the provided methods in part1-src/attacker-part1.c. You should only use the provided call_kernel_part1 method to interact with the kernel module. This function takes three arguments: a file descriptor to the kernel module, a pointer to the shared memory region, and an offset. kernel_fd and shared_memory can be directly passed to this method without modification. The offset for a given invocation is up to you. Build your attack step-by-step: start by leaking one character first, then try to leak the whole string. 1-2 Exercise . Implement the Flush+Reload attack in part1-src/attacker-part1.c to leak the secret string. Build the project with make and run ./part1 from the main directory to see if you get the secret. Run ./check.py 1 from the main directory to repeat the experiment multiple (5 by defualt) times. Submission and Grading . Submit your code part1-src/attacker-part1.c to your assigned Github repo. Full credit will be awarded to solutions that report the correct secret at least 80% of the time, while partial credit will be awarded for solutions which perform worse than that. Each attempt (i.e., each run of ./part1) should take no longer than 30 seconds. ",
    "url": "/2026/labs/spectre.html#part-1-leaking-kernel-memory-via-flushreload-20",
    "relUrl": "/labs/spectre.html#part-1-leaking-kernel-memory-via-flushreload-20"
  },"88": {
    "doc": "Spectre Attacks",
    "title": "Part 2: Basic Spectre (50%)",
    "content": "Now that Flush+Reload is working, let’s move on to actually implementing a Spectre attack! . Get to Know the Victim . Below is the pseudocode for Part 2’s victim code. This victim is quite similar to Part 1, except it will only perform the load if the offset is within a specific range (e.g., offset&lt;4). part2_limit = 4 def victim_part2 (shared_mem, offset): secret_data = part2_secret[offset] mem_index = 4096 * secret_data # to delay the subsequent branch flush(part2_limit) if offset &lt; part2_limit: load shared_mem[mem_index] . 2-1 Discussion Question . Copy your code in run_attacker from attacker-part1.c to attacker-part2.c. Does your Flush+Reload attack from Part 1 still work? Why or why not? . Attack Outline . Below are the steps required to leak a single byte. You may need to alter your approach to account for system noise. | Train the branch predictor to speculatively perform the load operation (i.e., take the branch). | Flush the shared memory region from the cache using clflush. | Call the victim function with an offset beyond the limit, leaking the secret byte during speculative execution. | Reload the memory region, measure the latency of accessing each address, and use the latency to determine the value of the secret. | . As you’ve observed in previous labs, side channel attacks generally do not work on the first attempt. You should try to use the good practices you have learned from the cache lab when attempting for any microarchitectural attacks. For example, . | DO NOT measure while printing. | To improve attack precision, you can repeat measurements multiple times and use statistical methods to decode secret. | Try to avoid using systemcall-related functions during attack. Both the printf and sleep functions trigger enough noise to seriously destruct your cache state and your branch predictor state. | . In addition, here is one more hint specific to the branch predictor. Modern processors employ branch predictors with significant complexity. Branch predictors can use global prediction histories, which allow different branches to interfere each other. Besides, the branch predictor is shared between userspace and kernel space. If the speculation is not working as expected, you may need to reduce the number of branches in your attack code. 2-2 Exercise . Implement the Spectre attack in attacker-part2.c to leak the secret string. Build the project with make and run ./part2 to see if you get the secret. Run ./check.py 2 to repeat the experiment multiple (5 by defualt) times. 2-3 Discussion Question . In our example, the attacker tries to leak the values in the array secret_part2. In a real-world attack, attackers can use Spectre to leak data located in an arbitrary address in the victim’s space. Explain how an attacker can achieve such leakage. 2-4 Discussion Question . Experiment with how often you train the branch predictor. What is the minimum number of times you need to train the branch (i.e. if offset &lt; part2_limit) to make the attack work? . Submission and Grading . This part is graded in the same way as Part 1. Full credit will be awarded to solutions that report the correct secret at least 80% of the time, while partial credit will be awarded for solutions which perform worse than that. Each attempt (i.e., each run of ./part2) should take no longer than 30 seconds. ",
    "url": "/2026/labs/spectre.html#part-2-basic-spectre-50",
    "relUrl": "/labs/spectre.html#part-2-basic-spectre-50"
  },"89": {
    "doc": "Spectre Attacks",
    "title": "Part 3: Advanced Spectre (30%)",
    "content": "Now that we’ve got our Spectre attack working, let’s try a harder version of the same problem. Get to Know the Victim . Below is the pseudocode for Part 3: . part3_limit = 4 def victim_part3 (shared_mem, offset): if offset &lt; part3_limit: false_dependency = lengthy computation # the computation result is 0 secret_data = part3_secret[offset] mem_index = 4096 * secret_data load shared_mem[mem_index + false_dependency] . There are two key differences in the victim code compared to Part 2. First, the victim no longer flushes the limit variable (partX_limit) before the branch. Second, we have added a false dependency before the memory access, making the memory access start later in the speculation window. If you copy run_attacker from Part 2, you should see that your attack does not work with the new victim. This is because in the modified victim code, the memory access instruction we try to monitor may not be issued speculatively for three reasons: . | The speculation window becomes shorter. The speculation window starts at the cycle the branch (if offset &lt; part3_limit) enters the processor, and ends at the cycle when the branch condition is resolved. If the part3_limit variable is cached, it will take a very short time to obtain its value, detect it is a branch misprediction, and squash the instructions after this branch. As a result, the speculative window becomes shorter. | The issue time of the secret-dependent memory access is delayed. Due to the data dependency between the false_dependency line and the load shared_mem line, the secret-dependent memory access can only be issued after the variable false_dependency is computed. It is possible that the branch condition is resolved before the speculative load even executes. | There is a hidden source of timing delay due to TLB misses. Feel free to refer to the section at the end of this handout for more information. You do not need to understand this factor for making your attack work. | . To make your attack work, you will need to find a way to increase the speculation window such that the speculative load has a higher chance of occuring. Note that you cannot change the long latency memory address dependency. Similar as before, use the good practices for microarchitectural attacks: do not use systemcall-related functions during attack, such as printf and sleep. Note . If your implementation from Part 2 can pass the test for Part 3, congratulations and please reach out to us! We have designed this part to make basic Spectre attack implementations work ineffectively, and we’d be curious to learn how you made it work in one shot. 3-1 Exercise . Optimize the attack in attacker-part3.c to leak the secret string. Build the project with make and run ./part3 to see if you get the secret. Run ./check.py 3 to repeat the experiment multiple (5 by defualt) times. 3-2 Discussion Question . Describe the strategy you employed to extend the speculation window of the target branch in the victim. 3-3 Discussion Question . Assume you are an attacker looking to exploit a new machine that has the same kernel module installed as the one we attacked in this part. What information would you need to know about this new machine to port your attack? Could it be possible to determine this information experimentally? Briefly describe in 5 sentences or less. Submission and Grading . Full credit will be awarded to solutions that report the correct secret at least 20% of the time, while partial credit will be awarded for solutions which perform worse than that. Each attempt (i.e., each run of ./part3) should take no longer than 10 minutes. We will give partial credit if the attack can recover some part of the secret string. You can check all parts at once with make and then ./check.py all . As always, do not forget to include answers to the discussion questions in your lab report and submit the report to Gradescope. ",
    "url": "/2026/labs/spectre.html#part-3-advanced-spectre-30",
    "relUrl": "/labs/spectre.html#part-3-advanced-spectre-30"
  },"90": {
    "doc": "Spectre Attacks",
    "title": "Behind the Scene: How this lab infrastructure was developed?",
    "content": "For those who are curious, here is a brief description of how this lab infrastructure was developped. The victims you are interacting with are part of a custom kernel module. You can find the source code of this kernel module in module-src/labspectrekm.c. The communication between the userspace and the kernel module is handled using a technique called procfs write handling. Specifically, whenever the userspace code writes to a file (i.e., /proc/labspectre-victim), a procfs write handler (i.e., spectre_lab_victim_write function in module-src/labspectrekm.c) in the kernel module will start to execute, using the written data (i.e., the local_cmd variable in call_kernel_partX functions) as the userbuf arguments. On the lab machine, SMAP (supervisor mode access prevention) and SMEP (supervisor mode execution prevention) are both on, which means that the kernel cannot directly read or execute userspace memory. You may wonder, in this case, how the kernel can read the shared_mem array, which is located in userspace. This is done by temporarily remapping an alias of the shared memory region into the kernel space. What we end up with is two different virtual addresses, one in the userspace and one the kernel space, both mapping to the same physical address. This is similar to what we have seen in Part 2 of the cache lab, where two virtual addresses in two processes are mapped to the same physical address. The interaction between the kernel module and the userspace code involves context switches. When the userspace code calls the kernel module (via the write syscall), the processor transitions from the userspace to the kernelspace, which will flush some microarchitecture structures, such as TLBs. The custom kernel module will then create an alias mapping for the shared memory region and execute the requested function. Before returning to the userspace, it will unmap the shared region. Therefore, every time the kernel module is called, the first accesses to each page will incur TLB misses. In Parts 2, we deliberately prevent TLB misses to make your attack easier by forcing page walks before performing any secret-dependent memory accesses. In Part 3, these redundant accesses are removed. You will need to craft an advanced Spectre attack that can succeed despite the added latency due to TLB misses. So in Part 3, in addition to the false dependency, the TLB misses also contribute to the extra latency. ",
    "url": "/2026/labs/spectre.html#behind-the-scene-how-this-lab-infrastructure-was-developed",
    "relUrl": "/labs/spectre.html#behind-the-scene-how-this-lab-infrastructure-was-developed"
  },"91": {
    "doc": "Spectre Attacks",
    "title": "Acknowledgements",
    "content": "Contributors: Joseph Ravichandran, Mengjia Yan, Peter Deutsch. ",
    "url": "/2026/labs/spectre.html#acknowledgements",
    "relUrl": "/labs/spectre.html#acknowledgements"
  },"92": {
    "doc": "Spectre Attacks",
    "title": "Spectre Attacks",
    "content": " ",
    "url": "/2026/labs/spectre.html",
    "relUrl": "/labs/spectre.html"
  }
}

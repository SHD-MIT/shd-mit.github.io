<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/2024/assets/css/just-the-docs-default.css"> <script src="/2024/assets/js/vendor/lunr.min.js"></script> <script src="/2024/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Cache Attacks | 6.5950/6.5951</title> <meta name="generator" content="Jekyll v4.2.2" /> <meta property="og:title" content="Cache Attacks" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Secure Hardware Design" /> <meta property="og:description" content="Secure Hardware Design" /> <meta property="og:site_name" content="6.5950/6.5951" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Cache Attacks" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Secure Hardware Design","headline":"Cache Attacks","url":"/2024/labs/cache.html"}</script> <!-- End Jekyll SEO tag --> <!-- Cover up the page while CSS is loading to prevent flicker --> <div id="preload-cover"></div> <style> #preload-cover { position:fixed; height:100%; width:100%; top:0; left:0; background:#fff; z-index:9999; } @media (prefers-color-scheme: dark) { #preload-cover { position:fixed; height:100%; width:100%; top:0; left:0; background:#222326; z-index:9999; } } </style> <script> window.addEventListener('load', function() { var cover = document.getElementById('preload-cover'); cover.style.display = 'none'; }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Feather. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="/2024/" class="site-title lh-tight"> 6.5950/6.5951 </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/2024/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="/2024/calendar.html" class="nav-list-link">Calendar</a></li><li class="nav-list-item"><a href="/2024/lectureReadings.html" class="nav-list-link">Lecture Readings</a></li><li class="nav-list-item"><a href="/2024/paperDiscussion.html" class="nav-list-link">Paper Discussion</a></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in Recitations category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/2024/recitations.html" class="nav-list-link">Recitations</a><ul class="nav-list "><li class="nav-list-item "><a href="/2024/recitations/cpp.html" class="nav-list-link">CTF of C Programming</a></li><li class="nav-list-item "><a href="/2024/recitations/physical.html" class="nav-list-link">CTF of Physical Attacks</a></li><li class="nav-list-item "><a href="/2024/recitations/riscv.html" class="nav-list-link">Binary Exploitation and RISC-V Warmup</a></li><li class="nav-list-item "><a href="/2024/recitations/formal.html" class="nav-list-link">Formal Verification</a></li></ul></li><li class="nav-list-item active"><a href="#" class="nav-list-expander" aria-label="toggle links in Labs category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/2024/labs.html" class="nav-list-link">Labs</a><ul class="nav-list "><li class="nav-list-item "><a href="/2024/labs/fingerprinting.html" class="nav-list-link">Website Fingerprinting</a></li><li class="nav-list-item active"><a href="/2024/labs/cache.html" class="nav-list-link active">Cache Attacks</a></li><li class="nav-list-item "><a href="/2024/labs/spectre.html" class="nav-list-link">Spectre Attacks</a></li><li class="nav-list-item "><a href="/2024/labs/rowhammer.html" class="nav-list-link">Rowhammer</a></li><li class="nav-list-item "><a href="/2024/labs/aslr.html" class="nav-list-link">ASLR Bypasses</a></li><li class="nav-list-item "><a href="/2024/labs/psp.html" class="nav-list-link">Pretty Secure Processor</a></li><li class="nav-list-item "><a href="/2024/labs/fuzz.html" class="nav-list-link">CPU Fuzzing</a></li><li class="nav-list-item "><a href="/2024/labs/formal.html" class="nav-list-link">CPU Verification</a></li></ul></li><li class="nav-list-item"><a href="/2024/paperReadingGuidance.html" class="nav-list-link">Paper Readings Guidance</a></li><li class="nav-list-item"><a href="/2024/forInstructors.html" class="nav-list-link">For Instructors</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search 6.5950/6.5951" aria-label="Search 6.5950/6.5951" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/2024/labs.html">Labs</a></li> <li class="breadcrumb-nav-list-item"><span>Cache Attacks</span></li> </ol> </nav> <div id="main-content" class="main-content" role="main"> <h1 class="no_toc" id="cache-side-channel-attacks-lab"> <a href="#cache-side-channel-attacks-lab" class="anchor-heading" aria-labelledby="cache-side-channel-attacks-lab"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Cache Side Channel Attacks Lab </h1> <p><strong>Due Date: Mar 7</strong>; Last Updated Date: Feb 20</p> <h2 class="no_toc" id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of Contents </h2> <ul id="markdown-toc"> <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li> <li><a href="#part-1-gathering-information-20" id="markdown-toc-part-1-gathering-information-20">Part 1: Gathering Information (20%)</a> <ul> <li><a href="#part-11-determining-machine-architecture" id="markdown-toc-part-11-determining-machine-architecture">Part 1.1: Determining Machine Architecture</a></li> <li><a href="#part-12-timing-a-memory-access" id="markdown-toc-part-12-timing-a-memory-access">Part 1.2: Timing a Memory Access</a></li> </ul> </li> <li><a href="#part-2-capture-the-flag-with-flushreload-30" id="markdown-toc-part-2-capture-the-flag-with-flushreload-30">Part 2: Capture the Flag with Flush+Reload (30%)</a></li> <li><a href="#part-3-capture-the-flag-with-primeprobe-50" id="markdown-toc-part-3-capture-the-flag-with-primeprobe-50">Part 3: Capture the Flag with Prime+Probe (50%)</a> <ul> <li><a href="#before-attacking-cache-addressing" id="markdown-toc-before-attacking-cache-addressing">Before Attacking: Cache Addressing</a></li> <li><a href="#using-hugepage" id="markdown-toc-using-hugepage">Using Hugepage</a></li> <li><a href="#implementing-the-attack-primeprobe" id="markdown-toc-implementing-the-attack-primeprobe">Implementing the Attack: Prime+Probe</a></li> </ul> </li> <li><a href="#bonus-dead-drop--an-evil-chat-client-10" id="markdown-toc-bonus-dead-drop--an-evil-chat-client-10">Bonus: Dead Drop – An Evil Chat Client (10%)</a></li> </ul> <h3 class="no_toc" id="collaboration-policy"> <a href="#collaboration-policy" class="anchor-heading" aria-labelledby="collaboration-policy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Collaboration Policy </h3> <p>Our full Academic Honesty policy can be found on the <a href="../index.html#collaboration-policy">Course Information page</a> of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code.</p> <h3 class="no_toc" id="getting-started"> <a href="#getting-started" class="anchor-heading" aria-labelledby="getting-started"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Getting Started </h3> <p>Log in to our lab machine that you are assigned, <code class="language-plaintext highlighter-rouge">unicorn.csail.mit.edu</code> for example, via <code class="language-plaintext highlighter-rouge">ssh</code> by running <code class="language-plaintext highlighter-rouge">ssh username@unicorn.csail.mit.edu</code>.</p> <p>You will complete this lab primarily in C.</p> <p>We are using <code class="language-plaintext highlighter-rouge">git</code> for all the labs – instructions for setting up the git repository can be found on the <a href="../labs.html#github">labs page</a>.</p> <p>In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to <a href="https://www.gradescope.com/courses/715149">gradescope</a>. We provide a markdown template in the starter code (<code class="language-plaintext highlighter-rouge">report.md</code>).</p> <h2 id="introduction"> <a href="#introduction" class="anchor-heading" aria-labelledby="introduction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Introduction </h2> <p>In this lab, you will complete the following tasks:</p> <ol> <li>Reverse engineer the cache configuration on our lab machine.</li> <li>Solve two CTF (capture-the-flag) puzzles using cache-based side channels.</li> </ol> <p>In this lab, you will learn how to interact and manipulate fine-grained cache states in real hardware. Real, commercial hardware is a black box to us. To be able to mount a cache attack, we need to leverage our computer architecture knowledge to infer how a cache behaves for a sequence of instructions. Making the attacker’s life more difficult, real-world caches are far more complex than the toy example caches that we learned in the classroom. After completing this lab, you will hopefully get a glimpse of the complexity of these hardware features.</p> <h3 class="no_toc" id="getting-prepared-before-you-start"> <a href="#getting-prepared-before-you-start" class="anchor-heading" aria-labelledby="getting-prepared-before-you-start"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Getting Prepared Before You Start </h3> <p>You will program in C throughout this lab. C is a low-level language that gives you more control over the hardware compared to high-level languages. Programs written in C can be directly compiled into machine code, and directly executed on the hardware without other abstraction layers. When working on microarchitectural attacks, having a high degree of control over the exact instructions being executed is essential. If you are not familiar with C, we highly recommend participating in the “CTF of C Programming” recitation. You can also get yourself familiar with C syntax by looking at the <a href="../recitations/cpp.html">recitation materials</a>.</p> <p>You will need to think about how the cache works while working on this lab. Our lab machine is huge (with 96 cores) and has a relatively complex cache hierarchy. We highly recommend you also attend the “Cache Attack” recitation, where we give an overview of the processor architecture of our lab machines. Knowing the overall organization may help you think and debug. You can also look up relevant information following the recitation materials (link will be available soon).</p> <h3 class="no_toc" id="setting-up-your-environment"> <a href="#setting-up-your-environment" class="anchor-heading" aria-labelledby="setting-up-your-environment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Setting Up Your Environment </h3> <p>You will run your attacks using two CPU cores on the lab machine. Every student will get a different pair of CPUs such that your programs do not interfere with each other. Each pair of CPUs provided is a pair of SMT (aka, Simultaneous MultiThreading) cores. These two “logical cores” map to the same physical core and share multiple hardware resources associated with that core, such as private L1 and L2 caches.</p> <blockquote class="exercise-title"> <p>Configuration</p> <p>After logging into the lab machine and cloning your repo, you <strong>must</strong> modify the <code class="language-plaintext highlighter-rouge">SENDER_CPU</code> and <code class="language-plaintext highlighter-rouge">RECEIVER_CPU</code> variables in <code class="language-plaintext highlighter-rouge">cpu.mk</code> to your assigned CPUs. You have to do so before running code for any portion of this lab! Only after you have configured these variables, you can remove the <code class="language-plaintext highlighter-rouge">$error$</code> line from <code class="language-plaintext highlighter-rouge">cpu.mk</code>. <strong>Double check that you have set these values correctly.</strong></p> </blockquote> <blockquote class="warning"> <p>Do not use VS Code’s remote ssh plugin to connect to the server! This plugin can introduce a large degree of noise, and is likely to cause your attack to fail.</p> </blockquote> <h2 id="part-1-gathering-information-20"> <a href="#part-1-gathering-information-20" class="anchor-heading" aria-labelledby="part-1-gathering-information-20"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Part 1: Gathering Information (20%) </h2> <p>Before we begin, think – what is the first step when planning to attack a system? We first need to gather information about the system’s <em>attributes</em>. This rule applies to attacking software, hardware, and even in real-life on non-computing systems! For example, if you wanted to plan a bank robbery, you would first need to figure out the floorplan of the bank, the locations of safes and security cameras, etc. In this part of the lab, you will see a few practical approaches people use to gain detailed microarchitecture information of commodity hardware. You will further get familiar with some common techniques and instructions that we can use to measure execution latencies on processors, which will help you mount your attacks later on.</p> <h3 id="part-11-determining-machine-architecture"> <a href="#part-11-determining-machine-architecture" class="anchor-heading" aria-labelledby="part-11-determining-machine-architecture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Part 1.1: Determining Machine Architecture </h3> <p>The simplest way to gather hardware information is to use existing public system interfaces and documentation. Here is a list of commands that can be used to determine machine architecture information on Linux.</p> <ul> <li><code class="language-plaintext highlighter-rouge">lscpu</code>: Provides information on the type of processor and some summary information about the architecture in the machine.</li> <li><code class="language-plaintext highlighter-rouge">less /proc/cpuinfo</code>: Provides detailed information about each logical processor in the machine. (Type <code class="language-plaintext highlighter-rouge">q</code> to exit.)</li> <li><code class="language-plaintext highlighter-rouge">getconf -a | grep CACHE</code>: Displays the system configuration related to the cache. This will provide detailed information about how the cache is structured. The numbers that are reported using this command use Bytes (B) as the unit.</li> </ul> <p>In addition, <a href="https://en.wikichip.org/wiki/WikiChip">WikiChip</a> is a good source of information, as it provides information specific to each processor and architecture. You can find a detailed architecture description of our lab machines (Intel Cascade Lake processors) <a href="https://en.wikichip.org/wiki/intel/microarchitectures/cascade_lake">here</a>, which additionally provides the raw latency value for accessing different levels of caches.</p> <!-- > TODO: Not sure how relevant this is here, maybe better to say this during lecture: > More advanced hardware hackers often use patents to gather information about hardware features which might be hidden in a CPU. > These patents, issued by big chip companies, are usually difficult to read and vague enough to confuse readers. > Still, it seems that reading patents has become popular among hardcore attackers. --> <blockquote class="discussion-title"> <p>1-1 Discussion Question</p> <p>Fill in the blanks in the following table using the information you gathered about the cache configuration of the lab machine. You should be able to directly obtain the information for the first 3 blank columns using commands above. You will need to derive the number of sets using what you have learned about set-associative caches in 6.1910<sub>[6.004]</sub>. Raw latency can be obtained from the WikiChip document. The line size of L1 data cache has been filled in for you.</p> <div class="table-wrapper"><table> <thead> <tr> <th>Cache</th> <th>Cache Line Size</th> <th>Total Size</th> <th>Number of Ways (Associativity)</th> <th>Number of Sets</th> <th>Raw Latency</th> </tr> </thead> <tbody> <tr> <td>L1-Data</td> <td>64 Bytes</td> <td> </td> <td> </td> <td> </td> <td> </td> </tr> <tr> <td>L2</td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> </tr> <tr> <td>L3</td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> </tr> </tbody> </table></div> </blockquote> <h3 id="part-12-timing-a-memory-access"> <a href="#part-12-timing-a-memory-access" class="anchor-heading" aria-labelledby="part-12-timing-a-memory-access"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Part 1.2: Timing a Memory Access </h3> <p>The information you can get from public sources can be limited, as hardware companies would not like to disclose all of their proprietary design details to general users and potential competitors. An alternative way to gather information is to reverse engineer the processor by running some very carefully designed instruction sequences on the processor and observing their behaviors.</p> <p>In this part, you will try to reverse engineer the latencies for accessing the cache hierarchy. Specifically, we would like to know how long it takes to access cache lines that are located in the (a) L1 data cache, (b) L2 cache, (c) L3 cache, and (d) the DRAM.</p> <h3 class="no_toc" id="the-reverse-engineering-plan"> <a href="#the-reverse-engineering-plan" class="anchor-heading" aria-labelledby="the-reverse-engineering-plan"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Reverse Engineering Plan </h3> <p>To measure the L1 latency, we can perform a load operation on a target address to bring the corresponding cache line into the L1 data cache. Then, we measure the access latency by counting the cycles it takes to re-access the same target address using <code class="language-plaintext highlighter-rouge">measure_one_block_access_time</code>. We have provided this code for you, and you can compile the starter code using the command <code class="language-plaintext highlighter-rouge">make</code>, and then run it with <code class="language-plaintext highlighter-rouge">make run</code>.</p> <p>Your task is to complete the <code class="language-plaintext highlighter-rouge">main</code> function in <code class="language-plaintext highlighter-rouge">main.c</code> to populate the three arrays <code class="language-plaintext highlighter-rouge">dram_latency</code>, <code class="language-plaintext highlighter-rouge">l2_latency</code>, and <code class="language-plaintext highlighter-rouge">l3_latency</code>. We suggest you start with measuring DRAM latency, since measuring DRAM latencies is the easiest. You can leverage the instruction <code class="language-plaintext highlighter-rouge">clflush</code> to place the target address to DRAM.</p> <p>Measuring L2 and L3 latencies is slightly more complex. To measure the L2 latency, we need to place the target address in the L2 cache. However, simply accessing the target address will make the address reside in the L1 cache. Therefore, need to access other addresses to <strong>evict</strong> the target address from the L1 cache. Thus, you first need to access the line to bring it into L1, then create cache conflicts to evict it into L2. When it comes to measuring the L3 latency, you need to similarly create cache conflicts to evict the cache line from both the L1 cache and the L2 cache.</p> <h3 class="no_toc" id="helper-functions"> <a href="#helper-functions" class="anchor-heading" aria-labelledby="helper-functions"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Helper Functions </h3> <p>Before you start, make sure you familiarize yourself with C syntax and several useful x86 instructions. Read the code in <code class="language-plaintext highlighter-rouge">utility.h</code> and understand the following functions.</p> <ul> <li><code class="language-plaintext highlighter-rouge">rdtscp</code> and <code class="language-plaintext highlighter-rouge">rdtscp64</code>: Read the current timestamp counter of the processor and return a 32-bit or 64-bit integer.</li> <li><code class="language-plaintext highlighter-rouge">lfence</code>: Perform a serializing operation. Ask the processor to first complete the memory loads before the <code class="language-plaintext highlighter-rouge">lfence</code> instruction, then start issuing memory loads after the <code class="language-plaintext highlighter-rouge">lfence</code> instruction. Other variants of fences exist, such as <code class="language-plaintext highlighter-rouge">sfence</code> and <code class="language-plaintext highlighter-rouge">mfence</code>.</li> <li><code class="language-plaintext highlighter-rouge">measure_one_block_access_time</code>: Measure the latency of performing one memory access to a given address.</li> <li><code class="language-plaintext highlighter-rouge">clflush</code>: Flush a given address from the cache, evict the line from the whole cache hierarchy so that later accesses to the address will load from DRAM.</li> <li><code class="language-plaintext highlighter-rouge">print_results_plaintext</code> and <code class="language-plaintext highlighter-rouge">print_results_for_visualization</code>: Print the collected latency data in different formats. The default Makefile compiles two binaries: <code class="language-plaintext highlighter-rouge">main</code> uses <code class="language-plaintext highlighter-rouge">print_results_plaintext</code>, while <code class="language-plaintext highlighter-rouge">main-visual</code> uses <code class="language-plaintext highlighter-rouge">print_results_for_visualization</code>.</li> </ul> <blockquote class="hint"> <p><strong>Pointer Arithmetic</strong></p> <p>Pointer arithemetic operations, such as <code class="language-plaintext highlighter-rouge">new_ptr = old_ptr + 1</code>, means moving the pointer forward by one element. For different types of pointers whose element size is different, the actual bytes being moved can be very different. For example, given a <code class="language-plaintext highlighter-rouge">uint8_t</code> pointer, since each element is 1 byte, <code class="language-plaintext highlighter-rouge">+1</code> means moving the pointer foward by 1 byte. However, <code class="language-plaintext highlighter-rouge">+1</code> of a <code class="language-plaintext highlighter-rouge">uint64_t</code> pointer means moving the pointer forward by 8 bytes. <strong>We highly suggest to use <code class="language-plaintext highlighter-rouge">uint8_t</code> pointers</strong> to make your address calculation easier and avoid introducing addressing mistakes. Further details about common C/C++ constructs can be found in the <a href="../recitations/cpp.html">C Programming Recitation</a>.</p> </blockquote> <h3 class="no_toc" id="visualization-support"> <a href="#visualization-support" class="anchor-heading" aria-labelledby="visualization-support"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Visualization Support </h3> <p>Microarchitectural side channels are notoriously noisy, and it is common to get inconsistent latency results from run to run. To combat noise, the most commonly used methodology is to repeat the experiments and plot the distribution of the observed latencies. We have provided two Python scripts to help you launch multiple measurements and visualize these measurements. To install python packages used in these two scripts, please run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> pip <span class="nb">install </span>matplotlib tqdm
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">run.py</code>: A python script that will generate 100 runs from the <code class="language-plaintext highlighter-rouge">main-visual</code> binary. It will create a folder (if one doesn’t already exist) called <code class="language-plaintext highlighter-rouge">data</code>, and it will store all the generated samples there in json format. The script will overwrite the folder if it already exists.</li> <li><code class="language-plaintext highlighter-rouge">graph.py</code>: A python script that will plot the histogram of the samples collected from <code class="language-plaintext highlighter-rouge">run.py</code>. It will read the JSON files from the folder <code class="language-plaintext highlighter-rouge">data</code> and generate a pdf file of the histogram in a folder called <code class="language-plaintext highlighter-rouge">graph</code>.</li> </ul> <h3 class="no_toc" id="expected-outcome"> <a href="#expected-outcome" class="anchor-heading" aria-labelledby="expected-outcome"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Expected Outcome </h3> <p>When grading we will not check the exact latency numbers generated by your code, since different implementations can yield different latency numbers. For example, it is unlikely that your L1 latency will match the L1 raw latency number from WikiChip. This is because our measurement involves extra latency introduced by the <code class="language-plaintext highlighter-rouge">lfence</code> instructions. Besides, other factors such as the frequency of the core and prefetch configurations of the cache can also affect the latency.</p> <p>If you want to check whether you are on the right track, you should look for the following patterns in your visualized plot. We also include an example plot below.</p> <ul> <li>There are distinct peaks for DRAM, L3, and L2 latency.</li> <li>The L1 and L2 latency do not need to be distinguishable.</li> </ul> <p><img src="figures/reference_plot.png" alt="Reference distribution plot" style="display:block; margin-left:auto; margin-right:auto" width="80%" /></p> <p class="image-caption"><em>A reference memory latency distribution plot</em></p> <blockquote class="exercise-title"> <p>1-2 Exercise</p> <p>Fill in the code in <code class="language-plaintext highlighter-rouge">main.c</code> to populate the arrays <code class="language-plaintext highlighter-rouge">dram_latency</code>, <code class="language-plaintext highlighter-rouge">l2_latency</code>, and <code class="language-plaintext highlighter-rouge">l3_latency</code>.</p> </blockquote> <blockquote class="warning"> <p><strong>DO NOT take latency measurements while also printing. Instead, measure then print.</strong></p> <p>When debugging your code, it is tempting to write code like this, which we call “measuring while printing”.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">l1_cache</span><span class="p">:</span>
    <span class="c1"># Observe some aspect of the cache state
</span>    <span class="n">val</span> <span class="o">=</span> <span class="n">time_access</span><span class="p">(</span><span class="n">cache</span> <span class="n">line</span> <span class="n">i</span><span class="p">)</span>
    <span class="c1"># In the same measurement loop, print the observed value out!
</span>    <span class="n">printf</span><span class="p">(</span><span class="s">"The cache took %d cycles"</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
    <span class="c1"># Now we go to the next interation and measure again
</span></code></pre></div> </div> <p><strong>Do not do this!</strong> We are no longer in the regular world, we are in the microarchitectural world, where each assembly instruction counts!</p> <p>What do we mean by this? Under the hood, a “simple” call to <code class="language-plaintext highlighter-rouge">printf</code> involves executing a huge number of instructions. When you call <code class="language-plaintext highlighter-rouge">printf</code>, you are going to go to the libc library, doing some string processing, and eventually making a system call into the kernel (so, the entire CPU performs a context switch, and does who knows what else). Think about how many cache lines this call to <code class="language-plaintext highlighter-rouge">printf</code> will need to read/write – printing anything is a destructive action to the state of the cache.</p> <p>Instead, you should measure <strong>then</strong> print. We suggest structuring your code like this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uint64_t</span> <span class="n">measurements</span><span class="p">[</span><span class="n">NUM_THINGS_TO_MEASURE</span><span class="p">]</span>
<span class="c1"># Measure
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">l1_cache</span><span class="p">:</span>
    <span class="n">measurements</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">time_access</span><span class="p">(</span><span class="n">cache</span> <span class="n">line</span> <span class="n">i</span><span class="p">)</span>
<span class="c1"># Then, print :)
</span><span class="k">print</span><span class="p">(</span><span class="n">measurements</span><span class="p">)</span>
</code></pre></div> </div> </blockquote> <blockquote class="hint"> <p><strong>Tips for Reliably Triggering Cache Evictions</strong></p> <p>The following tips may help you if you get stuck when you could not observe differences between the L2 and L3 cache latency. A common pitfall is not properly evicting the target address from the L1/L2 cache due to various reasons.</p> <ul> <li> <p><strong>Cache Line Size != Integer Size</strong>: To begin with, you should be careful with the the mismatch of access granularities. The smallest operational unit in cache is the cache line, which is larger than the size of an integer. Accessing two integers that fall into the same line (more precisely, that fall within the same cache line size aligned region of memory) will result in a cache hit, and won’t cause an eviction. So make sure to use eviction addresses that do not map to the same cache line when attempting to evict.</p> </li> <li> <p><strong>Advanced Cache Replacement Policy</strong>: The cache replacement policy in modern processors is more advanced than the simple policies that we learned in class, and is often not completely known to us. It may intelligently decide to keep a target address in the cache, rather than evicting it. To combat the advanced replacement policy, we suggest accessing the eviction buffer multiple times.</p> </li> <li> <p><strong>Virtual to physical address translation</strong>: Intuitively, we would imagine that given a cache, if we have a buffer whose size matches the cache size, then accessing each element in the buffer allows us to fully occupy every slot in the cache. However, this may not always be the case, due to virtual to physical address translation. Note that on our machine, the cache mapping is a function of physical address, while the software uses virtual address.</p> <p>Let’s consider a toy example where a 8KB directly-mapped cache which can hold two 4K pages. If we have a two-page-size buffer, after virtual address translation, we can end up with three posibilities: 1) the buffer covers the whole cache; 2) both pages map to the top half of the cache; and 3) both pages map to the bottom half of the cache.</p> <p>In this case, how can we reliably evict data from a certain cache level without the control of the address translation procedure? The common trick is to just use a buffer that is bigger than the cache itself – between 1.5x or even 4x of the cache size. Even though the eviction might still not be guaranteed, its likelihood is high enough.</p> </li> </ul> </blockquote> <blockquote class="discussion-title"> <p>1-3 Discussion Question</p> <p>After completing your code, generate the histogram pdf file and include it in the lab report.</p> </blockquote> <blockquote class="discussion-title"> <p>1-4 Discussion Question</p> <p>Based on the generated histogram, report two thresholds, one to distinguish between L2 and L3 latency and the other to distinguish between L3 and DRAM latency.</p> </blockquote> <h3 class="no_toc" id="submission-and-grading"> <a href="#submission-and-grading" class="anchor-heading" aria-labelledby="submission-and-grading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Submission and Grading </h3> <p>You will need to submit the code <code class="language-plaintext highlighter-rouge">Part1-Timing/main.c</code> to your assigned Github repository. Your code should be able to reproduce the histogram you submitted. You can determine whether your implementation is correct by check the description in <a href="#expected-outcome">expected outcome</a>. Due to noise, we will run your code multiple times (5 times) and grade based on the best results. You should feel comfortable to submit your code as long as it can generate the expected results most of the time.</p> <h2 id="part-2-capture-the-flag-with-flushreload-30"> <a href="#part-2-capture-the-flag-with-flushreload-30" class="anchor-heading" aria-labelledby="part-2-capture-the-flag-with-flushreload-30"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Part 2: Capture the Flag with Flush+Reload (30%) </h2> <p>From now on, we are entering attack time. In this part of the lab, you will be attempting to extract secrets from a victim program. You will get a taste of solving a Capture-the-Flag (CTF) puzzle. The future labs will follow a similar pattern.</p> <h3 class="no_toc" id="get-to-know-the-victim"> <a href="#get-to-know-the-victim" class="anchor-heading" aria-labelledby="get-to-know-the-victim"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Get to Know the Victim </h3> <p>We provide you with a victim program in <code class="language-plaintext highlighter-rouge">Part2-FlushReload/victim</code>, whose pseudocode is listed below. The victim program uses <code class="language-plaintext highlighter-rouge">mmap</code> to map a file into its own virtual address space to create a buffer. It then generates a random integer as the flag and uses the flag to index into the buffer. Your task is to learn the flag value by monitoring the victim’s memory accesses using a Flush+Reload attack.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Allocate a large memory buffer</span>
<span class="kt">char</span> <span class="o">*</span><span class="n">buf</span> <span class="o">=</span> <span class="n">get_buffer</span><span class="p">();</span>

<span class="c1">// Set the flag to random integer in the range [0, 1024)</span>
<span class="kt">int</span> <span class="n">flag</span> <span class="o">=</span> <span class="n">random</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1024</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="n">flag</span><span class="p">);</span>

<span class="c1">// Main loop</span>
<span class="k">while</span> <span class="p">(</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">buf</span> <span class="o">+</span> <span class="n">flag</span> <span class="o">*</span> <span class="mi">128</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <h3 class="no_toc" id="the-attack-setup-and-your-plan"> <a href="#the-attack-setup-and-your-plan" class="anchor-heading" aria-labelledby="the-attack-setup-and-your-plan"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Attack Setup and Your Plan </h3> <p>We have set up the attack framework that enables your attacker program to share a memory region with the victim. It uses a technique called <em>memory-mapped file</em>, where two virtual addresses (one from your program’s address space and the other from the victim’s address space) are mapped to a same physical address, which contains a copy of a file on the hard drive. You can use the figure below to understand what is happening under the hood.</p> <p><img src="figures/file_mmap.svg" alt="File mapped memory" style="display:block; margin-left:auto; margin-right:auto" width="60%" /></p> <p class="image-caption"><em>The <code class="language-plaintext highlighter-rouge">buf</code> in the victim program and the <code class="language-plaintext highlighter-rouge">buf</code> in the attacker program point to the same physical address</em></p> <p>Your attack should implement standard Flush+Reload. We are providing you with the attack skeleton and several practical tips.</p> <ul> <li><strong>Flush</strong>: Flush all the cache lines that might be accessed by the victim to DRAM using <code class="language-plaintext highlighter-rouge">clflush</code>. Be careful with the aforementioned cache line granularity issue. Note that cache size != integer size.</li> <li><strong>Wait</strong>: Wait a few hundred cycles for the victim to perform the flag-dependent memory load operations. Don’t use the system-provided <code class="language-plaintext highlighter-rouge">sleep</code> function to do this – similar to <code class="language-plaintext highlighter-rouge">printf</code>, this function will trigger a system call, potentially destroying cache states.</li> <li><strong>Reload</strong>: Re-access all the cache lines in the Flush step and measure the access latency to each of them. Use the threshold derived from Part 1 to decode the flag value.</li> </ul> <blockquote class="exercise-title"> <p>2-1 Exercise</p> <p>Complete the code in <code class="language-plaintext highlighter-rouge">Part2-FlushReload/attacker.c</code> to successfully extract the secret values from <code class="language-plaintext highlighter-rouge">Part2-FlushReload/victim</code>.</p> <p>To test your attack, you should first compile your code using <code class="language-plaintext highlighter-rouge">make</code> and generate a file for the shared buffer using <code class="language-plaintext highlighter-rouge">python3 gen_file.py</code>. Then use tmux, screen, or simply two SSH connections, and run <code class="language-plaintext highlighter-rouge">make run_victim</code> in one terminal and <code class="language-plaintext highlighter-rouge">make run_attacker</code> in another terminal. Make sure you are <strong>NOT</strong> executing <code class="language-plaintext highlighter-rouge">./victim</code> or <code class="language-plaintext highlighter-rouge">./attacker</code> directly because they will not launch the binary on your assigned cores. If you have problems running the victim binary, you may need to run <code class="language-plaintext highlighter-rouge">chmod +x victim</code>.</p> </blockquote> <blockquote class="hint"> <p><strong>Hardware Prefetchers</strong></p> <p>Modern processors can predict future memory accesses and prefetch data into the cache before it is used. Hardware prefetching is an effective performance optimization technique that is widely deployed in real-world processors. This feature can confuse your attack code. For example, regardless of what the flag value is, some Flush+Reload attack implementation may consistently observe a cache miss for the first reload operation, and cache hits for the rest of the reload operations, because the first load miss triggers hardware prefetching for the later addresses.</p> <p>Usually, the hardware prefetcher makes address prediction based on simple patterns, such as a linear, fixed-stride access pattern within a page. Therefore, you can bypass the prefetching effects by introducing randomness to your address access pattern.</p> <p>The prefethers are enabled on the lab machines. Make sure you have avoided aforementioned simple access patterns in your code. <!-- > We may turn off prefethers on the machine to make your life easier. Please check Piazza for the release announcement of this lab. --></p> </blockquote> <blockquote class="discussion-title"> <p>2-2 Discussion Question</p> <p>In the victim’s pseudocode above, the victim attempts to load the data indexed by <code class="language-plaintext highlighter-rouge">flag</code> into the <code class="language-plaintext highlighter-rouge">value</code> variable. How can you change the victim’s code to load the desired data without leaking the flag to the attacker?</p> </blockquote> <h3 class="no_toc" id="submission-and-grading-1"> <a href="#submission-and-grading-1" class="anchor-heading" aria-labelledby="submission-and-grading-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Submission and Grading </h3> <p>You will need to submit the code <code class="language-plaintext highlighter-rouge">Part2-FlushReload/attack.c</code> to your assigned Github repository. Your code should be able to reliably capture the flag. Due to system noise, we will grade this part by executing your code multiple times. Full credit will be awarded if your code works at least 4 out of 5 runs.</p> <h2 id="part-3-capture-the-flag-with-primeprobe-50"> <a href="#part-3-capture-the-flag-with-primeprobe-50" class="anchor-heading" aria-labelledby="part-3-capture-the-flag-with-primeprobe-50"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Part 3: Capture the Flag with Prime+Probe (50%) </h2> <p>We will now solve a more challenging CTF puzzle, leaking the flag using a Prime+Probe attack. In this setup, the attacker and the victim no longer share memory, and thus Flush+Reload will not work. Instead, to make the attack work, you need to carefully manipulate cache states and trigger cache set-conflicts.</p> <h3 class="no_toc" id="get-to-know-the-victim-1"> <a href="#get-to-know-the-victim-1" class="anchor-heading" aria-labelledby="get-to-know-the-victim-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Get to Know the Victim </h3> <p>We have created several victim binaries, <code class="language-plaintext highlighter-rouge">victim-N</code>, whose pseudocode is listed below. Each victim program generates a random number as the flag. Then it finds a collection of addresses that all map to the same L2 cache set whose set index matches this flag value. The value <code class="language-plaintext highlighter-rouge">N</code> denotes the number of cache lines being accessed by the victim, reflecting the strength of the side-channel signal. Intuitively, using a smaller <code class="language-plaintext highlighter-rouge">N</code> means the victim accesses fewer ways in a given cache set, and the generated side-channel signal is weaker, making attacks more difficult.</p> <p>We have provided the binary for <code class="language-plaintext highlighter-rouge">victim-[16,4,3,2]</code>, where <code class="language-plaintext highlighter-rouge">victim-16</code> accesses the full cache set and is the easiest to attack. To get full credit for Part 3, you have to make your attack work on <code class="language-plaintext highlighter-rouge">victim-16</code> and <code class="language-plaintext highlighter-rouge">victim-4</code>. See the detailed grading policy <a href="#submission-and-grading-2">later</a>.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Allocate a large memory buffer</span>
<span class="kt">char</span> <span class="o">*</span><span class="n">buf</span> <span class="o">=</span> <span class="n">get_buffer</span><span class="p">();</span>

<span class="c1">// Set flag to random integer in the </span>
<span class="c1">// range [0, NUM_L2_CACHE_SETS)</span>
<span class="kt">int</span> <span class="n">flag</span> <span class="o">=</span> <span class="n">random</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">NUM_L2_CACHE_SETS</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="n">flag</span><span class="p">);</span>

<span class="c1">// Find N addresses in buf that all map to the cache set </span>
<span class="c1">// with an index of flag to create a partial eviction set</span>
<span class="kt">char</span> <span class="o">*</span><span class="n">eviction_set</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
<span class="n">get_partial_eviction_set</span><span class="p">(</span><span class="n">eviction_set</span><span class="p">,</span> <span class="n">flag</span><span class="p">);</span>

<span class="c1">// Main loop</span>
<span class="k">while</span> <span class="p">(</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Access the eviction address</span>
        <span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">eviction_set</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="before-attacking-cache-addressing"> <a href="#before-attacking-cache-addressing" class="anchor-heading" aria-labelledby="before-attacking-cache-addressing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Before Attacking: Cache Addressing </h3> <p>Given the victim’s behavior described above, you will build a Prime+Probe covert channel targeting the L2 cache.</p> <p>Similar to previous parts, the addresses you are dealing with in your C code are virtual addresses while physical addresses (which you will not have access to within your code) are used when indexing into caches. This fact can be more problematic in this part because you might need to do more careful calculation on the addresses. For a review of virtual memory and address translation, please refer 6.191’s (6.004’s) lectures on <a href="../lectures/readings/6191-fall2023/L17.pdf">Virtual Memory 1</a> and <a href="../lectures/readings/6191-fall2023/L18.pdf">Virtual Memory 2</a>.</p> <p>It is very tempting to “fudge” the numbers in this lab (e.g., hypertuning various parameters to make incremental changes to your attack’s performance). While this approach may work, we really don’t recommend this approach. Instead, take the time to sit down and calculate all the cache parameters before you move forward may save you more time.</p> <p>Think about the following questions: How many bits are part of the tag in a virtual address? The set index? The offset (within a cache line)? How is this level of the cache indexed (virtually or physically indexed?) Which bits are shared between virtual and physical addresses for both kinds of pages (regular and huge)? You should know the answers to all of these before you start coding!</p> <p>Addresses look like this to the cache:</p> <p><img src="figures/cache_addr.svg" alt="File mapped memory" style="display:block; margin-left:auto; margin-right:auto" width="45%" /></p> <p>And look like this to the paging hierarchy:</p> <p><img src="figures/paging_addr.svg" alt="File mapped memory" style="display:block; margin-left:auto; margin-right:auto" width="45%" /></p> <p>You should know what each of these fields does, and how large they are at each level of the cache on the lab machine.</p> <blockquote class="discussion-title"> <p>3-1 Discussion Question</p> <p>Given a 64-bit virtual address, fill in the table below. In the last row, when we say an address bit is fully under the attacker’s control, we mean the address bit is not changed during virtual to physical address translation.</p> <div class="table-wrapper"><table> <tbody> <tr> <td> </td> <td>Using 4KB page</td> <td>Using 2MB page</td> </tr> <tr> <td>Which bits are page offset?</td> <td> </td> <td> </td> </tr> <tr> <td>Which bits are used as page number?</td> <td> </td> <td> </td> </tr> <tr> <td>Which bits are L2 set index?</td> <td> </td> <td> </td> </tr> <tr> <td>Which bits of the L2 set index are fully under your control?</td> <td> </td> <td> </td> </tr> </tbody> </table></div> </blockquote> <h3 id="using-hugepage"> <a href="#using-hugepage" class="anchor-heading" aria-labelledby="using-hugepage"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Using Hugepage </h3> <p>The default page size used by most operating systems is 4K bytes. Linux supports Huge pages, allowing programs to allocate 2 MB of contiguous physical memory, ensuring 2<sup>21</sup> bytes of consecutive physical addresses. You can use the <code class="language-plaintext highlighter-rouge">mmap</code> system call as follows to get a buffer using 2MB pages. You can use the command <code class="language-plaintext highlighter-rouge">man mmap</code> to understand the semantics for each argument used by this function.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="o">*</span><span class="n">buf</span><span class="o">=</span> <span class="n">mmap</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="n">BUFF_SIZE</span><span class="p">,</span> <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span> 
                <span class="n">MAP_POPULATE</span> <span class="o">|</span> <span class="n">MAP_ANONYMOUS</span> <span class="o">|</span> <span class="n">MAP_PRIVATE</span> <span class="o">|</span> <span class="n">MAP_HUGETLB</span><span class="p">,</span> 
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>

<span class="k">if</span> <span class="p">(</span><span class="n">buf</span> <span class="o">==</span> <span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">perror</span><span class="p">(</span><span class="s">"mmap() error</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
  <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
<span class="p">}</span>

<span class="o">*</span><span class="p">((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">buf</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// dummy write to trigger page allocation</span>
</code></pre></div></div> <p>Besides, you can see if your huge page is being allocated or not by watching the status of <code class="language-plaintext highlighter-rouge">/proc/meminfo</code>. Namely, if you run <code class="language-plaintext highlighter-rouge">cat /proc/meminfo | grep HugePages_</code>, you should see the number of <code class="language-plaintext highlighter-rouge">HugePages_Free</code> decrease by 1 when your code is using one.</p> <h3 id="implementing-the-attack-primeprobe"> <a href="#implementing-the-attack-primeprobe" class="anchor-heading" aria-labelledby="implementing-the-attack-primeprobe"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementing the Attack: Prime+Probe </h3> <p>We outline the attack procedure below and provide a few tips. The most important rule is, do not try to implement everything then test. Modern processors often contain optimizations that make them behave differently from the simplified architectures taught in class. This lab requires experimentation to find working approaches and values. You should not expect your solution to work on the first attempt, so be sure to <strong>incrementally build up your solution and verify that each step is working before proceeding</strong>.</p> <ul> <li><strong>Eviction addresses collection</strong>: You need to find a group of eviction addresses for each cache set, so that when these eviction addresses are accessed, they can fully occupy a given cache set. This step requires a clear understanding of the cache addressing scheme. We highly suggest you <strong>calculate twice, code once</strong>. Trust us, sitting down to think through cache addressing before coding will save you time.</li> <li><strong>Prime</strong>: For each cache set, access its corresponding eviction addresses to place these addresses in the cache and fully occupy the cache set. Again, be careful with the mismatch of the size of an integer and a cache line. Repeatedly accessing the same cache line will only bring one line into the cache, far from being able to monitor the whole cache set.</li> <li><strong>Wait</strong>: Similar to the Flush+Reload attack, wait for a few hundred cycles. Do not use system call functions, such as <code class="language-plaintext highlighter-rouge">sleep</code>.</li> <li><strong>Probe</strong>: For each cache set, re-access the eviction addresses for each cache set and measure their access latency. You can use simple statistic analysis (e.g., median, average, maximum, or median/average/max after removing outliers) to decode the flag.</li> </ul> <blockquote class="exercise-title"> <p>3-2 Exercise</p> <p>Complete the code in <code class="language-plaintext highlighter-rouge">attacker.c</code> to successfully extract the secret values from <code class="language-plaintext highlighter-rouge">victim-[16,4,3,2]</code>.</p> <p>Compile your code using <code class="language-plaintext highlighter-rouge">make</code>. Then use tmux, screen, or simply two SSH connections, and run <code class="language-plaintext highlighter-rouge">make run_victim-N</code> in one terminal and <code class="language-plaintext highlighter-rouge">make run_attacker</code> in another terminal. If you have problems running the victim binaries, you may need to run <code class="language-plaintext highlighter-rouge">chmod +x victim-N</code>.</p> </blockquote> <blockquote class="hint"> <p><strong>Practical Coding Tips</strong></p> <p>If the receiver needs to measure the latency of multiple memory accesses, you should pay attention to the following features that can introduce substantial noise to your communication channel.</p> <ul> <li> <p><strong>Randomizing the access pattern during probe</strong>: Similar to the Flush+Reload attack, accessing addresses with a fixed-stride pattern can trigger hardware prefetching and introduce confusing measurement results. The problem is that you do not know when you observe a cache hit, the line was always located inside the cache or it was brought into the cache by the prefetcher. Please avoid simple access patterns in your code. <!-- > We may turn off prefethers on the machine to make your life easier. Please check Piazza for the release announcement of this lab. --> <!-- > [TODO: we may turn off prefetcher. If so, we add a sentence here that we have turned off the prefetcher on the machine to make your life easier.] --></p> </li> <li> <p><strong>Probe in the reverse direction</strong>: While least recently used (LRU) is the most common example of a cache replacement policy, practical processor implementations often use much more complex policies. You may need to experiment a bit to roughly figure out how eviction and measurement works on your processor. With Prime+Probe attacks, it is common to encounter <em>cache-thrashing</em> or <em>self-conflicts</em>, a situation in which the attacker primes the cache set and evicts their own data with subsequent accesses while probing.</p> <p>For example, consider a 4-way cache using LRU, if we access four pieces of data in the order of <code class="language-plaintext highlighter-rouge">A</code>, <code class="language-plaintext highlighter-rouge">B</code>, <code class="language-plaintext highlighter-rouge">C</code>, <code class="language-plaintext highlighter-rouge">D</code>. Here, <code class="language-plaintext highlighter-rouge">A</code> will be the oldest data and <code class="language-plaintext highlighter-rouge">D</code> will be the youngest. Assume the system has noise where a random application touches a line called <code class="language-plaintext highlighter-rouge">X</code> in this set, evicting <code class="language-plaintext highlighter-rouge">A</code> out of cache. Now we have <code class="language-plaintext highlighter-rouge">B</code>, <code class="language-plaintext highlighter-rouge">C</code>, <code class="language-plaintext highlighter-rouge">D</code>, <code class="language-plaintext highlighter-rouge">X</code>, where <code class="language-plaintext highlighter-rouge">B</code> is the oldest and <code class="language-plaintext highlighter-rouge">X</code> is the youngest. Think about what if we perform the probe operation and re-accessing <code class="language-plaintext highlighter-rouge">A-D</code> in the same order as we prime them, what will happen? We will trigger the cache-thrashing effects where accessing <code class="language-plaintext highlighter-rouge">A</code> will evict <code class="language-plaintext highlighter-rouge">B</code>, and the access to <code class="language-plaintext highlighter-rouge">B</code> will evict <code class="language-plaintext highlighter-rouge">C</code>. As this pattern continues, we end up with 4 cache misses. As you see, a small amount of noise makes us lose the capability of monitoring the given cache set.</p> <p>Prior work has studied better access patterns to bypassing the cache-thrashing effects. The idea is to access the eviction addresses in one direction in Prime and in the reverse direction in Probe. Following the example above, we will need to access the four addresses in the order of <code class="language-plaintext highlighter-rouge">D</code>, <code class="language-plaintext highlighter-rouge">C</code>, <code class="language-plaintext highlighter-rouge">B</code>, <code class="language-plaintext highlighter-rouge">A</code> during probe. More studies on cache attack access ordering have been discussed in <a href="https://link.springer.com/article/10.1007/s00145-009-9049-y">Tromer et al</a>.</p> </li> <li> <p><strong>Keep data on the stack</strong>: This is more a rule of thumb than a hard “law” of microarchitectural attacks. One of our prior TAs, Joseph Ravi, found that keeping as much of your measured data (i.e., the latencies of memory accesses) on the stack (instead of the heap) as you can reduces noise. Note that, writing your measured data to an array, this operation itself, can introduce noise to our attack. Since stack anyway is frequently accessed, putting the measured data array onto stack may introduce less interference.</p> </li> </ul> </blockquote> <h3 class="no_toc" id="submission-and-grading-2"> <a href="#submission-and-grading-2" class="anchor-heading" aria-labelledby="submission-and-grading-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Submission and Grading </h3> <p>You need to submit the code <code class="language-plaintext highlighter-rouge">Part3-PrimeProbe/attack.c</code> to your assigned Github repository. We give credits if your code can <strong>reliably</strong> capture the flag in the following victims in <strong>2 minutes</strong>, and when we say reliably, we mean your attack works at least 4 out of 5 runs.</p> <p>Your code needs to first work reliably targeting <code class="language-plaintext highlighter-rouge">victim-16</code> to get 25% of the credits and then <code class="language-plaintext highlighter-rouge">victim-4</code> to get the remaining 75%. If your code can also work on <code class="language-plaintext highlighter-rouge">victim-3</code> and <code class="language-plaintext highlighter-rouge">victim-2</code>, bravo! It means your code is extremely reliable. We only see very few students made it work in the past semesters. We would be excited to grant you a 2% bonus credit for <code class="language-plaintext highlighter-rouge">victim-3</code> and 3% bonus for <code class="language-plaintext highlighter-rouge">victim-2</code>.</p> <p>As always, do not forget to include answers to the discussion questions in your lab report and submit the report to gradescope.</p> <h2 id="bonus-dead-drop--an-evil-chat-client-10"> <a href="#bonus-dead-drop--an-evil-chat-client-10" class="anchor-heading" aria-labelledby="bonus-dead-drop--an-evil-chat-client-10"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bonus: Dead Drop – An Evil Chat Client (10%) </h2> <p>If you find leaking an integer is not exciting enough, you can level it up to build a covert channel to send and receive arbitrary messages, like an evil chat client that can stealthily communicate without being monitored by privileged software, such as the OS. In this bonus part, you can decide to build a chat client using either Prime+Probe or even some other fancy side channels. There are only very few requirements.</p> <ol> <li>The sender and receiver must be <em>different processes</em>.</li> <li>The sender and receiver may only use syscalls and the functions accessible from the provided <code class="language-plaintext highlighter-rouge">util.h</code> except for <code class="language-plaintext highlighter-rouge">system()</code> and <code class="language-plaintext highlighter-rouge">clflush()</code>. There is no way to set up a shared <strong>writable</strong> address space between the sender and receiver, nor is there a way to call any obviously-useful-for-chat functions such as Unix sockets.</li> <li>If you would like to use some convenience code that stays within the spirit of the lab, please contact the course staff. Obviously, you may not use pre-packaged code from online for building covert channels (e.g., mastik).</li> </ol> <h3 class="no_toc" id="expected-behaviour"> <a href="#expected-behaviour" class="anchor-heading" aria-labelledby="expected-behaviour"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Expected Behaviour </h3> <p>The Dead Drop client should behave in the following way. Using tmux, screen, or simply two SSH connections, we can have two different terminals running on the same machine and run the following commands:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Terminal B: $ make run_receiver    // you start the receiver process in a terminal
Terminal B: Please press enter.    // the receiver prompts you to press enter to start listening for messages

Terminal A: $ make run_sender      // you start the sender in another terminal
Terminal A: Please type a message.

Terminal B: $                      // you press Enter in the receiver's terminal
Terminal B: Receiver now listening.

Terminal A: $ Hello.               // you type a message and hit enter in the sender's terminal

Terminal B: Hello.                 // receiver should generate the same message as you entered on the sender's side
</code></pre></div></div> <p>Note that you should support messages containing arbitrary number of characters. For example, the message “Hello.” above contains 6 characters and is typed by user together. Then all 6 characters appear on the receiver side. To acheive this, your sender needs to signal the receiver that “the next character is coming” in some way. Partial bonus will be awarded for solutions which only support a limited number of characters in a message.</p> <h3 class="no_toc" id="submission-and-grading-3"> <a href="#submission-and-grading-3" class="anchor-heading" aria-labelledby="submission-and-grading-3"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Submission and Grading </h3> <p>To get the bonus points, you will need to submit your working code to Github. You will then demonstrate your attack in person with a course staff during office hours or in a scheduled meeting. We will be excited to see you take this challenge! 😃</p> <h3 class="no_toc" id="acknowledgments"> <a href="#acknowledgments" class="anchor-heading" aria-labelledby="acknowledgments"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Acknowledgments </h3> <p>Contributors: Miles Dai, Weon Taek Na, Joseph Ravichandran, Mengjia Yan, Peter Deutsch, Shixin Song.</p> <p>The original Dead Drop lab (The bonus component of this lab) was developed by Christopher Fletcher for CS 598CLF at UIUC. The starting code and lab handout are both heavily adapted from his work.</p> </div> </div> <div class="search-overlay"></div> </div> </body> </html>

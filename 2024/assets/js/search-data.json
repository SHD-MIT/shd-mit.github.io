{"0": {
    "doc": "ASLR Bypasses",
    "title": "ASLR Bypasses Lab",
    "content": "Due Date: Apr 18; Last Updated Date: Mar 19 . ",
    "url": "/2024/labs/aslr.html#aslr-bypasses-lab",
    "relUrl": "/labs/aslr.html#aslr-bypasses-lab"
  },"1": {
    "doc": "ASLR Bypasses",
    "title": "Table of contents",
    "content": ". | Background | Part 1: Breaking ASLR . | Part 1A: Egghunter (20%) | Part 1B: Prefetch Side Channels (40%) | Part 1C: Speculative Probing (Bonus 5%) | . | Part 2: Code Reuse Attacks . | Part 2A: ret2win (10%) | Part 2B: Return Oriented Programming (ROP) (20%) | . | Part 3: Putting it All Together (10%) | References | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. ",
    "url": "/2024/labs/aslr.html#table-of-contents",
    "relUrl": "/labs/aslr.html#table-of-contents"
  },"2": {
    "doc": "ASLR Bypasses",
    "title": "Getting Started",
    "content": "This lab will be done on the same machine and user account as the Spectre lab, using one of the arch-sec-[1-4].csail.mit.edu as we have emailed you for the Spectre lab. We will not email you again about this information but feel free to ask TA if you forget it. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2024/labs/aslr.html#getting-started",
    "relUrl": "/labs/aslr.html#getting-started"
  },"3": {
    "doc": "ASLR Bypasses",
    "title": "Background",
    "content": "Long, long ago, programs used to be loaded at constant addresses. Every time you ran a program, every function was located at the exact same virtual address. This made it quite easy for attackers to jump to known locations in program memory as part of their exploits, as they knew that specific functions would be located at specific addresses every time. Enter Address-Space Layout Randomization, or ASLR. This mitigation randomizes the address of the program at runtime so that attackers can’t simply know the actual addresses of payloads or gadgets. It is now a necessity for most memory corruption exploits to first break the ASLR, meaning the attackers need to know how ASLR maps each constant address to a new random address. We will explore several means of breaking ASLR using, you guessed it, microarchitectural side channels. Luckily for us attackers, ASLR in Linux is applied not at the byte or word level, but at a page granularity. This means that on our x86_64 machines with 4KB pages, the lower 12 bits of an address will always stay the same (as only the virtual page number changes from run to run). ASLR is applied as a random constant, let’s call it delta, added to every virtual page number in the program’s address space. People usually use different delta values for different parts of memory. (So the stack gets its own delta, the heap gets its own delta, and the program code gets its own delta). This means that relative distances within a region are preserved under ASLR – Leaking just one pointer to a given region is typically sufficient to find anything in that region. For example, if my program binary has two methods- MethodA and MethodB, knowing the address of MethodA tells me where to find MethodB. The relative distance between MethodA and MethodB is unchanged under ASLR. As such, attackers only need to find the address for one of these addresses. We declare ASLR defeated if we can leak just a single address. In this lab, we will explore ASLR from a hardware perspective, and investigate techniques that can be used to reveal the address space layout by creating our own microarchitectural infoleaks. Lab Codebase . This lab is divided into three distinct modules – parts 1, 2, and 3. The code for each is contained within the part1, part2, and part3 folders respectively. In Part 1, you will be modifying the files part1A.c, part1B.c, and part1C.c. You should not modify main.c. In Part 2, you will be modifying part2A.c and part2B.c. The vulnerable method you will be exploiting is defined in main.c. The win and call_me_maybe methods are also defined in main.c. The gadgets to use for your ROP chain are defined in gadgets.s. You should not modify main.c. In Part 3, you will be modifying part3.c. Just like in Part 2, call_me_maybe and vulnerable are defined in main.c. The gadgets you will be using are in gadgets.o (run make to get it), and are the same as the gadgets in part2/gadgets.s. You should not modify main.c. For all three parts, you will build the lab by running make. Each subpart is a binary identified simply by the part letter. For example, Part 2 will contain: . a b build gadgets.s main.c Makefile part2A.c part2B.c . a and b are your built programs. (a is your solution for Part 2A and b is your solution for Part 2B). You can run them with ./a or ./b. In Part 3, the binary is simply called part3, as there is only one subsection for Part 3. Here’s a list of all files we will consider while grading: . - part1/part1A.c - part1/part1B.c - part1/part1C.c - part2/part2A.c - part2/part2B.c - part3/part3.c . You are free to include whatever standard library header files you’d like anywhere in the lab. If you accidentally include something that uses an illegal syscall, you’ll see the seccomp-filter complain (See the section about the ASLR lab jail). Automated Checking . We provide a check script that can tell you whether your code was correct or not. The script is very similar to the autograder we used in the spectre lab. Below are the options available with the check utility: . % ./check.py -h usage: check.py [-h] part Check your lab code positional arguments: part Which part to check? 1a, 1b, 1c, 2a, 2b, or 3? optional arguments: -h, --help show this help message and exit . You can check a specific part by specifying the part to check: . % ./check.py 1a make: Nothing to be done for 'all'. Checking part 1A... 100%|██████████████████████████████████████████████████████████| 100/100 [00:00&lt;00:00, 500.13it/s] You passed 100 of 100 runs (100.0%) Success! Good job Your score is 20 / 20 You scored 100.0% for this part! . You can also check the entire lab by running ./check.py all. At the end the autograder will tell you your grade. In the above example, we scored 100% for Part 1A. Jailing . During these exercises, you will be operating inside of a chroot and seccomp-filter jail. This jail will prevent your code from performing most system calls and file accesses, so you can’t simply read /proc/self/pagemap to determine where our mystery page is. Here’s the system calls that we allow your code to execute: . | Allowed Syscalls in this lab | . | write- Write to an already opened file descriptor. | . | access- See Part 1A. | . | close- Close a file descriptor. | . | exit / exit_group - Quit the program. | . | fstat- Needed by printf. | . If your code tries to access an illegal syscall, you’ll see the following message: . % ./part1A zsh: invalid system call ./part1A . You can use strace to trace which system calls your program made. % strace ./part1A ... execve(NULL, NULL, NULL) = ? +++ killed by SIGSYS +++ zsh: invalid system call strace ./part1A . In this example, the program was terminated for trying to use execve. You should not have to worry about the filter, as it is only there to prevent you from bypassing the lab assignment in a trivial manner, and to increase the immersion of the lab experience. If you’re curious about how the seccomp filter works, check out setup_jail in main.c of Part 1 or 3 (Part 2 doesn’t use a jail). ",
    "url": "/2024/labs/aslr.html#background",
    "relUrl": "/labs/aslr.html#background"
  },"4": {
    "doc": "ASLR Bypasses",
    "title": "Part 1: Breaking ASLR",
    "content": "In this part we will explore three different ways to break ASLR – one simple method operating at the ISA level, and two of them relying on microarchitectural attacks. In all three parts, you will be tasked with locating a single page of code within a given range. Before your code runs, we will mmap a random page into memory at a random location within this range. Everywhere inside this range except for the single page to find will be unmapped (no entry in the page table). We will then pass the range (the upper bound and the lower bound) to your code. You will scan this range using three different techniques, and return the correct page as the return value of your function. See the figure below. Your code will operate as follows: . // Your code for each exercise in Part 1: uint64_t find_address(uint64_t low, uint64_t high) { for (uint64_t addr = low; addr &lt; high; addr += PAGE_SIZE) { // The implementation of is_the_page_mapped will be // different for Parts 1A, 1B, and 1C. if (is_the_page_mapped(addr)) { return addr; } } return NULL; } . For now, all you need to do is locate the page. In later parts, we’ll need the location of this page for conducting realistic code reuse attacks in Part 3! . Part 1A: Egghunter (20%) . Egghunters are a technique commonly used in binary exploitation where you have limited code execution and are trying to find a larger payload to execute. For example, you may be able to execute a small (on the order of 64 bytes) amount of code. You have also injected a larger code payload into the program but don’t know where it is located. An “egg hunter” is a small chunk of code that is used to find the larger chunk of code. In this lab, we will be writing an egg hunter in C to scan for a page in memory. We won’t be looking for a particular value in memory (as most egg hunters do) – we will just look for the mapped page. You may be wondering what the mechanism for egg hunting actually is. Typically, it is the kernel itself! To see what we mean by this, check out this excerpt from the man page for the access system call: . ERRORS EACCES The requested access would be denied to the file, or search permission is denied for one of the directories in the path prefix of pathname. (See also path_resolution(7).) ... EFAULT pathname points outside your accessible address space... The access syscall takes a path name and a mode, and returns whether the file can be accessed by our current process. It has the following declaration: . int access(const char *pathname, int mode); . We provide access a pointer to a string containing the path name, and it will do something with it (what it does, we don’t care). We won’t be using access for its intended purpose – we will use it as an oracle for determining if an address is mapped into our address space. Notice how access will return the EACCES error if the string points to valid memory (but describes an invalid file), and the EFAULT error if the string we provide doesn’t belong to our address space. We can pass every address in the region to scan to access, and if access returns anything but EFAULT, we know the address is mapped! . Key Idea . If access returns EFAULT, our argument to pathname was unmapped. 1-1 Exercise . Implement an egg hunter using the access system call. Any error generated by a call to access isn’t directly returned by the function itself, see the “Return Value” section of the access man-page for more details. 1-2 Discussion Question . Identify one other syscall that could be used for egg hunting. Any syscall that returns EFAULT is likely to be useful for egg hunting. Sadly, while this approach works great for userspace, it won’t work on kernel addresses becuase no matter whether a kernel address is mapped or not, your access from userspace will always say the kernel address cannot be accessed. For that, we need to move to the microarchitectural level. (Parts 1B and 1C are done in userspace, but the techniques have been shown to work on the kernel as well). Grading . Each attempt (i.e., each run of ./part1/a) should run in 1 second or less and should produce the correct answer 100% of the time. (If it ever gets the answer wrong, you will receive a 0 for this part). Part 1B: Prefetch Side Channels (40%) . In this part, we will be implementing the Prefetch attack from Prefetch Side-Channel Attacks [1]. The prefetch instruction provides a hint to the hardware prefetcher to load a particular line into the cache. This instruction performs absolutely 0 access control checks. We will use the prefetch instruction to try and load every address into the cache. In particular, we will use the “Translation-Level Oracle” technique (described in their Section 3.2) to locate our hidden page. The prefetch instruction will try to translate the given virtual address into a physical address and load it into the cache hierarchy. If the address is unmapped, it will require a full page table walk (which takes many cycles!). If the page is already present in the cache hierarchy, prefetch will finish early. To be more precise, when we use prefetch on an address, if the corresponding page is unmapped, the page table entry has not appearred in any micro-architectural structures. So the processor ends up doing the following operations: . | TLB lookup (miss) | Page cache lookup (miss) | Page table walk (traverse the page table tree) | Find the entry is invalid | Done | . If the page is mapped and if it has been accessed before, the corresponding page table entry could exist in one or multiple of these structures and prefetch will finish much earlier. By timing how long prefetch takes to run, we can determine whether the given address was mapped or not. If prefetch is slow, that means a full page table walk occurred, and therefore the address was not mapped. If it is fast, that means the address is likely to have already existed in the cache hierarchy, and so is very likely to be our address. Key Idea . Prefetching a mapped address is faster than prefetching unmapped ones. Timing the prefetch instruction is a little tricky due to CPU synchronization. We recommend you follow the instruction sequence approach used by the paper authors: . mfence rdtscp cpuid prefetch cpuid rdtscp mfence . While doing this exercise, you may find referring to the source code for the prefetch paper helpful [3]. You can refer to this repo or past lab assignments for how to write inline assembly. Additionally, the GNU manual on inline assembly is quite handy [9]. For causing a prefetch instruction, you can either try the builtin _mm_prefetch(address, _MM_HINT_T2) function, or you can use the following wrapper (taken from the IAIK repo [3]): . void prefetch(void* p) { asm volatile (\"prefetchnta (%0)\" : : \"r\" (p)); asm volatile (\"prefetcht2 (%0)\" : : \"r\" (p)); } . 1-3 Exercise . Use the prefetch instruction to find the hidden page. 1-4 Discussion Question . Imagine you are the Intel engineer tasked with fixing this problem. How would you approach fixing it? . Grading . Each attempt should run in 5 seconds or less and should produce the correct result 90% of the time or better. Part 1C: Speculative Probing (Bonus 5%) . This part is quite difficult, we suggest finishing the other parts before choosing to do this one! . Having access to the prefetch instruction makes things too easy. Additionally, not all architectures have such a convenient instruction for performing attacks. Speculative Probing [2] is a more general technique that has been shown to work on many architectures. We will be implementing a modified version of the Code Region Probing attack described in Section 5.1 of the Speculative Probing paper. To conduct a speculative probing attack, you will write and exploit your own spectre gadget! Here’s an overview of how it works. First, you will write your own Spectre gadget (similar to the one you attacked in the spectre lab). Below is pseudocode you can use as a guide for your speculative probing gadget. Write this as a C function in part1C.c. def speculative_probing_gadget(condition, guess, controlled_memory): if condition: # Access 1: Derefence the \"guess\" address (if it is mapped). idx = load(guess) # If guess was not mapped, we will crash here. # Hopefully all crashes happen under speculation so the program doesn't crash! # Access 2: Modify some controlled memory at an index dependent on the first load. # This only happens if the first load didn't crash, since the index is # a function of the contents of the first load. controlled_memory[idx] += 1 . You’ll notice that this gadget operates on a subtly different mechanism than the Spetre gadgets from the spectre lab. In the spectre lab, the goal was to learn the contents of the “guess” address (reveal the contents of the first load). Here, we don’t actually care about the value of the first load. Instead, we only want to determine whether or not the load was successful. There are two cases for our guess address: either our current guess is correct, or it isn’t. If we have the right address, we can read freely from it without any issues. However, if it isn’t mapped, reading from it will cause a page fault exception (that we will observe as a segfault). Just one segfault will crash the whole program. So instead, let’s have the crashes run under speculation, and use a side channel to learn whether or not a crash happened. Key Idea . We suppress exceptions by causing them to happen speculatively, and then afterwords learn whether or not a crash happened using microarchitectural side channels. After creating the gadget, you will need to control it. You can use the following as a high-level overview of a potential attack: . | Allocate a chunk of memory to use. | Train the branch predictor for your speculative_probing_gadget. | Try an address with speculative_probing_gadget. | Learn whether or not a load occurred with time_access to your controlled memory. | . There are a few engineering problems to solve here. Notably, the contents of the probed memory could be anything! How do you know what idx’s value was? Is there a way to make our attack access controlled_memory the same way regardless of what idx was? . 1-5 Exercise . Use speculative probing to leak the address of the hidden page. | You completely control the Spectre code, so you can write it any way you like. | You may find revisiting the Spectre lab document or your Spectre lab code helpful. | Make sure that both memory accesses happen speculatively so that you don’t crash the program! | Don’t forget you can clflush any address you’d like. | . Grading . Each attempt should run in 2 minutes or less and should produce the correct result 10% of the time or better. ",
    "url": "/2024/labs/aslr.html#part-1-breaking-aslr",
    "relUrl": "/labs/aslr.html#part-1-breaking-aslr"
  },"5": {
    "doc": "ASLR Bypasses",
    "title": "Part 2: Code Reuse Attacks",
    "content": "In this part, we will explore what the consequences are for breaking ASLR. We will also get some practice constructing realistic code reuse attacks that attackers might use in the real world against vulnerable programs. We will be exploiting a category of bugs known as buffer overflows. In a buffer overflow, the program reads more information than can fit into a particular buffer, overwriting memory past the end of the buffer. Buffer Overflows . The most basic form of a buffer overflow is the stack buffer overflow. /* * vulnerable * This method is vulnerable to a buffer overflow */ void vulnerable(char *your_string) { // Allocate 16 bytes on the stack char stackbuf[0x10]; // Copy the attacker-controlled input into 'stackbuf' strcpy(stackbuf, your_string); } . If your_string is larger than 16 bytes, then whatever is on the stack below stackbuf will be overwritten. So, what’s on the stack? . When a function is called, the return address is pushed to the stack. The return address is the next line of code that will be executed. Let’s take a look at a hypothetical piece of assembly: . 0x100: call vulnerable 0x101: nop . Immediately after call vulnerable, the next instruction to execute (in this case, 0x101) will be pushed to the stack. When vulnerable is done, it will execute ret, which will pop the return address off the stack and jump to it. Let’s look at the disassembly of vulnerable to find out more: . vulnerable: # rdi contains 'your_string' # First, setup the stack frame for vulnerable 1 push rbp 2 mov rbp,rsp # Create some space for stackbuf on the stack 3 sub rsp,0x10 # Put 'your_string' into rsi (argument 2) 4 mov rsi,rdi # Put 'stackbuf' into rdi (argument 1) 5 lea rax,[rbp-0x10] 6 mov rdi,rax # Call strcpy(stackbuf, your_string) 7 call strcpy # Teardown our stack frame 8 mov rsp, rbp 9 pop rbp # Return from vulnerable (this is basically pop rip) 10 ret . Immediately upon entry to vulnerable (right before line 1), the stack will look like this: . Towards 0x0000000000000000 Stack Growth /|\\ | +---------------+ | 0x101 | &lt;- Return address! +---------------+ Towards 0xFFFFFFFFFFFFFFFF . Next, the rbp register is pushed, and some more space is made for stackbuf. So, after line 3, the stack will look like this: . Towards 0x0000000000000000 Stack Growth /|\\ | +---------------+ | ????? | &lt;- Space for stackbuf +---------------+ | Old RBP | &lt;- Saved RBP +---------------+ | 0x101 | &lt;- Return address! +---------------+ Towards 0xFFFFFFFFFFFFFFFF . Note that stackbuf sits above the return address on the stack. If we put more information into your_string than can fit into stackbuf, we will continue writing down the stack, and overwrite the return address! That means we can change what happens when vulnerable concludes executing, effectively redirecting control flow in a way we desire! . Of course, in order to actually do this, we will need to know where the code we want to run is located. This is where ASLR bypasses come in handy. By breaking the address randomization of a program, we can reveal where program instructions are located, and jump to them by overwriting return addresses (or any function pointers in a program). You can read Stack Smashing in the 21st Century for more background on buffer overflows. Part 2A: ret2win (10%) . In this activity we will perform a ret2win attack. In a ret2win attack, the attacker replaces the return address with the address of a win method that, when called, does everything the attacker wants. The attacker does not need to control any arguments passed to win– we only care that win gets executed. The vulnerable method for this lab operates as follows: . void vulnerable(char *your_string) { // Allocate 16 bytes on the stack char stackbuf[16]; // Copy the user input to the stack: strcpy(stackbuf, your_string); } . Feel free to read the source code of vulnerable for a bit more info on how the stack works. For now, you can get the win address manually (without needing to use your ASLR bypass techniques developped in Part 1) as follows: . // Cast win to a function pointer and then to a 64 bit int uint64_t win_address = (uint64_t)&amp;win; . After we run your code, we will print the resulting stack frame to the console so you can see how your attack worked. In this example, I’ve set your_string to 16 A’s ('A' == 0x41) followed by a new line ('\\n'). So we see 16 0x41’s repeated on the stack. The newline does not appear as our version of strcpy doesn’t copy the ending new line byte. This is what the stack looks like now: +-----------------------------------------+ 0x00: | 0x00007FFE055628B0 = 0x4141414141414141 | &lt;- stackbuf starts here +-----------------------------------------+ 0x01: | 0x00007FFE055628B8 = 0x4141414141414141 | +-----------------------------------------+ 0x02: | 0x00007FFE055628C0 = 0x00007FFE05562CE0 | &lt;- Saved RBP +-----------------------------------------+ 0x03: | 0x00007FFE055628C8 = 0x000055FEF9B4E91A | &lt;- Return address! +-----------------------------------------+ . We provide you some sample code to fill in the string you pass to vulnerable. For your convenience, we treat your “string” as an array of 64-bit integers. This way you can directly write to a specific slot on the stack by indexing the provided array. For example, to set the saved RBP position (index 2), you can use your_string[2] = 0x0123456789abcdef. Note on strcpy: To allow NULL characters into your buffer, we use a different definiton of strcpy than the libc one. Our strcpy allows NULL characters, but stops at newlines (0x0A, or '\\n'). This is to mirror the behavior of gets, which is commonly used in CTF stack overflow problems. Note on rbp: The base pointer rbp is reset upon entry to a C function (see line 2 of the vulnerable disassembly above). So you can set it to whatever you like during your overflow and it won’t make a difference (you will need to overwrite rbp to change the return address). Exercise 2-1 . Overwrite the return address in vulnerable with the address of win. Note . It’s ok if your code segfaults on occasion for Part 2A (it doesn’t have to work every time, so long as it works most of the time). This is because sometimes ASLR gives an address that has a new line in it, which means your overflow will stop early. Part 2B: Return Oriented Programming (ROP) (20%) . In this part, we will perform a return oriented programming attack, or ROP. ROP is a technique devised to counteract Data Execution Prevention (DEP for short, otherwise known as W^X), which is a security feature introduced to protect against simply writing your own code into the stack and jumping to it. DEP and ASLR are the foundation of all modern exploit mitigations. Just like how ASLR can be sidestepped with an information leak, DEP can be defeated by ROP. The idea behind ROP is to construct a sequence of code by combining tiny “gadgets” together into a larger chain. ROP looks a lot like ret2win, except we add more things to the stack than just overwriting a single return address. Instead, we construct a chain of return addresses that are executed one after the other. Let’s take a look at two example ROP gadgets: . gadget_1: pop rdi ret gadget_2: pop rsi ret . The above sequences of code will pop the top value off the stack into rdi or rsi, and then return to the next address. We can combine them as follows to gain control of rdi and rsi by writing the following to the stack: . +---------------+ | OVERWRITTEN | &lt;- Space for stackbuf +---------------+ | OVERWRITTEN | &lt;- Saved RBP +---------------+ | gadget_1 | &lt;- Return address +---------------+ | New rdi Value | +---------------+ | gadget_2 | +---------------+ | New rsi Value | +---------------+ | Next gadget...| +---------------+ . We can encode desired values for rdi and rsi onto the stack alongside our return addresses. Then, by carefully controlling where code execution goes, we can make the gadgets perform arbitrary computation. In fact, it has been shown that ROP is Turing Complete for sufficiently large programs. Key Idea . We can chain code sequences together by continuing to overflow the stack. For this problem, you will need to combine ROP gadgets to cause call_me_maybe to return the flag. You will use the same buffer overflow as we used in Part 2A, and you can get the address of a given gadget the same way we got the address of the win function. The gadgets are defined in gadgets.s. call_me_maybe is defined below: . void call_me_maybe(uint64_t rdi, uint64_t rsi, uint64_t rdx) { if ((rdi &amp; 0x02) != 0) { if (rsi == 2 * rdi) { if (rdx == 1337) { printf(\"MIT{flag_goes_here}\\n\"); exit(0); } } } printf(\"Incorrect arguments!\\n\"); printf(\"You did call_me_maybe(0x%lX, 0x%lX, 0x%lX);\\n\", rdi, rsi, rdx); exit(-1); } . Exercise 2-2 . Construct a ROP chain to call call_me_maybe with satisfactory arguments. Note . It’s ok if your code segfaults on occasion for Part 2B (it doesn’t have to work every time, so long as it works most of the time). This is because sometimes ASLR gives an address that has a new line in it, which means your overflow will stop early. If you are experiencing crashes and don’t know why, you can use GDB to help figure out where your exploit is going wrong. Stack Alignment . If your code seems like it should work (the correct arguments are passed to call_me_maybe, yet your program keeps crashing), it is likely due to a problem called stack alignment. The System V C ABI requires that the stack is 16 byte aligned when entering a function. When we mess about with the stack in a buffer overflow attack, we can sometimes change that alignment. There is a simple solution here- use a single ret gadget to realign the stack to 16 bytes. You can get the address of a ret instruction from objdump (use the ret instruction from any of the 6 provided gadgets). ",
    "url": "/2024/labs/aslr.html#part-2-code-reuse-attacks",
    "relUrl": "/labs/aslr.html#part-2-code-reuse-attacks"
  },"6": {
    "doc": "ASLR Bypasses",
    "title": "Part 3: Putting it All Together (10%)",
    "content": "We are now going to combine the ASLR bypasses in Part 1 with the ROP chain you wrote in Part 2. The random page from Part 1 will contain the same sequence of ROP gadgets that you had access to in Part 2B. Additionally, it will be marked executable so that it can be executed if you jump to it. Dumping the gadgets . The hidden page from Part 1 will be filled with the code from the gadgets.o file, which can be generated by running ./check.py 3. Dump the contents of gadgets.o with the following: . objdump -d gadgets.o -M intel . Objdump will report something like the following: . Disassembly of section .text: 0000000000000000 &lt;gadget1&gt;: 0: 5f pop rdi 1: c3 ret ... 0000000000000010 &lt;gadget2&gt;: 10: 5e pop rsi 11: c3 ret . The line 0000000000000000 &lt;gadget1&gt;: tells you the relative distance of gadget1 from the randomized base address. In this case, gadget1 will be located at hidden_page[0x0000] and gadget2 will be at hidden_page[0x0010] (where hidden_page is a uint8_t * that points to the page your Part 1 code found). As ASLR slides everything together by applying a constant offset, gadget2 will always be 0x10 bytes after gadget1, no matter where ASLR places them. Key Idea . Relative distances between instructions are preserved under ASLR. Performing the Attack . For Part 3, you will need to reconstruct your ROP chain using the gadgets dumped from objdump. Then, you will combine your code from Part 1 with the reconstructed Part 2 chain to complete a full ROP attack in the hidden page. Your attack will do the following: . | Locate the hidden mmap page with your choice of technique from Part 1. | Construct a ROP chain using the gadgets in the hidden page (with offsets calculated from objdump). | Call vulnerable with your payload configured. | . Exercise 3-1 . Combine your Part 1 and Part 2 attacks to defeat Part 3. On success, you should see the success flag printed to the console. A note on realism . You may be wondering why we bother with jumping to a sequence of ROP gadgets if we already have control of C code. This is to simulate attacking a real program without the ability to run code within the victim context (for example, attacking the kernel from userspace, or attacking a remote server over a netcat connection). Grading . Commit all the required C file to Github. Check your code from all the parts with the check script and make sure it passes. As always, submit your discussion questions as a PDF to gradescope. ",
    "url": "/2024/labs/aslr.html#part-3-putting-it-all-together-10",
    "relUrl": "/labs/aslr.html#part-3-putting-it-all-together-10"
  },"7": {
    "doc": "ASLR Bypasses",
    "title": "Contributors",
    "content": "Made by Joseph Ravichandran and Mengjia Yan. ",
    "url": "/2024/labs/aslr.html#contributors",
    "relUrl": "/labs/aslr.html#contributors"
  },"8": {
    "doc": "ASLR Bypasses",
    "title": "References",
    "content": "[1] Daniel Gruss et al. Prefetch Side-Channel Attacks: Bypassing SMAP and Kernel ASLR. 2016. DOI:https://doi.org/10.1145/2976749.2978356 . [2] Enes Göktas et al. Speculative Probing: Hacking Blind in the Spectre Era. 2020. DOI:https://doi.org/10.1145/3372297.3417289 . [3] IAIK Prefetch Paper Code . [4] Intel Software Developer’s Manual . [5] Stack Smashing in the 21st Century . [6] Daniel Gruss et al. KASLR is Dead: Long Live KASLR. 2017. [7] Ben Gras et al. ASLR on the Line: Practical Cache Attacks on the MMU. NDSS (2017). [8] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazières and D. Boneh, “Hacking Blind,” 2014 IEEE Symposium on Security and Privacy, 2014, pp. 227-242, doi: 10.1109/SP.2014.22. [9] GNU Extended Inline Assembly Manual . ",
    "url": "/2024/labs/aslr.html#references",
    "relUrl": "/labs/aslr.html#references"
  },"9": {
    "doc": "ASLR Bypasses",
    "title": "ASLR Bypasses",
    "content": " ",
    "url": "/2024/labs/aslr.html",
    "relUrl": "/labs/aslr.html"
  },"10": {
    "doc": "Cache Attacks",
    "title": "Cache Side Channel Attacks Lab",
    "content": "Due Date: Mar 7; Last Updated Date: Feb 20 . ",
    "url": "/2024/labs/cache.html#cache-side-channel-attacks-lab",
    "relUrl": "/labs/cache.html#cache-side-channel-attacks-lab"
  },"11": {
    "doc": "Cache Attacks",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 1: Gathering Information (20%) . | Part 1.1: Determining Machine Architecture | Part 1.2: Timing a Memory Access | . | Part 2: Capture the Flag with Flush+Reload (30%) | Part 3: Capture the Flag with Prime+Probe (50%) . | Before Attacking: Cache Addressing | Using Hugepage | Implementing the Attack: Prime+Probe | . | Bonus: Dead Drop – An Evil Chat Client (10%) | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . Log in to our lab machine that you are assigned, unicorn.csail.mit.edu for example, via ssh by running ssh username@unicorn.csail.mit.edu. You will complete this lab primarily in C. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2024/labs/cache.html#table-of-contents",
    "relUrl": "/labs/cache.html#table-of-contents"
  },"12": {
    "doc": "Cache Attacks",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Reverse engineer the cache configuration on our lab machine. | Solve two CTF (capture-the-flag) puzzles using cache-based side channels. | . In this lab, you will learn how to interact and manipulate fine-grained cache states in real hardware. Real, commercial hardware is a black box to us. To be able to mount a cache attack, we need to leverage our computer architecture knowledge to infer how a cache behaves for a sequence of instructions. Making the attacker’s life more difficult, real-world caches are far more complex than the toy example caches that we learned in the classroom. After completing this lab, you will hopefully get a glimpse of the complexity of these hardware features. Getting Prepared Before You Start . You will program in C throughout this lab. C is a low-level language that gives you more control over the hardware compared to high-level languages. Programs written in C can be directly compiled into machine code, and directly executed on the hardware without other abstraction layers. When working on microarchitectural attacks, having a high degree of control over the exact instructions being executed is essential. If you are not familiar with C, we highly recommend participating in the “CTF of C Programming” recitation. You can also get yourself familiar with C syntax by looking at the recitation materials. You will need to think about how the cache works while working on this lab. Our lab machine is huge (with 96 cores) and has a relatively complex cache hierarchy. We highly recommend you also attend the “Cache Attack” recitation, where we give an overview of the processor architecture of our lab machines. Knowing the overall organization may help you think and debug. You can also look up relevant information following the recitation materials (link will be available soon). Setting Up Your Environment . You will run your attacks using two CPU cores on the lab machine. Every student will get a different pair of CPUs such that your programs do not interfere with each other. Each pair of CPUs provided is a pair of SMT (aka, Simultaneous MultiThreading) cores. These two “logical cores” map to the same physical core and share multiple hardware resources associated with that core, such as private L1 and L2 caches. Configuration . After logging into the lab machine and cloning your repo, you must modify the SENDER_CPU and RECEIVER_CPU variables in cpu.mk to your assigned CPUs. You have to do so before running code for any portion of this lab! Only after you have configured these variables, you can remove the $error$ line from cpu.mk. Double check that you have set these values correctly. Do not use VS Code’s remote ssh plugin to connect to the server! This plugin can introduce a large degree of noise, and is likely to cause your attack to fail. ",
    "url": "/2024/labs/cache.html#introduction",
    "relUrl": "/labs/cache.html#introduction"
  },"13": {
    "doc": "Cache Attacks",
    "title": "Part 1: Gathering Information (20%)",
    "content": "Before we begin, think – what is the first step when planning to attack a system? We first need to gather information about the system’s attributes. This rule applies to attacking software, hardware, and even in real-life on non-computing systems! For example, if you wanted to plan a bank robbery, you would first need to figure out the floorplan of the bank, the locations of safes and security cameras, etc. In this part of the lab, you will see a few practical approaches people use to gain detailed microarchitecture information of commodity hardware. You will further get familiar with some common techniques and instructions that we can use to measure execution latencies on processors, which will help you mount your attacks later on. Part 1.1: Determining Machine Architecture . The simplest way to gather hardware information is to use existing public system interfaces and documentation. Here is a list of commands that can be used to determine machine architecture information on Linux. | lscpu: Provides information on the type of processor and some summary information about the architecture in the machine. | less /proc/cpuinfo: Provides detailed information about each logical processor in the machine. (Type q to exit.) | getconf -a | grep CACHE: Displays the system configuration related to the cache. This will provide detailed information about how the cache is structured. The numbers that are reported using this command use Bytes (B) as the unit. | . In addition, WikiChip is a good source of information, as it provides information specific to each processor and architecture. You can find a detailed architecture description of our lab machines (Intel Cascade Lake processors) here, which additionally provides the raw latency value for accessing different levels of caches. 1-1 Discussion Question . Fill in the blanks in the following table using the information you gathered about the cache configuration of the lab machine. You should be able to directly obtain the information for the first 3 blank columns using commands above. You will need to derive the number of sets using what you have learned about set-associative caches in 6.1910[6.004]. Raw latency can be obtained from the WikiChip document. The line size of L1 data cache has been filled in for you. | Cache | Cache Line Size | Total Size | Number of Ways (Associativity) | Number of Sets | Raw Latency | . | L1-Data | 64 Bytes |   |   |   |   | . | L2 |   |   |   |   |   | . | L3 |   |   |   |   |   | . Part 1.2: Timing a Memory Access . The information you can get from public sources can be limited, as hardware companies would not like to disclose all of their proprietary design details to general users and potential competitors. An alternative way to gather information is to reverse engineer the processor by running some very carefully designed instruction sequences on the processor and observing their behaviors. In this part, you will try to reverse engineer the latencies for accessing the cache hierarchy. Specifically, we would like to know how long it takes to access cache lines that are located in the (a) L1 data cache, (b) L2 cache, (c) L3 cache, and (d) the DRAM. The Reverse Engineering Plan . To measure the L1 latency, we can perform a load operation on a target address to bring the corresponding cache line into the L1 data cache. Then, we measure the access latency by counting the cycles it takes to re-access the same target address using measure_one_block_access_time. We have provided this code for you, and you can compile the starter code using the command make, and then run it with make run. Your task is to complete the main function in main.c to populate the three arrays dram_latency, l2_latency, and l3_latency. We suggest you start with measuring DRAM latency, since measuring DRAM latencies is the easiest. You can leverage the instruction clflush to place the target address to DRAM. Measuring L2 and L3 latencies is slightly more complex. To measure the L2 latency, we need to place the target address in the L2 cache. However, simply accessing the target address will make the address reside in the L1 cache. Therefore, need to access other addresses to evict the target address from the L1 cache. Thus, you first need to access the line to bring it into L1, then create cache conflicts to evict it into L2. When it comes to measuring the L3 latency, you need to similarly create cache conflicts to evict the cache line from both the L1 cache and the L2 cache. Helper Functions . Before you start, make sure you familiarize yourself with C syntax and several useful x86 instructions. Read the code in utility.h and understand the following functions. | rdtscp and rdtscp64: Read the current timestamp counter of the processor and return a 32-bit or 64-bit integer. | lfence: Perform a serializing operation. Ask the processor to first complete the memory loads before the lfence instruction, then start issuing memory loads after the lfence instruction. Other variants of fences exist, such as sfence and mfence. | measure_one_block_access_time: Measure the latency of performing one memory access to a given address. | clflush: Flush a given address from the cache, evict the line from the whole cache hierarchy so that later accesses to the address will load from DRAM. | print_results_plaintext and print_results_for_visualization: Print the collected latency data in different formats. The default Makefile compiles two binaries: main uses print_results_plaintext, while main-visual uses print_results_for_visualization. | . Pointer Arithmetic . Pointer arithemetic operations, such as new_ptr = old_ptr + 1, means moving the pointer forward by one element. For different types of pointers whose element size is different, the actual bytes being moved can be very different. For example, given a uint8_t pointer, since each element is 1 byte, +1 means moving the pointer foward by 1 byte. However, +1 of a uint64_t pointer means moving the pointer forward by 8 bytes. We highly suggest to use uint8_t pointers to make your address calculation easier and avoid introducing addressing mistakes. Further details about common C/C++ constructs can be found in the C Programming Recitation. Visualization Support . Microarchitectural side channels are notoriously noisy, and it is common to get inconsistent latency results from run to run. To combat noise, the most commonly used methodology is to repeat the experiments and plot the distribution of the observed latencies. We have provided two Python scripts to help you launch multiple measurements and visualize these measurements. To install python packages used in these two scripts, please run: . python3 -m pip install matplotlib tqdm . | run.py: A python script that will generate 100 runs from the main-visual binary. It will create a folder (if one doesn’t already exist) called data, and it will store all the generated samples there in json format. The script will overwrite the folder if it already exists. | graph.py: A python script that will plot the histogram of the samples collected from run.py. It will read the JSON files from the folder data and generate a pdf file of the histogram in a folder called graph. | . Expected Outcome . When grading we will not check the exact latency numbers generated by your code, since different implementations can yield different latency numbers. For example, it is unlikely that your L1 latency will match the L1 raw latency number from WikiChip. This is because our measurement involves extra latency introduced by the lfence instructions. Besides, other factors such as the frequency of the core and prefetch configurations of the cache can also affect the latency. If you want to check whether you are on the right track, you should look for the following patterns in your visualized plot. We also include an example plot below. | There are distinct peaks for DRAM, L3, and L2 latency. | The L1 and L2 latency do not need to be distinguishable. | . A reference memory latency distribution plot . 1-2 Exercise . Fill in the code in main.c to populate the arrays dram_latency, l2_latency, and l3_latency. DO NOT take latency measurements while also printing. Instead, measure then print. When debugging your code, it is tempting to write code like this, which we call “measuring while printing”. for i in l1_cache: # Observe some aspect of the cache state val = time_access(cache line i) # In the same measurement loop, print the observed value out! printf(\"The cache took %d cycles\", val) # Now we go to the next interation and measure again . Do not do this! We are no longer in the regular world, we are in the microarchitectural world, where each assembly instruction counts! . What do we mean by this? Under the hood, a “simple” call to printf involves executing a huge number of instructions. When you call printf, you are going to go to the libc library, doing some string processing, and eventually making a system call into the kernel (so, the entire CPU performs a context switch, and does who knows what else). Think about how many cache lines this call to printf will need to read/write – printing anything is a destructive action to the state of the cache. Instead, you should measure then print. We suggest structuring your code like this: . uint64_t measurements[NUM_THINGS_TO_MEASURE] # Measure for i in l1_cache: measurements[i] = time_access(cache line i) # Then, print :) print(measurements) . Tips for Reliably Triggering Cache Evictions . The following tips may help you if you get stuck when you could not observe differences between the L2 and L3 cache latency. A common pitfall is not properly evicting the target address from the L1/L2 cache due to various reasons. | Cache Line Size != Integer Size: To begin with, you should be careful with the the mismatch of access granularities. The smallest operational unit in cache is the cache line, which is larger than the size of an integer. Accessing two integers that fall into the same line (more precisely, that fall within the same cache line size aligned region of memory) will result in a cache hit, and won’t cause an eviction. So make sure to use eviction addresses that do not map to the same cache line when attempting to evict. | Advanced Cache Replacement Policy: The cache replacement policy in modern processors is more advanced than the simple policies that we learned in class, and is often not completely known to us. It may intelligently decide to keep a target address in the cache, rather than evicting it. To combat the advanced replacement policy, we suggest accessing the eviction buffer multiple times. | Virtual to physical address translation: Intuitively, we would imagine that given a cache, if we have a buffer whose size matches the cache size, then accessing each element in the buffer allows us to fully occupy every slot in the cache. However, this may not always be the case, due to virtual to physical address translation. Note that on our machine, the cache mapping is a function of physical address, while the software uses virtual address. Let’s consider a toy example where a 8KB directly-mapped cache which can hold two 4K pages. If we have a two-page-size buffer, after virtual address translation, we can end up with three posibilities: 1) the buffer covers the whole cache; 2) both pages map to the top half of the cache; and 3) both pages map to the bottom half of the cache. In this case, how can we reliably evict data from a certain cache level without the control of the address translation procedure? The common trick is to just use a buffer that is bigger than the cache itself – between 1.5x or even 4x of the cache size. Even though the eviction might still not be guaranteed, its likelihood is high enough. | . 1-3 Discussion Question . After completing your code, generate the histogram pdf file and include it in the lab report. 1-4 Discussion Question . Based on the generated histogram, report two thresholds, one to distinguish between L2 and L3 latency and the other to distinguish between L3 and DRAM latency. Submission and Grading . You will need to submit the code Part1-Timing/main.c to your assigned Github repository. Your code should be able to reproduce the histogram you submitted. You can determine whether your implementation is correct by check the description in expected outcome. Due to noise, we will run your code multiple times (5 times) and grade based on the best results. You should feel comfortable to submit your code as long as it can generate the expected results most of the time. ",
    "url": "/2024/labs/cache.html#part-1-gathering-information-20",
    "relUrl": "/labs/cache.html#part-1-gathering-information-20"
  },"14": {
    "doc": "Cache Attacks",
    "title": "Part 2: Capture the Flag with Flush+Reload (30%)",
    "content": "From now on, we are entering attack time. In this part of the lab, you will be attempting to extract secrets from a victim program. You will get a taste of solving a Capture-the-Flag (CTF) puzzle. The future labs will follow a similar pattern. Get to Know the Victim . We provide you with a victim program in Part2-FlushReload/victim, whose pseudocode is listed below. The victim program uses mmap to map a file into its own virtual address space to create a buffer. It then generates a random integer as the flag and uses the flag to index into the buffer. Your task is to learn the flag value by monitoring the victim’s memory accesses using a Flush+Reload attack. // Allocate a large memory buffer char *buf = get_buffer(); // Set the flag to random integer in the range [0, 1024) int flag = random(0, 1024); printf(flag); // Main loop while (true) { value = load(buf + flag * 128); } . The Attack Setup and Your Plan . We have set up the attack framework that enables your attacker program to share a memory region with the victim. It uses a technique called memory-mapped file, where two virtual addresses (one from your program’s address space and the other from the victim’s address space) are mapped to a same physical address, which contains a copy of a file on the hard drive. You can use the figure below to understand what is happening under the hood. The buf in the victim program and the buf in the attacker program point to the same physical address . Your attack should implement standard Flush+Reload. We are providing you with the attack skeleton and several practical tips. | Flush: Flush all the cache lines that might be accessed by the victim to DRAM using clflush. Be careful with the aforementioned cache line granularity issue. Note that cache size != integer size. | Wait: Wait a few hundred cycles for the victim to perform the flag-dependent memory load operations. Don’t use the system-provided sleep function to do this – similar to printf, this function will trigger a system call, potentially destroying cache states. | Reload: Re-access all the cache lines in the Flush step and measure the access latency to each of them. Use the threshold derived from Part 1 to decode the flag value. | . 2-1 Exercise . Complete the code in Part2-FlushReload/attacker.c to successfully extract the secret values from Part2-FlushReload/victim. To test your attack, you should first compile your code using make and generate a file for the shared buffer using python3 gen_file.py. Then use tmux, screen, or simply two SSH connections, and run make run_victim in one terminal and make run_attacker in another terminal. Make sure you are NOT executing ./victim or ./attacker directly because they will not launch the binary on your assigned cores. If you have problems running the victim binary, you may need to run chmod +x victim. Hardware Prefetchers . Modern processors can predict future memory accesses and prefetch data into the cache before it is used. Hardware prefetching is an effective performance optimization technique that is widely deployed in real-world processors. This feature can confuse your attack code. For example, regardless of what the flag value is, some Flush+Reload attack implementation may consistently observe a cache miss for the first reload operation, and cache hits for the rest of the reload operations, because the first load miss triggers hardware prefetching for the later addresses. Usually, the hardware prefetcher makes address prediction based on simple patterns, such as a linear, fixed-stride access pattern within a page. Therefore, you can bypass the prefetching effects by introducing randomness to your address access pattern. The prefethers are enabled on the lab machines. Make sure you have avoided aforementioned simple access patterns in your code. 2-2 Discussion Question . In the victim’s pseudocode above, the victim attempts to load the data indexed by flag into the value variable. How can you change the victim’s code to load the desired data without leaking the flag to the attacker? . Submission and Grading . You will need to submit the code Part2-FlushReload/attack.c to your assigned Github repository. Your code should be able to reliably capture the flag. Due to system noise, we will grade this part by executing your code multiple times. Full credit will be awarded if your code works at least 4 out of 5 runs. ",
    "url": "/2024/labs/cache.html#part-2-capture-the-flag-with-flushreload-30",
    "relUrl": "/labs/cache.html#part-2-capture-the-flag-with-flushreload-30"
  },"15": {
    "doc": "Cache Attacks",
    "title": "Part 3: Capture the Flag with Prime+Probe (50%)",
    "content": "We will now solve a more challenging CTF puzzle, leaking the flag using a Prime+Probe attack. In this setup, the attacker and the victim no longer share memory, and thus Flush+Reload will not work. Instead, to make the attack work, you need to carefully manipulate cache states and trigger cache set-conflicts. Get to Know the Victim . We have created several victim binaries, victim-N, whose pseudocode is listed below. Each victim program generates a random number as the flag. Then it finds a collection of addresses that all map to the same L2 cache set whose set index matches this flag value. The value N denotes the number of cache lines being accessed by the victim, reflecting the strength of the side-channel signal. Intuitively, using a smaller N means the victim accesses fewer ways in a given cache set, and the generated side-channel signal is weaker, making attacks more difficult. We have provided the binary for victim-[16,4,3,2], where victim-16 accesses the full cache set and is the easiest to attack. To get full credit for Part 3, you have to make your attack work on victim-16 and victim-4. See the detailed grading policy later. // Allocate a large memory buffer char *buf = get_buffer(); // Set flag to random integer in the // range [0, NUM_L2_CACHE_SETS) int flag = random(0, NUM_L2_CACHE_SETS); printf(flag); // Find N addresses in buf that all map to the cache set // with an index of flag to create a partial eviction set char *eviction_set[N]; get_partial_eviction_set(eviction_set, flag); // Main loop while (true) { for (int i = 0; i &lt; N; i++) { // Access the eviction address (*(eviction_set[i]))++; } } . Before Attacking: Cache Addressing . Given the victim’s behavior described above, you will build a Prime+Probe covert channel targeting the L2 cache. Similar to previous parts, the addresses you are dealing with in your C code are virtual addresses while physical addresses (which you will not have access to within your code) are used when indexing into caches. This fact can be more problematic in this part because you might need to do more careful calculation on the addresses. For a review of virtual memory and address translation, please refer 6.191’s (6.004’s) lectures on Virtual Memory 1 and Virtual Memory 2. It is very tempting to “fudge” the numbers in this lab (e.g., hypertuning various parameters to make incremental changes to your attack’s performance). While this approach may work, we really don’t recommend this approach. Instead, take the time to sit down and calculate all the cache parameters before you move forward may save you more time. Think about the following questions: How many bits are part of the tag in a virtual address? The set index? The offset (within a cache line)? How is this level of the cache indexed (virtually or physically indexed?) Which bits are shared between virtual and physical addresses for both kinds of pages (regular and huge)? You should know the answers to all of these before you start coding! . Addresses look like this to the cache: . And look like this to the paging hierarchy: . You should know what each of these fields does, and how large they are at each level of the cache on the lab machine. 3-1 Discussion Question . Given a 64-bit virtual address, fill in the table below. In the last row, when we say an address bit is fully under the attacker’s control, we mean the address bit is not changed during virtual to physical address translation. |   | Using 4KB page | Using 2MB page | . | Which bits are page offset? |   |   | . | Which bits are used as page number? |   |   | . | Which bits are L2 set index? |   |   | . | Which bits of the L2 set index are fully under your control? |   |   | . Using Hugepage . The default page size used by most operating systems is 4K bytes. Linux supports Huge pages, allowing programs to allocate 2 MB of contiguous physical memory, ensuring 221 bytes of consecutive physical addresses. You can use the mmap system call as follows to get a buffer using 2MB pages. You can use the command man mmap to understand the semantics for each argument used by this function. void *buf= mmap(NULL, BUFF_SIZE, PROT_READ | PROT_WRITE, MAP_POPULATE | MAP_ANONYMOUS | MAP_PRIVATE | MAP_HUGETLB, -1, 0); if (buf == (void*) - 1) { perror(\"mmap() error\\n\"); exit(EXIT_FAILURE); } *((char *)buf) = 1; // dummy write to trigger page allocation . Besides, you can see if your huge page is being allocated or not by watching the status of /proc/meminfo. Namely, if you run cat /proc/meminfo | grep HugePages_, you should see the number of HugePages_Free decrease by 1 when your code is using one. Implementing the Attack: Prime+Probe . We outline the attack procedure below and provide a few tips. The most important rule is, do not try to implement everything then test. Modern processors often contain optimizations that make them behave differently from the simplified architectures taught in class. This lab requires experimentation to find working approaches and values. You should not expect your solution to work on the first attempt, so be sure to incrementally build up your solution and verify that each step is working before proceeding. | Eviction addresses collection: You need to find a group of eviction addresses for each cache set, so that when these eviction addresses are accessed, they can fully occupy a given cache set. This step requires a clear understanding of the cache addressing scheme. We highly suggest you calculate twice, code once. Trust us, sitting down to think through cache addressing before coding will save you time. | Prime: For each cache set, access its corresponding eviction addresses to place these addresses in the cache and fully occupy the cache set. Again, be careful with the mismatch of the size of an integer and a cache line. Repeatedly accessing the same cache line will only bring one line into the cache, far from being able to monitor the whole cache set. | Wait: Similar to the Flush+Reload attack, wait for a few hundred cycles. Do not use system call functions, such as sleep. | Probe: For each cache set, re-access the eviction addresses for each cache set and measure their access latency. You can use simple statistic analysis (e.g., median, average, maximum, or median/average/max after removing outliers) to decode the flag. | . 3-2 Exercise . Complete the code in attacker.c to successfully extract the secret values from victim-[16,4,3,2]. Compile your code using make. Then use tmux, screen, or simply two SSH connections, and run make run_victim-N in one terminal and make run_attacker in another terminal. If you have problems running the victim binaries, you may need to run chmod +x victim-N. Practical Coding Tips . If the receiver needs to measure the latency of multiple memory accesses, you should pay attention to the following features that can introduce substantial noise to your communication channel. | Randomizing the access pattern during probe: Similar to the Flush+Reload attack, accessing addresses with a fixed-stride pattern can trigger hardware prefetching and introduce confusing measurement results. The problem is that you do not know when you observe a cache hit, the line was always located inside the cache or it was brought into the cache by the prefetcher. Please avoid simple access patterns in your code. | Probe in the reverse direction: While least recently used (LRU) is the most common example of a cache replacement policy, practical processor implementations often use much more complex policies. You may need to experiment a bit to roughly figure out how eviction and measurement works on your processor. With Prime+Probe attacks, it is common to encounter cache-thrashing or self-conflicts, a situation in which the attacker primes the cache set and evicts their own data with subsequent accesses while probing. For example, consider a 4-way cache using LRU, if we access four pieces of data in the order of A, B, C, D. Here, A will be the oldest data and D will be the youngest. Assume the system has noise where a random application touches a line called X in this set, evicting A out of cache. Now we have B, C, D, X, where B is the oldest and X is the youngest. Think about what if we perform the probe operation and re-accessing A-D in the same order as we prime them, what will happen? We will trigger the cache-thrashing effects where accessing A will evict B, and the access to B will evict C. As this pattern continues, we end up with 4 cache misses. As you see, a small amount of noise makes us lose the capability of monitoring the given cache set. Prior work has studied better access patterns to bypassing the cache-thrashing effects. The idea is to access the eviction addresses in one direction in Prime and in the reverse direction in Probe. Following the example above, we will need to access the four addresses in the order of D, C, B, A during probe. More studies on cache attack access ordering have been discussed in Tromer et al. | Keep data on the stack: This is more a rule of thumb than a hard “law” of microarchitectural attacks. One of our prior TAs, Joseph Ravi, found that keeping as much of your measured data (i.e., the latencies of memory accesses) on the stack (instead of the heap) as you can reduces noise. Note that, writing your measured data to an array, this operation itself, can introduce noise to our attack. Since stack anyway is frequently accessed, putting the measured data array onto stack may introduce less interference. | . Submission and Grading . You need to submit the code Part3-PrimeProbe/attack.c to your assigned Github repository. We give credits if your code can reliably capture the flag in the following victims in 2 minutes, and when we say reliably, we mean your attack works at least 4 out of 5 runs. Your code needs to first work reliably targeting victim-16 to get 25% of the credits and then victim-4 to get the remaining 75%. If your code can also work on victim-3 and victim-2, bravo! It means your code is extremely reliable. We only see very few students made it work in the past semesters. We would be excited to grant you a 2% bonus credit for victim-3 and 3% bonus for victim-2. As always, do not forget to include answers to the discussion questions in your lab report and submit the report to gradescope. ",
    "url": "/2024/labs/cache.html#part-3-capture-the-flag-with-primeprobe-50",
    "relUrl": "/labs/cache.html#part-3-capture-the-flag-with-primeprobe-50"
  },"16": {
    "doc": "Cache Attacks",
    "title": "Bonus: Dead Drop – An Evil Chat Client (10%)",
    "content": "If you find leaking an integer is not exciting enough, you can level it up to build a covert channel to send and receive arbitrary messages, like an evil chat client that can stealthily communicate without being monitored by privileged software, such as the OS. In this bonus part, you can decide to build a chat client using either Prime+Probe or even some other fancy side channels. There are only very few requirements. | The sender and receiver must be different processes. | The sender and receiver may only use syscalls and the functions accessible from the provided util.h except for system() and clflush(). There is no way to set up a shared writable address space between the sender and receiver, nor is there a way to call any obviously-useful-for-chat functions such as Unix sockets. | If you would like to use some convenience code that stays within the spirit of the lab, please contact the course staff. Obviously, you may not use pre-packaged code from online for building covert channels (e.g., mastik). | . Expected Behaviour . The Dead Drop client should behave in the following way. Using tmux, screen, or simply two SSH connections, we can have two different terminals running on the same machine and run the following commands: . Terminal B: $ make run_receiver // you start the receiver process in a terminal Terminal B: Please press enter. // the receiver prompts you to press enter to start listening for messages Terminal A: $ make run_sender // you start the sender in another terminal Terminal A: Please type a message. Terminal B: $ // you press Enter in the receiver's terminal Terminal B: Receiver now listening. Terminal A: $ Hello. // you type a message and hit enter in the sender's terminal Terminal B: Hello. // receiver should generate the same message as you entered on the sender's side . Note that you should support messages containing arbitrary number of characters. For example, the message “Hello.” above contains 6 characters and is typed by user together. Then all 6 characters appear on the receiver side. To acheive this, your sender needs to signal the receiver that “the next character is coming” in some way. Partial bonus will be awarded for solutions which only support a limited number of characters in a message. Submission and Grading . To get the bonus points, you will need to submit your working code to Github. You will then demonstrate your attack in person with a course staff during office hours or in a scheduled meeting. We will be excited to see you take this challenge! 😃 . Acknowledgments . Contributors: Miles Dai, Weon Taek Na, Joseph Ravichandran, Mengjia Yan, Peter Deutsch, Shixin Song. The original Dead Drop lab (The bonus component of this lab) was developed by Christopher Fletcher for CS 598CLF at UIUC. The starting code and lab handout are both heavily adapted from his work. ",
    "url": "/2024/labs/cache.html#bonus-dead-drop--an-evil-chat-client-10",
    "relUrl": "/labs/cache.html#bonus-dead-drop--an-evil-chat-client-10"
  },"17": {
    "doc": "Cache Attacks",
    "title": "Cache Attacks",
    "content": " ",
    "url": "/2024/labs/cache.html",
    "relUrl": "/labs/cache.html"
  },"18": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": "All content on this website, including the calendar, is subject to change. | Monday | Tuesday | Wednesday | Thursday | Friday | . | Feb 5LectureOverview | Feb 6 | Feb 7LectureSide Channel Overview | Feb 8 | Feb 9 | . | Feb 12RecitationCTF of C Programming | Feb 13 | Feb 14LectureDeep Dive of Cache Side Channels | Feb 15Lab 1 Due | Feb 16 | . | Feb 19No ClassPresident’s Day | Feb 20RecitationCache Attack | Feb 21LectureTransient Execution Side Channels | Feb 22 | Feb 23 | . | Feb 26LectureHardware-Software Contracts | Feb 27 | Feb 28LectureSide-channel Mitigations | Feb 29 | Mar 1 | . | Mar 4DiscussionRecent Microarchitecture Attacks | Mar 5 | Mar 6LectureHardware Security Module (HSM) | Mar 7Lab 2 Due | Mar 8Add Date | . | Mar 11LecturePhysical Attacks (by Joseph Ravichandran) | Mar 12 | Mar 13RecitationCTF of Physical Attacks | Mar 14 | Mar 15 | . | Mar 18TalkIoT/Sensor Security (Prof. Kevin Fu) | Mar 19 | Mar 20LectureRowhammer Attacks | Mar 21Lab 3 Due | Mar 22 | . | Mar 25No ClassSpring Break | Mar 26No ClassSpring Break | Mar 27No ClassSpring Break | Mar 28No ClassSpring Break | Mar 29No ClassSpring Break | . | Apr 1LectureRowhammer Mitigation + Reliability Solutions | Apr 2 | Apr 3LectureHardware Support for Software Security | Apr 4 | Apr 5 | . | Apr 8DiscussionMore Physical Attacks | Apr 9 | Apr 10LectureFuzzing and Bug Finding | Apr 11Lab 4 Due | Apr 12 | . | Apr 15No ClassPatriot’s Day | Apr 16 | Apr 17LectureFormal Verification for Hardware Security | Apr 18Lab 5 Due | Apr 19 | . | Apr 22RecitationRISC-V System Programming | Apr 23Drop Date | Apr 24RecitationFormal Verification Toolchain | Apr 25 | Apr 26 | . | Apr 29DiscussionHardware Support for Software Safety | Apr 30 | May 1TalkFuzzing (Prof. Manuel Egele) | May 2 | May 3 | . | May 6DiscussionFuzzing and Formal Verification | May 7Lab 6.A Due | May 8LectureTrusted Execution Environment (TEE) | May 9 | May 10 | . | May 13No ClassOffice Hour at 32-G7 Lobby | May 14Lab 6.B Due | May 15 | May 16 | May 17 | . ",
    "url": "/2024/calendar.html",
    "relUrl": "/calendar.html"
  },"19": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": " ",
    "url": "/2024/calendar.html",
    "relUrl": "/calendar.html"
  },"20": {
    "doc": "CTF of C Programming",
    "title": "CTF of C Programming",
    "content": "Throughout the class, we’ll be heavily relying on the low-level C and C++ languages. Using C and C++ allows us to manipulate the hardware at a very fine granularity, allowing us to pull off very powerful microarchitectural attacks in later labs. This is in contrast with higher-level languages, such as python, which make reasoning about the exact instructions executed by a program difficult. In this recitation we’ll primarily focus on learning how to write code in C, since C++ is a superset of C’s syntax (with limited exceptions). ",
    "url": "/2024/recitations/cpp.html",
    "relUrl": "/recitations/cpp.html"
  },"21": {
    "doc": "CTF of C Programming",
    "title": "Table of Contents",
    "content": ". | Crash Course | Pointers . | Declaration, Address-of, Dereference | Casting | A Pointer Points to Another Pointer | . | Commonly Used Data Structures . | Arrays | Strings | . | Useful for the Cache Lab . | Dynamically Allocated Memory | . | Useful for Rowhammer Lab . | C++ Maps (std::map) | . | Capture the Flag (CTF) | . ",
    "url": "/2024/recitations/cpp.html#table-of-contents",
    "relUrl": "/recitations/cpp.html#table-of-contents"
  },"22": {
    "doc": "CTF of C Programming",
    "title": "Crash Course",
    "content": "We’ll first walk through a quick code example to get you familiar with the format of C. #include &lt;stdio.h&gt; #define MAGIC_NUM 5 void sayHello(int helloNum) { printf(\"Hello World! The addition sum is: %d\\n\", helloNum); } int main(void) { int result = 1 + MAGIC_NUM; sayHello(result); return 0; } . A few things to note about this code: . | #include and #define are pre-processor directives, which are resolved prior to compilation. | #include tells the pre-processor to include the contents of the listed file (e.g. stdio.h) when compiling this file. | #define tells the pre-processor to replace all instances of the listed term with the following value (e.g. MAGIC_NUM is replaced with 5 everywhere in the code prior to compilation) | . | C is a strongly typed language, hence variables must be declared with their type (e.g. int). | printf prints a message to console. You can include variables in your printout by including a format specifier such as %d for integers. | Warning: printf is fairly heavy duty, so be cautious when calling it when measuring microarchitectural behaviours! | . | . ",
    "url": "/2024/recitations/cpp.html#crash-course",
    "relUrl": "/recitations/cpp.html#crash-course"
  },"23": {
    "doc": "CTF of C Programming",
    "title": "Pointers",
    "content": "Declaration, Address-of, Dereference . An extremely powerful tool used in C programs to interact with memory are pointers. Pointers are variables that contain a memory address, rather than a value directly. void example_method() { int a = 1234; // (1) int *b = &amp;a; // (2) *b = 9876; // (3) } . In this code, we declare an integer variable a and assign value 1234 to it. Next, we decleare a pointer variable, name it b, and assign the address of a to it, meaning we make pointer b points to the location of a. Let’s first understand three pointer-related operations. | Pointer declaration: To declare a pointer and give it a name, you need to use the type written as int *. More generally, it is written as the target data type followed by a star, such as char *, void *, etc. In the code above, we define a pointer named b and tell the compiler that it points to an integer. | Obtaining address: Every variable in C is stored in a location in memory, and thus each of them has an address. We use &amp; to obtain the address of a variable, and &amp; is called the address-of operator. As shown, we obtain the address of the variable a by writing &amp;a. | Dereference a pointer: Given a pointer, we can read or write the location pointed to by the pointer by dereferencing it. As shown, we write to the location pointed to by b by writing *b = 9876. Because b points to a, so after executing the last line of the code, if you read variable a, you will see it is now equal to 9876. | . Pointer declaration vs. Pointer dereference . Pointer declaration and pointer dereference both involve using the * notation. Make sure you understand what the * means each time you see it. For example, int *b = &amp;a; is the same as int *b; b = &amp;a;. Here, * means pointer declaration, and the assignement (i.e., =) initializes the pointer, NOT the value that the pointer points to. Next, let’s visualize the memory layout for the code above so you can get a better view. Reach to the course staff if you find the figure below difficult to understand. Casting . Occasionally you may be required to change the data type of a variable. For instance, you may want to access a specific address at a given 64-bit integer value. To do this, you can cast a variable into another as such: . void example_method() { uint64_t x = 0x12345678; // x is a 64-bit unsigned integer uint8_t *y = (uint8_t *) x; // change the type of x to make it a pointer (treat it as an address) uint8_t z = *y; // access the data pointed to by pointer y. // z now contains the data from address 0x12345678 } . A Pointer Points to Another Pointer . We can define a pointer that points to a location that holds another pointer. int a = 1234; int *b = &amp;a; int **c = &amp;b; . In the code above, int ** should be interpreted as (int *)*, meaning a pointer that points to a location holds a int *, which is also a pointer. You can dereference the pointer c in two ways. In both cases, val will be 1234. | int val = **c; | int* ptr = *c; int val = *ptr; | . ",
    "url": "/2024/recitations/cpp.html#pointers",
    "relUrl": "/recitations/cpp.html#pointers"
  },"24": {
    "doc": "CTF of C Programming",
    "title": "Commonly Used Data Structures",
    "content": "Arrays . C arrays are much like arrays in other languages! . void example_method() { int a[2]; // array declaration a[0] = 0; a[1] = 1; // access array element like in other languages printf(\"The first element of a is: %d\\n\", a[0]); printf(\"The second element of a is: %d\\n\", a[1]); printf(\"The first element of a is: %d\\n\", *(a)); // treat the array identifier as a pointer printf(\"The second element of a is: %d\\n\", *(a + 1)); } . Observe that the array variable (i.e. a) is just a pointer to the first element in the array (remember that C arrays start at 0). Specifically, ptr[index] treats ptr as an array and retrieves the entry at index index. This is the same as *(ptr+index). Pointer arithemetic operation under the hood . In a[1] and *(a + 1), the value 1 does not mean 1 byte. Instead it means 1 element. For example, if ptr points to address 0xFF00, then which address does ptr+1 point to? The answer is not 0xFF01. Instead it should be 0xFF00 + sizeof(int) = 0xFF04, as the size of an int is 4 bytes. Under the hood, the compiler is doing the pointer arithemetic computation for us by converting the 1 to 4 bytes based on the pointer type. Cheatsheet for Pointer size and Data Size . | int: 4 bytes | char: 1 byte | uint64_t means 64-bit unsigned integer: 8 bytes. | a pointer (int *, char *, void *): depends on your machine. On a 64-bit machine, no matter what data type it points to, a pointer is 64 bits, i.e., 8 bytes. | . If you incur a new data type and want to find out its size, you can printf(\"the size is: %lu\\n\", sizeof(x)) where x is the variable with the data type that you want to query about. Note that, when you cast a pointer, the address this pointer points to does not change, but the size may change, and the meaning of the associated arithemetic operation will also change. Strings . In memory, a string of “Hi!” looks like this . | Address | 0x0 | 0x1 | 0x2 | 0x3 | 0x4 | 0x5 | . | Data | ‘H’ | ‘i’ | ’!’ | ‘\\0’ | - | - | . In C, strings are just character arrays in disguise! . void example_method() { char string[6] = \"Hi!\"; printf(\"String stored: %s\\n\", string); // Print it character-by-character int i = 0; while(string[i] != '\\0') { printf(\"Character %d of string: %c\\n\", i, string[i]); i++; } } . Since a string is encoded as a fixed length array (e.g. 6 characters in our case), we need a way to indicate the end of the text. We use the null terminator (e.g. 0x00) to denote the end of the string (this is automatically inserted for you when you write “Hi!”). The above character-by-character code is actually quite dangerous! Think about what happens if you accidentally forget the null terminator here. ",
    "url": "/2024/recitations/cpp.html#commonly-used-data-structures",
    "relUrl": "/recitations/cpp.html#commonly-used-data-structures"
  },"25": {
    "doc": "CTF of C Programming",
    "title": "Useful for the Cache Lab",
    "content": "Dynamically Allocated Memory . You may have noticed that we were statically sizing our data structures in the previous sections. Sometimes you may want to allocate a dynamic amount of memory at runtime. This can be done using malloc() and free(): . void example_method() { int *array = malloc(2*sizeof(int)); // request a region that can hold 2 `int` if (array == NULL) { printf(\"malloc failed! \\n\"); return -1; } array[0] = 1; array[1] = 2; free(array); // return the memory region so others can resue it } . On success, malloc returns a pointer to the beginning of some newly allocated memory. To avoid a memory leak, make sure to deallocate dynamically allocated memory regions after you’re done with them using free(). ",
    "url": "/2024/recitations/cpp.html#useful-for-the-cache-lab",
    "relUrl": "/recitations/cpp.html#useful-for-the-cache-lab"
  },"26": {
    "doc": "CTF of C Programming",
    "title": "Useful for Rowhammer Lab",
    "content": "For later labs in the course, some advanced knowledge of C/C++ constructs may be required. We list some notes below for your reference. C++ Maps (std::map) . C++ is a slight departure from C – it is an object-oriented programming language which shares a majority of its syntax with C, and is backwards compatible with C (apart from some minor exceptions). C++ maps are very similar to Python dictionaries, with key-value pairs being assigned in a very similar fashion. A full description of this data structure can be found here. An example of using C++ maps is shown below. std::map&lt;uint64_t, uint64_t&gt; cpp_map; uint64_t key = 0xDEAD; uint64_t value = 0xBEEF; // Add or modify a key-value pair cpp_map[key] = value; // Retrieve a value for a key uint64_t key2 = 0xBAAD; uint64_t value2 = cpp_map[key2] if (value2 == 0){ assert(\"Key does not exist!\\n\"); } . ",
    "url": "/2024/recitations/cpp.html#useful-for-rowhammer-lab",
    "relUrl": "/recitations/cpp.html#useful-for-rowhammer-lab"
  },"27": {
    "doc": "CTF of C Programming",
    "title": "Capture the Flag (CTF)",
    "content": "With knowledge of these constructs, let’s try some CTF challenges! Check Piazza Post to get started. ",
    "url": "/2024/recitations/cpp.html#capture-the-flag-ctf",
    "relUrl": "/recitations/cpp.html#capture-the-flag-ctf"
  },"28": {
    "doc": "Website Fingerprinting",
    "title": "Website Fingerprinting Lab",
    "content": "Due Date: Feb 15; Last Updated Date: Feb 1 . ",
    "url": "/2024/labs/fingerprinting.html#website-fingerprinting-lab",
    "relUrl": "/labs/fingerprinting.html#website-fingerprinting-lab"
  },"29": {
    "doc": "Website Fingerprinting",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 1: Warm-up (20%) . | Hello World (Optional) | Timing Measurement | . | Part 2: Side Channel Attacks with JavaScript (60%) . | The Sweep Counting Attack | Part 2.1: Cache Trace Collection + Processing | Part 2.2: Automated Attacks with Machine Learning | . | Part 3: Root Cause Analysis (20%) | Takeaways | Contributors | . ",
    "url": "/2024/labs/fingerprinting.html#table-of-contents",
    "relUrl": "/labs/fingerprinting.html#table-of-contents"
  },"30": {
    "doc": "Website Fingerprinting",
    "title": "Lab Details",
    "content": "Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . This lab is done on your own computer, and should be (micro)architecture agnostic. If you don’t have a device to use, please reach out to the TA. You will complete this lab primarily in Python and JavaScript. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2024/labs/fingerprinting.html#lab-details",
    "relUrl": "/labs/fingerprinting.html#lab-details"
  },"31": {
    "doc": "Website Fingerprinting",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Launch an end-to-end side-channel attack to conduct website fingerprinting. | Try to understand the root cause of this attack. | . What is website fingerprinting? . In a website fingerprinting attack, an attacker tries to distinguish which website a victim has accessed on their machine. Website fingerprinting attacks can allow an attacker to gather a lot of user information, such as political views, religious beliefs, and sexual orientation. There exist many variants of website fingerprinting attacks, which we can classify into two categories (based on the resources that the attacker can access): on-path attacks and co-located attacks. An on-path attacker executes on a different machine from the victim. The attacker observes all network packets sent and received by the victim’s machine and infers the website based on the timing and size of the observed network packets. In contrast, a co-located attacker executes on the same machine and shares microarchitectural resources with the victim, including caches, DRAM, and GPUs. In the case of a low-privileged attacker, this co-location can be achieved by running attacker-controlled JavaScript code in a different browser tab. We focus on co-located attacks in this lab. Example of co-located attack setup (source) . What is the plan? . You will implement a variant of cache-occupancy side-channel attacks, called Sweep Counting Attack. This attack was originally described in the following two papers. Reading these two papers is not required to complete the lab, however they discuss several other attack techniques that you may find inspiring. | Robust Website Fingerprinting Through the Cache Occupancy Channel: Section 4.1, Page 8, Website Memorygrams. | Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel Defenses: Section 3.1, Page 5, Sweep Counting. | . You will demonstrate the attacks mounted from inside a web browser (a restricted execution environment). A browser usually cannot access fine-grained timers, cache-flushing instructions, or manipulate low-level memory. As such, after you complete this lab, you will hopefully see how versatile side channels are. Our plan of attack involves 1) writing JavaScript code to collect side-channel traces; and 2) using machine-learning techniques to analyze the traces we collect. Knowledge of the internal machine-learning techniques and mechanisms is not required. Instead, the goal is to allow you to use ML as a black-box tool. The attack you’ll develop in this lab should work in any web browser, including Chrome, Firefox, Safari, and even the Tor browser. Discussion Question (Optional) . Report your browser version, CPU type, cache size, RAM amount, and OS. We use this information to learn about the attack’s behavior on different machines. ",
    "url": "/2024/labs/fingerprinting.html#introduction",
    "relUrl": "/labs/fingerprinting.html#introduction"
  },"32": {
    "doc": "Website Fingerprinting",
    "title": "Part 1: Warm-up (20%)",
    "content": "In this part, you will familiarize yourself with the development environment and determine the timer resolution offered by JavaScript. Code Structure . | warmup.js: A JavaScript file with two functions, measureOneLine and measureNLines, which you will complete. | warmup.html: A webpage that displays the return values of the two functions. | . Hello World (Optional) . As a warm-up exercise, we will guide you through JavaScript development by writing a simple Hello World program. If you’re familiar with JavaScript, feel free to skip to Timing Measurement. Otherwise, here we provide a brief overview of JavaScript and the developer tools you’ll need for this lab. By including &lt;script src=\"warmup.js\"&gt;&lt;/script&gt; on line 31 of warmup.html, your browser downloads, runs, and executes the script’s contents immediately upon loading warmup.html. You can test this by adding a simple print function like console.log(\"Hello World!\"). You can then view the console by right-clicking the page, selecting Inspect (Cmd-Opt-I on MacOS or F12 on Windows/Linux), and then selecting Console. In Safari, you may need to unlock inspect mode with Safari &gt; Preferences &gt; Advanced &gt; Show Develop Menu. You can use console.log to debug your JavaScript code. JavaScript’s basic syntax is fairly similar to other languages you might be familiar with, such as C or Java. If you need to review JavaScript’s syntax while completing this lab, feel free to refer to various online resources. Exercise (Optional) . Add a console.log statement with a message of your choice, anywhere in warmup.js. Then, open warmup.html in your web browser and check the console to ensure that your message is displayed. Timing Measurement . Before we can execute a timing side-channel attack, we need to determine the quality (i.e., resolution) of the timer. The JavaScript’s timer (in milliseconds) can be accessed via the performance.now() API. This API yields different resolutions depending on the browser – the resolution is 0.1 ms in Chrome 92, and 1ms in Firefox 91. In warmup.js we provide measureOneLine(), an example of how we can measure the access latency of a single memory access using performance.now(). You should see the following output when you open warmup.html in a browser (you may occasionally see some non-zero entries). Website Fingerprinting Lab Warmup 1 Cache Line: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] N Cache Lines: [] . Your first task is to determine the timing resolution of performance.now() by measuring the latency of accessing multiple cache lines. Report the observed value for accessing N cache lines, where N ranges from 1 to 10,000,000. Feel free to access the memory in sequential order, as we are trying to get a rough idea about the timing resolution. You can ignore any potential effects of hardware prefetching. Since you may not get consistent results each time due to system noise, perform the measurement 10 times and report the median access latency. A cache line != A single element in an array . A cache line is different from an element in an array because they have different sizes. The cache line size of your machine is likely 64 or 128 Bytes. If you are not sure, you can use getconf -a | grep CACHE if you are running Linux or use sysctl -a | grep cachelinesize if you are running MacOS. Once you figure out the cache line size, you will want to access an array with a specified stride to make sure each access targets a different cache line. 1-1 Exercise . Complete measureNLines() such that it measures the access time of N cache lines 10 times and pushes each measurement to the end of the result array. These values will be displayed on warmup.html when you refresh the page. 1-2 Discussion Question . Use the values printed on the webpage to find the median access time and report your results as follows. | Feel free to find the median value by hand (you are not required to implement the code to do statistic calculation). | In the case that your browser complains about the buffer size that you request is too large (with an “out-of-memory” error), you can fill in the corresponding entry with “N/A”. | . | Number of Cache Lines | Median Access Latency (ms) | . | 1 |   | . | 10 |   | . | 100 |   | . | 1,000 |   | . | 10,000 |   | . | 100,000 |   | . | 1,000,000 |   | . | 10,000,000 |   | . 1-3 Discussion Question . According to your measurement results, what is the resolution of your performance.now()? In order to measure differences in time with performance.now(), approximately how many cache accesses need to be performed? . Submission and Grading . You need to submit part1/warmup.js to your assigned GitHub repository. You should not modify any other files. ",
    "url": "/2024/labs/fingerprinting.html#part-1-warm-up-20",
    "relUrl": "/labs/fingerprinting.html#part-1-warm-up-20"
  },"33": {
    "doc": "Website Fingerprinting",
    "title": "Part 2: Side Channel Attacks with JavaScript (60%)",
    "content": "The Sweep Counting Attack . In a cache-occupancy attack, the attacker leverages the fact that the attacker and victim share the same cache hierarchy. As such, an attacker can monitor its own cache access latency to estimate how much of the cache is occupied by the victim and infer the victim’s behavior. For example, consider an attacker which accesses each element of a Last Level Cache (LLC) sized buffer prior to the victim’s execution. When the victim subsequently performs a lot of memory accesses, it will evict the attacker’s buffer from the cache, and the attacker will observe a longer latency when it re-accesses the buffer. As such, the attacker’s own memory access time is roughly proportional to the number of cache lines the victim accessed. The sweep counting attack is a variant of these cache-occupancy attacks, particularly suited for the case when the attacker is restricted to using low-resolution timers. The attacker allocates a Last Level Cache (LLC) sized buffer and sequentially accesses each cache line in the buffer (like what you have done in Part 1). We call one round of scanning the buffer “one sweep over the LLC.” Then, the attack works by counting how many sweeps over the cache can fit into a single time window whose length is P ms. P ms is on the order of a few milliseconds, and it is a parameter chosen by you. You will repeatedly perform sweep counting for 5 seconds, so that the counters you gather can form a trace with the length as K, where K = 5000/P. Part 2.1: Cache Trace Collection + Processing . Let’s start with implementing the sweep counting attack to collect cache traces in JavaScript. In this attack, the victim code and attacker code resides in two separate JavaScript environments. They can be within two different browser tabs, or entirely separate web browsers on the same machine. The attacker tab will create two threads: a main thread that handles user interactions (e.g., clicking website buttons) and a worker thread that executes your provided code in the background. Note that the worker thread runs even if the attacker tab is not in the foreground. Setting Up The Web Server . To run the worker thread, modern web browsers require that you load the page from a server (rather than simply opening index.html as a file). To get around this issue, you can develop your code by running a simple web server using the following commands, run from the part2/ folder. Make sure you’re using Python3 for this step (and the rest of the lab). $ cd part2 $ python3 -m http.server Serving HTTP on :: port 8000 (http://[::]:8000/) ... Web browsers typically cache the worker thread upon loading the page, so you will need to change your browser’s settings to load updates you make to worker.js. Follow the instructions here in order to do this. If this doesn’t work for you, you can force a refresh of the service worker by opening your worker script at http://localhost:8000/worker.js, holding down shift while clicking the refresh button in your browser’s toolbar, and manually checking that the file’s contents match what you expect. Trace Collection . Open http://localhost:8000 in your preferred web browser. Pressing Collect Trace will begin a countdown, which you can use to prepare your experiment (i.e., switching to a new window). At the end of the countdown, the worker will trigger record(), which will be written by you in worker.js. The output of this function is displayed as a 1D heatmap for convenience. You can click this button multiple times without refreshing the window in order to collect multiple traces. Clicking Download Traces will allow you to download all of the traces collected in a JSON format. You will implement the sweep counting attack inside the record() function. Feel free to refer to the description of the attack at the beginning of Part 2. If you have difficulty in making the attack work, you can also refer to the pseudocode in There’s Always a Bigger Fish: A Case Study of a Misunderstood Timing Side Channel Figure 2. Trace Processing . You can process these downloaded traces in Python with code such as the following: . import json import numpy as np with open(\"traces.json\", \"r\") as f: # Load contents from file as JSON data data = json.loads(f.read()) # Convert 2D array into Numpy for data processing traces = np.array(data[\"traces\"]) # Labels are only available with the automation script. # Use the line below in part 2.2 onward to access them. # labels = data[\"labels\"] # Example data analysis print(traces.mean()) . Such traces can be used to distinguish different system events. The below image shows three traces that were collected under the following circumstances: . | Do nothing while the trace is collected | Add random system activity, moving the mouse during trace collection | Open nytimes.com in a new window during trace collection | . 2-1 Exercise . Complete the record() function in worker.js. Experiment with different P values and collect traces for the three scenarios above for the best value of P you find. Your traces will not exactly match those in the provided example, but they should be visually distinguishable from one another. 2-2 Discussion Question . Report important parameters used in your attack. For each sweep operation, you access N addresses, and you count the number of sweep operations within a time interval P ms. What values of N and P do you use? How do you choose N? Why do not you choose P to be larger or smaller? . 2-3 Discussion Question . Take screenshots of the three traces generated by your attack code and include them in the lab report. Part 2.2: Automated Attacks with Machine Learning . It is tedious and unreliable to launch the victim website manually. To automate the attack process, we provide an automation script (automate.py) based on the Selenium browser automation framework for you to use. Installing Drivers . To complete this section, you will need to install Flask, Selenium, and SciKit-Learn. Make sure you are using Python 3 and install these modules with python3 -m pip install flask selenium scikit-learn. If you do not want to change your defualt Python environment, you can use Python’s support for Virtual Environment . Selenium should automatically install the latest drivers for the browser(s) you have installed. If you are encountering running Selenium, try manually installing the driver using option 3. Using the Automation Script . You can test the automation script by collecting a few traces while your victim opens different websites using the following commands: . $ python3 automate.py --part 2 --domains google.com,nytimes.com --num_traces_per_domain 4 --out_filename traces.out . Detailed descriptions of the arguments used by the automation script can be found by executing python automate.py --help: . usage: automate.py [-h] [--browser {chrome,firefox,safari}] [--domains DOMAINS] [--num_traces_per_domain NUM_TRACES_PER_DOMAIN] [--trace_length TRACE_LENGTH] --out_filename OUT_FILENAME --part {2,3} optional arguments: -h, --help show this help message and exit --browser {chrome,firefox,safari} Browser to run automation in. --domains DOMAINS Comma-separated list of domain names to collect traces from. Defaults to google.com,youtube.com,baidu.com,facebook.com --num_traces_per_domain NUM_TRACES_PER_DOMAIN Number of traces to collect per domain. --trace_length TRACE_LENGTH The length of each recorded trace, in milliseconds. required arguments: --out_filename OUT_FILENAME Name of the output file to save traces to. --part {2,3} Set to the part of the lab you're working on. We recommend starting with a few traces from google.com and nytimes.com. Google is a lightweight website with mostly static content, while NYTimes is a heavyweight website that loads many assets, making them easy to distinguish. 2-4 Discussion Question . Use the Python code we provided in Part 2.1 to analyze simple statistics (mean, median, etc.) on the traces from google.com and nytimes.com. Report the statistic numbers. Using Machine Learning for Classification . Let’s now design a more advanced attacker. Instead of collecting four traces on two websites, we’re going to collect 20 traces on four different websites. As we’re collecting five-second traces, this will take about 7 minutes to run. Pick four of your favorite websites (school appropriate / G-rated) to classify between, pass them to the domains argument, and leave your computer alone until it’s done (to avoid introducing unnecessary noise to your attack). $ python automate.py --part 2 --domains website1.com,website2.com,website3.com,website4.com --num_traces_per_domain 20 --out_filename traces.out . Once the script has finished, you should divide your traces into a training set with 16 traces from each site, and a testing set with 4 traces from each site. The training set is used to train a machine learning model, and the testing set is used to evaluate its accuracy once training is complete. We recommend using the train_test_split function from the scikit-learn library, with test_size=0.2. Then, train a RandomForestClassifier (or another classification model of your choice from scikit-learn) on your training set. Finally, use your model to predict labels for the testing set, and check your model’s accuracy with scikit-learn’s classification_report function. An example classification report is shown below. precision recall f1-score support https://www.baidu.com 1.00 1.00 1.00 4 https://www.google.com 1.00 1.00 1.00 4 https://www.facebook.com 1.00 0.75 0.86 4 https://www.youtube.com 0.80 1.00 0.89 4 accuracy 0.94 16 macro avg 0.95 0.94 0.94 16 weighted avg 0.95 0.94 0.94 16 . 2-5 Exercise . Complete the eval() function in eval.py. In this function you should: . | Load your traces into memory | Split your data into a training and test set | Train a classification model on your training set | Use your model to predict labels for your test set | Print out your model’s accuracy using classification_report | . Use your eval() implementation to analyze the traces that you collected for four websites and print the classification result. Remember to include the traces part2/traces.out in the Github repo to get full credit for this exercise. Exercise (Optional) . Try different machine learning models to see whether you can improve on the accuracy of your previous scheme. 2-6 Discussion Question . Include your classification results in your report. Submission and Grading . You need to submit the code you changed (mainly part2/worker.js and part2/eval.py)and traces (part2/traces.out) to your GitHub repository. The accuracy (i.e. the accuracy f1-score reported in the classification report) can be affected by the websites you choose as well as your web brower versions. Anything higher than 60% accuracy will recieve full credit. In most cases, you should easily be able to achieve 80% accuracy. If your accuracy is lower than 60%, try some websites with more distinguishable content, or try an older version of the web brower. We observe Chrome 98 or earlier works well for MacOS and Chromium 113 works well for Ubuntu. If you still have trouble, reach out to TAs. ",
    "url": "/2024/labs/fingerprinting.html#part-2-side-channel-attacks-with-javascript-60",
    "relUrl": "/labs/fingerprinting.html#part-2-side-channel-attacks-with-javascript-60"
  },"34": {
    "doc": "Website Fingerprinting",
    "title": "Part 3: Root Cause Analysis (20%)",
    "content": "Machine-learning-assisted side-channel attacks are very powerful as they are able to find correlations across traces and can tolerate medium to heavy amounts of noise. A key challenge with using machine learning, however, is that it doesn’t provide us insight as to why an attack works. Given that JavaScript is a high-level language, we do not have full control or knowledge of the instructions being executed on the processor, nor do we have a good idea of where our signal is actually coming from! . In this part, you will try a slightly modified attack to learn about the pros and cons of ML-driven attacks. So far, we have implemented the sweep counting attack, a variant of the cache-occupancy attack. As the name of the attack suggests, this attack leaks information via cache interference. But what if we remove the cache accesses in the code? Will the attack still work? . 3-1 Exercise . Copy your record() function from part2/worker.js to part3/worker.js and modify record() by removing all memory accesses in your code. After removing the memory accesses, all that will remain in loop body is an add operation for incrementing a counter. Therefore, what you end up doing is counting the number of times you perform the add operation within a time window of length P ms. Then re-collect the traces for the four sites you previously examined and report the accuracy. Remember to include the traces part3/traces.out in the Github repo to get full credit for this exercise. 3-2 Discussion Question . Include your new accuracy results for the modified attack code in your report. 3-3 Discussion Question . Compare your accuracy numbers between Part 2 and 3. Does the accuracy decrease in Part 3? Do you think that our “cache-occupancy” attack actually exploits a cache side channel? If not, take a guess as to possible root causes of the modified attack. Note: Without detailed investigation, you will not be able to verify your answer to this question. We will give full credit as long as the reasoning behind your guess is logical. If you’re curious as to the reasons why, we recommend reading the paper There’s Always a Bigger Fish: A Case Study of a Misunderstood Timing Side Channel. We will also discuss this paper in one of the recitation sessions. Submission and Grading . You need to submit your code (part3/worker.js) and the traces (part3/traces.out) to your GitHub repository. Anything higher than 60% accuracy will recieve full credit. ",
    "url": "/2024/labs/fingerprinting.html#part-3-root-cause-analysis-20",
    "relUrl": "/labs/fingerprinting.html#part-3-root-cause-analysis-20"
  },"35": {
    "doc": "Website Fingerprinting",
    "title": "Takeaways",
    "content": "Congratulations on finishing the website fingerprinting lab. We hope your very first experience with the side-channel attack in this class went well. After completing this lab, it would be valuable to recap and think about what you have learned. As the developers of the lab, we hope that, in addition to giving you a taste of attack engineering, the lab can enlighten you with the following takeaway message: Side channels are versatile in modern systems, and with the help of machine learning techniques, they become easier to pull off. However, finding the root cause of a side channel now presents as a new challenge. ",
    "url": "/2024/labs/fingerprinting.html#takeaways",
    "relUrl": "/labs/fingerprinting.html#takeaways"
  },"36": {
    "doc": "Website Fingerprinting",
    "title": "Contributors",
    "content": "Jack Cook, Mengjia Yan, Joseph Ravichandran and Peter Deutsch. ",
    "url": "/2024/labs/fingerprinting.html#contributors",
    "relUrl": "/labs/fingerprinting.html#contributors"
  },"37": {
    "doc": "Website Fingerprinting",
    "title": "Website Fingerprinting",
    "content": " ",
    "url": "/2024/labs/fingerprinting.html",
    "relUrl": "/labs/fingerprinting.html"
  },"38": {
    "doc": "For Instructors",
    "title": "Looking to use our course materials in your course?",
    "content": "There are two things you won’t want to miss: . | Our lab handouts can be found here. | The lab starter code and deployment instructions can be found here. | . ",
    "url": "/2024/forInstructors.html#looking-to-use-our-course-materials-in-your-course",
    "relUrl": "/forInstructors.html#looking-to-use-our-course-materials-in-your-course"
  },"39": {
    "doc": "For Instructors",
    "title": "Get in touch!",
    "content": "Reach out to our team at hw-sec-lab-dev at mit.edu before using our code in your course. We can provide you the instructor’s solutions, a starter gradebook, and grading scripts. ",
    "url": "/2024/forInstructors.html#get-in-touch",
    "relUrl": "/forInstructors.html#get-in-touch"
  },"40": {
    "doc": "For Instructors",
    "title": "For Instructors",
    "content": " ",
    "url": "/2024/forInstructors.html",
    "relUrl": "/forInstructors.html"
  },"41": {
    "doc": "Formal Verification",
    "title": "Table of Contents",
    "content": ". | The Big Picture . | Model Checking = Cover All Reachable States | Symbolic Execution Using Rosette | How does Rosette work internally? | . | Verifying The Tiny CPU . | Tiny CPU Specification | From RTL to Rosette | How does “yosys+knox” work internally? | . | Learn Rosette Syntax . | Rosette and Racket | Define Functions, Call Functions, and Define Variables | Include libraries | Struct | Bitvector and vector | Printf | Branch and Loops | . | Hands-on Exercise . | Exercise 1: Interact With Tiny CPU in Rosette | Exercise 2: Encode Specification into Rosette | Exercise 3: Use assert to Express “Implementation Matches Specification” | . | . ",
    "url": "/2024/recitations/formal.html#table-of-contents",
    "relUrl": "/recitations/formal.html#table-of-contents"
  },"42": {
    "doc": "Formal Verification",
    "title": "Formal Verification of RTL Implementation",
    "content": "Formal verification is a well-explored research area and has been shown to be effective in hardware verification. In this recitation, we will provide an overview of one type of formal verification technique, called bounded model checking. You will learn how to use a powerful toolchain that combines Yosys, Rosette, and several scripts to perform bounded model checking and find processor bugs on RTL code. It will give you a taste on how to perform automatic bug finding and understand the challenges of this topic. We will start by giving you the big picture of formal verification and how the toolchain will help acheive our goals. Next, we will go through the basics of Rosette, which programs using a functional programming lanaguge. It might be a pain to swtich from C/Python to a functional programming lanague, but we will go through the start code with you and get you fully prepared. Finally, you will try to play with the toolchain and automatically find bugs as you like. Getting Started . The starter code of the recitation is here. It could be run on our lab machine unicorn.csail.mit.edu. Log in with the same user account as previous labs. Alternatively, you can use the docker file provided in the starter code to run the lab locally. Instructions to run the docker are provided here. (The docker image takes ~20 minutes to build.) . ",
    "url": "/2024/recitations/formal.html#formal-verification-of-rtl-implementation",
    "relUrl": "/recitations/formal.html#formal-verification-of-rtl-implementation"
  },"43": {
    "doc": "Formal Verification",
    "title": "The Big Picture",
    "content": "The general idea of formal verification is far from complex. As shown in the picture below, we have 1) an implementation of the hardware (e.g., verilog code, miniSpec code), which can be complex and potentially buggy, and 2) a clearly-defined specification of what we expect the hardware to do, like the RISC-V manual we use in lab6.A. The goal of formal verification is to check the implementation matches the specification under all possible inputs to the hardware. Model Checking = Cover All Reachable States . We consider our hardware as a state machine, the concept of model checking is to check for all the reachable states of the system to satisfy certain properties/specifications. One approach is to do exhaustive search, but we may suffer from serious scalability issues, especially when the input space is huge. In this recitation, we will use a symbolic execution engine and leverage some help from advanced mathmatical techniques (SMT solvers) to automatically search the space in an efficient and smart way. Let us introduce our first tool, a programming language, called Rosette. Rosette is a language extension based on Racket to add the symbolic execution feature. Language extension is similar to a library in C/python, but can provide more syntax-related features in addition to extra functions. We will explain how Rosette works using the following example. Symbolic Execution Using Rosette . Exercise . To test the code by yourself, run cd RosetteExample &amp;&amp; racket example.rkt . Broken Environment . In case the command above returns -bash: racket: command not found on unicorn, try source /knox/envSetup.sh to set environment variables. (This should not happen normally because this source command should be run automatically when you log in.) . Here is a function that can trigger some forbidden execution path under some non-trivial condition: . #lang rosette ; # Here is a python version: (define (f x y) ; def f(x, y): (when (= (* (+ x 10) 2) y) ; if (x+10)*2 == y: (assert #f))) ; assert False (f 1 10) ; f(1, 10) . We want to check this program (corresponding to the implementation in the big picture figure) against a specification, which says the program does not trigger an assertion. We will need to check it against all the inputs. Here, rather than using concrete input values, we use Rosette to declare the inputs as symbolic values and ask Rosette to check all possible inputs. No worries about the syntax for now, we will go through the syntax in detail in a few minutes. (define-symbolic x integer?) (define-symbolic y integer?) (verify (f x y)) . When running the verify command, Rosette will do some magic internally and generate an input (x and y) that fails the function: . (model [x 0] [y 20]) . Excellent tool! Using Rosette, we are capable to write a program embedded with assert (a state that we should not reach) and ask Rosette to automatically generate the inputs that can lead us to that invalid state. We call the above output a counterexample. How does Rosette work internally? . Skipping this part will not prevent you working on the recitation. But read on if you are curious. Symbolic Execution. The first technique Rosette uses is called Symbolic Execution. Normally, a program will execute on concrete input values. For example, (* (+ 1 10) 2) will return 22. However, you will forget how 22 is computed. Executing on symbolic value, instead, will remember how a new value is computed from the symbolic input values by using a syntax tree as the return value. For example, running the following program in Rosette will print exactly (* (+ x 10) 2): . (define-symbolic x integer?) (println (* (+ x 10) 2)) . With symbolic execution, every time a branch is met, the condition of the branch is actually an expression of symbolic values that encodes the syntax tree that computes this condition. Since we do not know whether the symbolic expression is true or false, we will execute both sides of the branch. But we have to use an extra data structure to remember the symbolic expressions of all branches in the history and remember which direction we took. This extra data structure is called path condition that can be extracted using (vc-assumes (vc)) in Rosette. This following example will print Path1: (= 0 x) and Path2: (! (= 0 x)) . (define-symbolic x integer?) (if (= x 0) (printf (~a \"Path1: \" (vc-assumes (vc)) \"\\n\")) (printf (~a \"Path2: \" (vc-assumes (vc)) \"\\n\"))) . Finally, every time you make an assertion under a specific path, the path condition will be combined with the asserted expression. This combined expression will be used to determine whether the assert true will be guaranteed. For example, the following code will print (|| (! (= 0 x)) (= x y)), which is the condition that the assert true will be guaranteed. (define-symbolic x integer?) (define-symbolic y integer?) (when (= x 0) (assert (= x y))) (println (vc-asserts (vc))) . In summary, with the techniques of syntax tree expression and path condition, symbolic execution converts assertions in the program into symbolic expressions that need to be asserted to be true. SMT solver. The second part of Rosette is about using an SMT solver as the backend. With symbolic execution, the problem of finding a forbidden execution path is converted to a pure mathematical problem. Rosette will send the symbolic expression (i.e. a logic formula) to a logic solver (i.e. a SMT solver) and the SMT solver will find a binding of symbolic values that trigger the forbidden execution path. For example . (model [x 0] [y 20]) . shows a binding that x is 0 and y is 20. In the rest of the recitation, free feel to print out symbolic expressions and path conditions to get a sense of what Rosette is doing. ",
    "url": "/2024/recitations/formal.html#the-big-picture",
    "relUrl": "/recitations/formal.html#the-big-picture"
  },"44": {
    "doc": "Formal Verification",
    "title": "Verifying The Tiny CPU",
    "content": "This is probably a good time to introduce our example CPU that we try to verify: the Tiny CPU. Throughout this recitation, we will use it to demonstrate how to use the model checking framework. Tiny CPU Specification . We will verify a verilog implementation of tiny_cpu matches its specification as below. The tiny_cpu cannot really be simpler. It uses 4 bits for all registers. It has two general purpose-register R1 and R2, as well as a pc register. At each cycle, it reads an instruction from a 16-entry instruction memory and decodes&amp;executes it as 3 possible instructions, INC, ACC, and NOP, as shown in the table above. Then, pc will be incremented by 1. (pc can overflow from 0xf to 0x0.) There is no data memory. We implement it in verilog as a multi-cycle cpu (tiny_cpu/tiny_cpu.v). It executes instructions one by one. It takes 2 cycles to execute an INC instruction, 3 cycles to execute an ACC instruction, and 1 cycle to execute an NOP instruction. Here is the internal stage transition in the implementation: . At the commit stage, it will increment the pc and update R1, R2 according to the instruction. From RTL to Rosette . We have seen that the Rosette is a functional programming language, far different from our RTL code. Therefore, the first step is to lift the RTL code that we are trying to verify to Rosette. You can view this process as a translation process from one language to another. For this purpose, we use a toolchain “yosys+knox“ developed by Anish Athalye from the PDOS group at MIT. Take our tiny_cpu as an example, run ./scripts/v2rkt.sh will convert the tiny_cpu/tiny_cpu.v into generated_src/tiny_cpu.rkt. The converted Rosette code provides a few APIs to simulate the tiny_cpu. To demonstrate how these APIs can be used, we provide src/impl.rkt. It will simulate the tiny_cpu for 20 cycles and print its state at each cycle. Exercise . Run ./scripts/v2rkt.sh to convert Verilog to Rosette. Then, simulate tiny_cpu for 20 cycles with racket src/impl.rkt. How does “yosys+knox” work internally? . Here is the story of how this toolchain is created. Anish, the author of knox was looking for a way to convert Verilog code to Rosette so that he could symbolically execute the Verilog code to conduct some interesting research. Traditionally, the most direct method to translate Verilog code to a simulator code involves parsing the Verilog into some netlist representation and using the netlist to generate the target code in the new language. There are many compilers (or more precisely, synthesis tools) available to do this, yosys is one of them. But even with the help of them, you need to deal with a lot of tedious syntax problems of Racket. Anish, instead, used chatGPT to do that. End of Story. tried to find a simpler way. He realized one target code called SMT2 that yosys can translate Verilog to, looks very similar to Racket code. (Check the file generated_src/tiny_cpu.smt2 by yourself.) Then, he decided to teach Racket to understand SMT2 code! . Remember that we say Rosette is a language extension to Racket? Anish wrote a new extension to Racket called yosys so that Racket can understand the syntax of SMT2 code and define some Racket functions from it. These functions are the APIs generated_src/tiny_cpu.rkt provides to us. Actually, the only difference between generated_src/tiny_cpu.rkt and generated_src/tiny_cpu.smt2 is an extra line of #lang yosys that imports the yosys extension. Hoepfully now you can understand better about “Language extension is similar to a library in C, but can provide more syntax-related features in addition to extra functions”. It can really do some magic. ",
    "url": "/2024/recitations/formal.html#verifying-the-tiny-cpu",
    "relUrl": "/recitations/formal.html#verifying-the-tiny-cpu"
  },"45": {
    "doc": "Formal Verification",
    "title": "Learn Rosette Syntax",
    "content": "The transition from a C-programming style to a functional-programming style like Rosette can be painful. But hopefully, you are motivated enough to tackle this challenge so far. We will guide you to read through src/impl.rkt to warm you up. Rosette and Racket . Firstly, you might notice the filename extension is .rkt. This is because technically, most code here is not Rosette code but Racket code. As we mentioned, Rosette is a language extension based on Racket. To render the file with your editor, your should search for Racket plugins. Here are the official versions: VScode and Sublime. Vim and Emacs probably support racket out of the box. If not, check: Vim and Emacs . Racket’s official document page is extremely convenient to search for information about sytax or functions. Just put the function name into the search box at the left-top corner. We will also provide links to this document while going through the code. Define Functions, Call Functions, and Define Variables . Skim through the file, you can see a bunch of functions are defined in a pattern: . (define (init-impl imem) ; STEP1: Initialize a new tiny_cpu whose states are all zeros. (define tiny_cpu (new-zeroed-tiny_cpu_s)) ; STEP2: Pull up the reset signal and advance cpu state to the next cycle. (set! tiny_cpu (step (with-input tiny_cpu (input* 'rst #t)))) ..... ; STEP4: Create a impl structure and return it. (impl tiny_cpu) ) . This defines a function named init-impl which takes one argument named imem. The last line of the function body (impl tiny_cpu) is the return value. To call a function, we put brackets around the function name and the argument. For example, (impl tiny_cpu) calls a function named impl with argument tiny_cpu. The variables are defined in a similar way. The first line of the function body above defines a variable named tiny_cpu, which is the return value of function new-zeroed-tiny_cpu_s (we will explain the meaning of new-zeroed-tiny_cpu_s later). Note that in a functional programming language like Racket, people try to avoid updating the value of a variable (for code reusability). However, you can still update its value with set! function. For example, the code above updates the value of tiny_cpu to the value returned by (step (with-input tiny_cpu (input* 'rst #t))) (we will also explain the meaning of step later). Actually, it is a convention to add ! to the function name if it updates the value of its arguments. Include libraries . The first three lines in the file are the basic information about the whole file. #lang rosette states the file use rosette as a base language. (require ...) includes (or imports) a few other files. (provide ...) states that if this file is required by another file, that file will have access to use these provided functions and variables. Struct . Same as many other languages, you can define your own data structure in Racket, which enables modular designs. Actually, this whole file is defining functions operating on a struct named impl. We use init-impl to initialize a tiny_cpu implementation, use step-impl! to simulate the implementation for 1 cycle, and use impl-commit to indicate whether it will commit an instruction at this cycle. It is a naming convention to have the struct name impl in the function names and these functions’ first arguments are actually also a variable with impl type. To understand these functions, the table below summarizes the default APIs to operate on a struct. |   | API | Example | . | Define a new struct | (struct id (field1 field2 …)) | (struct impl (tiny_cpu)) defines a new data type named impl, it has a field named tiny_cpu. | . | Initialize a struct | (id x1 x2 … ) | (impl (new-zeroed-tiny_cpu_s)) returns a impl struct whose field is initialized with the return value of function new-zeroed-tiny_cpu_s | . | Extract a field | (id-field INST) | (impl-tiny_cpu impl) takes an instance named impl and returns the value saved in its tiny_cpu field. | . | Update a field | (set-id-field! INST value) | (set-impl-tiny_cpu! impl (step …)) uses the return value of function step to update the tiny_cpu field of instance impl | . Bitvector and vector . When we model and simulate a cpu, most data is in bit or vector of bits formats. To represent these data, we will frequently use bitvector and vector structure in our Racket code. bitvector is a datatype that saves bits with a fixed width (e.g., 4 bits, 32 bits). It can be used to represent a register or an entry of the memory. vector is a fixed-length array. It can be used to represent a memory. For example, in the testMe function in src/impl.rkt. we call init-impl function to initialize a tiny_cpu with an imem as the argument. The imem is: . (vector (bv 0 4) (bv 1 4) (bv 0 4) (bv 1 4) (bv 0 4) (bv 1 4) (bv 0 4) (bv 1 4) (bv 0 4) (bv 1 4) (bv 0 4) (bv 1 4) (bv 0 4) (bv 1 4) (bv 0 4) (bv 1 4)) . It initializes a 16-element vector and each element is a 4-bit bitvector whose value is either 0 or 1. For more APIs on bitvector and vector, the official document is the most helpful resource. We also summarize a few APIs here: . |   | API | Example | . | Initialize a bitvector | (bv value size) | (bv 1 4) returns a 4-bit bitvector whose value is 1. | . | Compare two bitvectors | (bveq x y) | (bveq (bv 1 4) (bv 0 4)) returns #f since 1!=0 | . | Add two bitvectors | (bvadd x y) | (bveq (bv 1 4) (bv 15 4)) returns (bv 0 4) | . | Concatenate bitvectors | (concat x1 x2 …) | (concat (bv 1 4) (bv 0 4)) returns (bv 16 8) | . | Initialzie a vector | (vector v1 v2 …) | (vector (bv 0 4) (bv 1 4)) returns a 2-element vector | . | Extract an element from a vector | (vector-ref vec pos) | (vector-ref (vector (bv 0 4) (bv 2 4)) 1) returns (bv 2 4) | . | Extract an element from a vector with a bitvector | (vector-ref-bv vec pos) | (vector-ref (vector (bv 0 4) (bv 2 4)) (bv 1 4)) returns (bv 2 4) | . Be careful with the difference between vector-ref and vector-ref-bv. You might want to use the later one in many cases. Printf . Printing is the most basic way to debug a program. Racket provides quite a few different ways to print out a datatype in different formats. We will only use a most simple way: . |   | API | Example | . | print out a few variables | (printf (~a x1 x2 …)) | (printf (~a “commit: “ (impl-commit impl) “\\n”)) prints out something like “commit: #f” and starts a new line. | . Branch and Loops . Here is how to write the simplest control flows in Racket with when, cond (aka, case switch) and for: . |   | API | Example | . | if condition | (when condition expr1 expr2 …) | (when (bveq inst INC) (set! R1 (bvadd R1 (bv 1 4))) (set! R1 (bvadd pc (bv 1 4)))) executes the INC instruction. | . | case switch | (cond [cond1 expr1 expr2 …] [cond2 expr1 …] [else expr1 …]) | (cond [(bveq inst INC) (set! R1 (bvadd R1 (bv 1 4))) (set! R1 (bvadd pc (bv 1 4)))] [else …]) decodes and executes instructions. | . | for loop | (for ([loopVar (in-range loopNum)]) expr1 expr2 …) | check the for loop in testMe function in src/impl.rkt | . ",
    "url": "/2024/recitations/formal.html#learn-rosette-syntax",
    "relUrl": "/recitations/formal.html#learn-rosette-syntax"
  },"46": {
    "doc": "Formal Verification",
    "title": "Hands-on Exercise",
    "content": "With all the information above, you can start the following exercises! . Exercise 1: Interact With Tiny CPU in Rosette . First, let’s ensure we can run the tiny cpu which was lifted from RTL to Rosette. You can even interact with the CPU and monitor its execution. Here is a reference of the APIs provided by tiny_cpu.rkt and used in src/impl.rkt: . |   | API | Return Value | . | Initialization | (new-zeroed-tiny_cpu_s) | a new structure that saves the state of an initialized tiny_cpu (tiny_cpu_s type) | . | Simulation | (step (with-input tiny_cpu (input* ‘rst #t))) | a new state of tiny_cpu which is derived by simulating from state tiny_cpu by 1 cycle with input rst fed with true (you can change #t to #f to feed false to rst) | . | Extract States | (tiny_cpu_s-REGNAME tiny_cpu) | the value saved in register REGNAME (i.e., R1, R2, pc in our case) | . Exercise 1 . After converting Verilog to Rosette with./scripts/v2rkt.sh. Isn’t it exciting to be able to simulate a cpu and extract the value of any possible registers at any cycle? . Currently, we only print the commit signal at each cycle. Complete the print-impl function in src/impl.rkt to further print the pc, R1, and R2 registers, with the APIs provided in the table above. You can also take print-impl-imem function as an example. You can test the code with racket src/impl.rkt. It will run the testMe function at the end of the file, which simulates the implementation for 20 cycles. With your code, you should see pc, R1, and R2 are printed out at each cycle. Exercise 2: Encode Specification into Rosette . The yosys+knox toolchain allows us to lift the RTL implementation to Rosette, meaning we have the model that we want to check. We now need to also encode the specification of the processor into Rosette. Specification is basically “what we expect” the hardware to do. Unfortunately, such expectation is usually expressed in human language with unavoidable ambiguity (imagine your boss is asking you to add some fancy features in hardware, it is probably very high-level and misses details). However, to conduct a formal verification, it is very important to express the specification perfectly precisely, because otherwise, Rosette will not know how to check the implementation. In this recitation, we will manually translate the tiny_cpu specification into Rosette. We provide you src/spec.rkt as a start code. You can execute it with racket src/spec.rkt. But before you write your part of the code, it does nothing at each cycle. Exercise 2 . Complete the step-spec! function in src/spec.rkt to update the tiny_cpu’s state according to the specification figure above. Your specification code should execute 1 instruction at each cycle (while the implementation might take multiple cycles for 1 instruction). Test your code with racket src/spec.rkt. It will execute the program defined in testMe at the end of the file for 10 cycles. With your code, you should see, at each cycle, the state is updated properly according to the program. Bad Syntax Error . If you see an error of let: bad syntax (missing binding pairs or body), this likely means you left one case of the cond to be empty, which is not allowed in Racket. You can solve it by adding a dummy line (void). How do formal people ensure a precise ISA specification? . The ISA manuals are usually hundreds of pages, and it is non-trivial to manually translate them into an executable specification. Researchers working on formal verification always spend a lot of effort translating the manual into a language that is compatible with their verification platform (e.g., Coq, HOL4, and our Rosette). Recently, they made insteresting progress that tries to solve it once and for all. Instead of translating ISA designers’ human language manual, they try to take control and ask ISA designers to write ISA manual in an executable language from the beginning! “Sail is a language for describing the instruction-set architecture (ISA) semantics of processors. Sail aims to provide an engineer-friendly, vendor-pseudocode-like language for describing instruction semantics.” From Sail, compilers can generate Latex snippets for documentation, C/Ocaml for executable emulator, Isabelle/HOL4/Coq for formal reasoning. Exercise 3: Use assert to Express “Implementation Matches Specification” . We are almost there! We will now fill in the last piece of our framework, which will compare the execution of the implementation and specification and assert they match. What does “match” mean exactly? The implementation of hardware can be far more complicated than the specification. It can take different cycles to finish one instruction, there can be multiple instructions in-flight, and can have different book-keeping structures to remember the execution stages of all in-flight instructions. For a CPU design, all states in the implementation are called micro-architectural states and the states described in the specification only are called architectural states. In order to compare the execution trace from this complicated implementation to the specification, we need to look at the cycle-by-cycle trace of micro-architectural states and extract certain states at certain cycles that can reflect the architectural states. In src/impl.rkt, we provide a function called impl-archState to extract those certain states from all micro-architecture states. And provide a function called impl-commit to indicate at which cycle, the states extracted by impl-archState should be compared to the architectural state. We use the function spec-archState in src/spec.rkt to extract the architectural state from the specification. Those states are assert to be the same in the simu function in src/veri.rkt. Specifically, src/veri.rkt will simulate the specification and implication with an initial imem containing only symbolic value. The verify function will ask SMT solver to check all assert and try to find a concrete instance of the imem that violates some asserts. If SMT provides a counterexample, we query it for the concrete instance of imem and simulate the specification and implication again to demonstrate the assert fails. Exercise 3 . Complete the impl-archState function in src/impl.rkt and spec-archState function in src/spec.rkt. They extract the architectural state of the implementation and specification. Then, run racket src/veri.rkt to verify the tiny_cpu. You should see “Counterexample Found” and then the counterexample is simulated and the states of implementation and specification are printed out whenever an instruction is committed. Could you describe the bug found in the implementation? . Maybe you want a function to combine multiple bitvector together? Try concat function mentioned here. Congratulations! You have finished our materials on formal verification. Hope you enjoy it. ",
    "url": "/2024/recitations/formal.html#hands-on-exercise",
    "relUrl": "/recitations/formal.html#hands-on-exercise"
  },"47": {
    "doc": "Formal Verification",
    "title": "Formal Verification",
    "content": " ",
    "url": "/2024/recitations/formal.html",
    "relUrl": "/recitations/formal.html"
  },"48": {
    "doc": "CPU Verification",
    "title": "CPU Verification Lab",
    "content": "Due Date: May 14; Last Updated Date: Apr 30 . ",
    "url": "/2024/labs/formal.html#cpu-verification-lab",
    "relUrl": "/labs/formal.html#cpu-verification-lab"
  },"49": {
    "doc": "CPU Verification",
    "title": "Table of Contents",
    "content": ". | Overview: Formally Verify the PSP . | Your Verification Task | Code Structure | . | Part 1: Get Familiar with the Starter Code . | Part 1A: Specification Code (20%) | Part 1B: Implementation Code (5%) | Part 1C: Verification Code (10%) | . | Part 2: Find the Adder Bug (5%) | Part 3: Find the Backdoor Instruction . | Simplications on the Original PSP Processor | Part 3A: Add Exceptions in the Specification (20%) | Part 3B: Find the Backdoor Instruction (40%) | . | . ",
    "url": "/2024/labs/formal.html#table-of-contents",
    "relUrl": "/labs/formal.html#table-of-contents"
  },"50": {
    "doc": "CPU Verification",
    "title": "Lab Details",
    "content": "Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . This lab could be run on our lab machine unicorn.csail.mit.edu. Log in with the same user account as previous labs. Alternatively, you can use the docker file provided in the starter code to run the lab locally. Instructions to run the docker are provided here. ",
    "url": "/2024/labs/formal.html#lab-details",
    "relUrl": "/labs/formal.html#lab-details"
  },"51": {
    "doc": "CPU Verification",
    "title": "Overview: Formally Verify the PSP",
    "content": "In the Fuzzing Lab, you have been playing with the buggy Pretty Secure Processor and found the ALU bug and the backdoor instruction. In this lab, you will try to find them again with another approach – Model Checking – as you have learned from the Formal Verification Recitation. Hope you will have a better understanding and comparison of fuzzing and formal verification. Finish the Recitation First! . If you have not finished the Formal Verification Recitation, stop continuing on the lab and finish the Recitation first! The recitation is basically a simpler version of the lab and gets you familiar with the whole verification framework. A solution to the recitation has been provided on Piazza. Your Verification Task . As explained in the “The Big Picture” Section of the Recitation, the basic idea of formal verification is to check the implementation matches the specification under all possible inputs to the hardware. In this lab, the 3 key components of this task are: . | Implementation: Verilog source code of the PSP Processor. | Specification: (A small portion of) RISC-V ISA definition. | Covering all possible inputs: Use Rosette, a symbolic execution framework. | . Code Structure . You will gradually write the code to achieve this verification task. Here is an overview of the starter code structure, which is similar to the code structure in the Recitation. We will guide you through the starter code in Part 1 of this lab. |-- core_to_verify # System Verilog code of PSP |-- ... | `-- core_to_verify.sv # Top module |-- scripts |-- sv2rkt.sh # Convert System Verilog to Rosette |-- yosys_command.ys # yosys commands used by `sv2rkt.sh` | `-- verify.sh # Run the verification |-- generated_src | `-- core_to_verify.rkt # Rosette code generated through `sv2rkt.sh` | `-- src # Contain all verification code |-- param # Parameters like instructions encodings | `-- ... |-- array # Functions operating on register arrays | `-- ... |-- impl.rkt # Functions to simulate the implementation |-- spec.rkt # Functions to simulate the specification `-- veri.rkt # Simulate the impl and spec and verify they match . ",
    "url": "/2024/labs/formal.html#overview-formally-verify-the-psp",
    "relUrl": "/labs/formal.html#overview-formally-verify-the-psp"
  },"52": {
    "doc": "CPU Verification",
    "title": "Part 1: Get Familiar with the Starter Code",
    "content": "The processor you will verify this time will be more complex than the one in the Recitation. It could be hard to directly jump into the implementation part of the processor. So, let’s start by looking at the specification. The specification is used to represent how architecture states should be updated by each instruction. It does not need to reflect how long (i.e. how many cycles) an instruction should take in a real (pipelined / Out-of-Order) processor and we can just write a specification that executes 1 instruction per cycle for convenience. Part 1A: Specification Code (20%) . We will look at spec.rkt and the 3 files it requires (i.e., imports), array/rf.rkt, array/imem.rkt, and param/inst.rkt in this part. The following exercises and discussions are designed to help you understand them. Run a Test Program . 1-1 Exercise . The main function of the spec.rkt file (i.e., the last line in it) contains a single function call to the testMe function. Run the spec.rkt file with racket src/spec.rkt command from the root folder in the terminal. Check the terminal output. Broken Environment . In case the command above returns -bash: racket: command not found on unicorn, try source /knox/envSetup.sh to set environment variables. (This should not happen normally because this source command should be run automatically when you log in.) . The code you just ran initializes an instance of the specification data structure and simulates it by 5 cycles. The states of the specification are printed out at each cycle. You will be asked to explain this output along with the source code of testMe function in the following discussion question. HINT: Rosette Libraries . Forget the meaning of a built-in function? You can: . | Check the “Learn Rosette Syntax” Section from the Recitation for basic keywords/functions including define, struct, bitvector, vector, printf, branch and loops. | Search the function in Racket’s official document page, by putting the function name into the search box at the left-top corner. If you find multiple searched results, use the function “provided from /rosette/…”. | . 1-2 Discussion Question . | Which function is called to initialize the variable spec? What is the data type of this variable? | What are the instructions stored in the initial instruction memory? How about the initial content of the data memory and register file? (Hint: find the file where init-debug-imem, init-zero-dmem, and init-zero-rf are defined.) | Move on to the simulation of spec. The function step-spec! is called to simulate it by 1 cycle. In this function, what is the function spec-pc doing? | The function inst-rd is defined in param/inst.rkt. What is it doing? (Hint: extract is a built-in function you could search in the Racket’s official document page) | In the starter code of step-spec!, what instruction has already been supported? | . Now you should have a general idea about what spec.rkt is doing. Read through the file and confirm you understand the 5 key functions it defines, summarized in the table below. They will be used during the verification. | Function | Explanation | . | (init-spec imem dmem) | Initialize an instance of spec data structure and return it. | . | (step-spec! spec) | Simulate the specification by 1 cycle. | . | (spec-archState spec) | Extract the architectural state of the specification that will be compared with the implementation. | . | (spec-justCommit spec) | Indicate whether the spec just committed an instruction during the last time step-spec! is called. This function is implicitly defined when we define the struct spec. | . | (spec-&gt;string spec) | Convert the spec data structure to string for a nice printing. (Yes, -&gt; can be part of the function name.) | . Support 4 More Instructions . Now that you have been familiar with the starter code of the specification, let’s extend it a little bit to test your understanding. 1-3 Exercise . Following the pattern of how step-spec! executes LUI instruction, extend it to support ADDI, SRLI, ADD, and BEQ instructions. Some helper functions to decode instructions are provided in param/inst.rkt. You could test your code by updating the init-debug-imem function in array/imem.rkt to include these new instructions, and run it with racket src/spec.rkt from the root folder (where you will run all the rest commands in this lab) in the terminal. HINT: ISA Definitions . Please refer to ISA Specification, starting at Page 18, for the detailed explanation of each instruction. A summary of these instructions is on Page 130. If you are confused by what (assume #f) is doing in the else case of the cond block, don’t worry, you do not need to change it in this exercise, and we will talk about it later. Part 1B: Implementation Code (5%) . Writing the specification code above is nothing more than writing a normal program, but in our newly learned Rosette language. In this part, however, you will explore more power of the framework and simulate the Verilog code cycle by cycle. Most of the implementation code is automatically generated by the yosys+knox you have used in the “From RTL to Rosette” Section of Recitation. As you have seen in the Exercise 1 of the Recitation, this automatically generated code provides interface functions to initialize the state of a Verilog module, simulate it, and extract the output from it. The impl.rkt file uses these interface functions to define 5 functions for our verification (, which are similar to the functions defined in the spec.rkt file): . | Function | Explanation | . | (init-impl imem dmem) | Initialize an instance of impl data structure and return it. | . | (step-impl! impl) | Simulate the implementation by 1 cycle. | . | (impl-archState impl) | Extract the architectural state of the implementation that will be compared with the specification. | . | (impl-justCommit impl) | Indicate whether the impl just commit an instruction during the last time step-impl! is called. | . | (impl-&gt;string impl) | Convert the impl data structure to string for a nice printing. | . All these functions are provided in the file impl.rkt. You do not need to fully understand how these functions are implemented and only need to know how to use them. Specifically, you will run a testMe function in it to see how a Verilog module is simulated with a concrete instruction memory. 1-4 Exercise . Generate the .rkt file (i.e., generated_src/core_to_verify.rkt) from the System Verilog files by running ./scripts/sv2rkt.sh. Run the impl.rkt file with racket src/impl.rkt command. Check the terminal output. 1-5 Discussion Question . Check the output of racket src/impl.rkt and answer: After simulating how many cycles did you observe the first and the second instructions being committed? Could you explain the reason for these two cycle numbers based on the micro-architecture of the pretty secure processor? . If you are curious about how these functions are implemented, feel free to read through the impl.rkt file. There are many comments to explain the code. They are implemented with two key ideas in mind: . | To simulate the pipeline of the processor, it uses the interface functions provided by the generated code from the yosys+knox toolchain. This is similar to how we simulate the Tiny CPU in the Recitation. | It also simulates the interaction between the pipeline and the instruction/data memory. The memory takes 1 cycle to return the data: At cycle 0, it saves the inputs to a buffer register; At cycle 1, it returns the data. | . Part 1C: Verification Code (10%) . Finally, we will start to do the verification! We will help you understand the veri.rkt file. It uses the 5 key functions from spec.rkt and the 5 from impl.rkt that you should already be familiar with. It also requires (i.e., imports) a small configuration file param/veri.rkt that will be explained later. Verify a Concrete Test Program . Normally, we want to verify the specification and implementation match under any initial state of the instruction memory. This requires us to initialize the instruction memory with symbolic values (with the function init-sym-imem in array/imem.rkt). However, this might be inconvenient for us to debug or just to learn the code. Thus, let’s first try to run the framework with a concrete initial instruction memory, which essentially means we want to verify the specification and implementation match under a concrete program. We provide a simple variable in param/veri.rkt, the param-imem-type to determine whether to use symbolic or concrete initial instruction memory. Let’s start by setting the variable to “concrete” first. 1-6 Exercise . Change the param-imem-type variable in param/veri.rkt to “concrete” and run the veri.rkt file with racket src/veri.rkt. You should see “No Counterexample” at the end of the terminal output. If not, it means the specification and the implementation mismatch when running the program returned by the init-debug-imem function in array/imem.rkt – You probably did Exercise 1-3 incorrectly. Now, let me ask you a few questions to help you understand the output and the source code (i.e., the testMe function in veri.rkt). But before that, let me remind you of a few build-in functions for the verification in Rosette (that you will see in veri.rkt): . | Function | Explanation | . | (verify expr) | Symbolically execute the expr. At the end of the execution, send all assumptions and assertions generated by expr to an SMT solver, asking for a solution (i.e., a counterexample satisfying all the assumptions but violating one of the assertions). The solution is returned. | . | (sat? sol) | Return true if the solution (sol) indeed finds a counterexample. | . | (evaluate v sol) | In the counterexample shown in the solution (sol), what is the concrete instance of variable v? This function returns the concrete instance. | . 1-7 Discussion Question . | When executing the line of code (verify (simu imem dmem #f)) in veri.rkt, what are the assertions generated? | In the for loop of function simu, the implementation and specification are simulated in a “synchronized” manner. What could go wrong if we just simulate both of them by 1 cycle in each loop iteration, without changing other code? | . Test on Finding a Counterexample . It is not essentially fun to see no counterexample found. After all, we try to find bugs with our framework in the lab. So, let’s manually create a mismatch between the specification and the implementation and see how will the framework react. 1-8 Exercise . Go to the step-spec! function in spec.rkt and look at the code that executes the LUI instruction. Let’s change the line (write-rf! rf rd imm-U) to (write-rf! rf rd (bv 0 32)) and then run racket src/veri.rkt again. Now, our specification and implementation will definitely mismatch because the specification is not executing the LUI instruction correctly. Let’s look at the terminal output and see how the framework figures out this mismatch. Here is how the code in veri.rkt works: . | Line (define sol (verify (simu imem dmem #f))) simulates the specification and implementation. At the end of the simulation, it queries the SMT solver and finds a solution that contains a counterexample. | Line (set! imem (evaluate imem sol)) looks into the counterexample in the sol and finds the concrete value of the instruction memory that triggers the assertion false. It updates the variable imem with this concrete value. (For now, this concrete imem is just the one you define in array/imem.rkt.) | Line (simu imem dmem #t) simulates the specification and implementation again with this concrete instruction memory. It will print out a trace to show the counterexample. | . 1-9 Discussion Question . Check the terminal output and answer: after finishing simulating which cycle does the implementation and specification start to mismatch on the architectural state? What is the mismatch? Why do we have this mismatch? . Find a Counterexample with Symbolic Initial Instruction Memory . Now, let’s change the initial state of the instruction memory to symbolic value and release the full power of our framework. 1-10 Exercise . Change the param-imem-type variable in param/veri.rkt to “sym” and run racket src/veri.rkt. 1-11 Discussion Question . This time, what instruction triggers the mismatch in the architectural state at which cycle? . Debug with Concrete imem . Whenever your code does not work properly later in this lab, with symbolic initial instructions, you can always switch back to concrete initial instructions for debugging. Constraint the Search Space . You might face a small trouble in investigating the counterexample in the last run: the concrete instruction is executing on a register whose index is quite large. However, our terminal only prints out the registers with index 0, 1, 2, and 3, due to the space limit. To see the value stored in this register with a large index, we have to adjust the printing function to include the specific register in the printings. It could be annoying to do this for every new counterexample. We provide a convenient configuration variable to solve this problem: The param-limit-space in param/veri.rkt can be used to limit the search space of the solver by only considering the register file accesses whose indexes are within [0, 3] and memory requests whose addresses are within [0x0, 0x1f]. Let’s try it. 1-12 Exercise . Change the param-limit-space variable in param/veri.rkt to #t and run racket src/veri.rkt. We will keep it to #t for the rest of the lab. Now, you should be able to see the counterexample uses a register with a smaller index and the state mismatch can be easily checked from the terminal printout. Assumptions and Assertions . The param-limit-space configuration you just tried is no more than achieving a small engineering trick to help us debug. However, we want to bring your attention to how it is implemented, which will reveal a more fundamental concept in the formal verification – Constraining the search space with Assumptions. You have already been familiar with the assertions, right? Basically, whenever you want to check a property, you assert it. Assumptions, on the other hand, have also been used in the code base a few times without being fully explained to you. Let’s take one example you just used to explain it. Check out the write-rf! function in array/rf.rkt. The assume is called to assume the higher 3 bits of the register index (i.e., pos) is always zero. You have just benefited from this assumption in a way that the counterexample generated only uses a register whose index is within [0, 3]. Here is a summary of how assumptions work: . | During the symbolic simulation, all expressions being assumed by the assume function are collected, in the same way the assertions are collected. | When querying the SMT solver, instead of just asking the SMT solver to find a counterexample violating the assertions, we now ask for a counterexample, i.e., a concrete instance of instruction memory, that satisfies all assumptions but still violates some assertions. | . In our example, the assumption in this write-rf! function makes sure the program in the counterexample will not use a register with larger indexes. Assumptions help us constrain the search space for those symbolic values. Another place where you have been benefiting from assumption is the step-spec! function in the spec.rkt file. When an instruction type has not been supported (i.e., in the else case of the cond block), we use (assume #f). This makes sure programs using unsupported instructions will not be considered (as a counterexample). HINT: Use assume! . If you could have a good understanding of assume and take advantage of it later in the lab, it could save you a lot of coding efforts while finding the same bug you are asked for. 1-13 Exercise . Go to the step-spec! function in spec.rkt and look at the code that executes the LUI instruction. Change the line (write-rf! rf rd (bv 0 32)) back to (write-rf! rf rd imm-U), run racket src/veri.rkt, and you should see “no counterexample found”. Now, you are ready to go with real challenges! . Grading . The only code that we will grade for this part is Exercise 1-3. Other exercises are helping you to understand the framework and answer the discussion questions. The discussion questions will be graded. ",
    "url": "/2024/labs/formal.html#part-1-get-familiar-with-the-starter-code",
    "relUrl": "/labs/formal.html#part-1-get-familiar-with-the-starter-code"
  },"53": {
    "doc": "CPU Verification",
    "title": "Part 2: Find the Adder Bug (5%)",
    "content": "It is rather simple to find the adder bug after we have built up the framework. In fact, we already have all the code required to find this bug. The only thing you need to do in this part is to ask the model checker to check for more cycles. Bounded Model Checking . We are doing a bounded model checking here, which means we only simulate the implementation for a bounded number of cycles and check whether the mismatch happens within this number of cycles. When it passes the check, it does not mean the implementation is fully correct and more bugs might be found when increasing the number of the bound. The number of the bound in our code base is defined in param/veri.rkt by the variable param-simuCycle. 2-1 Exercise . Increase the value of param-simuCycle in param/veri.rkt and redo the verification, until you could find the adder bug. (You might want to have a minimal param-simuCycle, so your counterexample showing the bug will also be short.) . 2-2 Discussion . Describe the adder bug you found here. Grading . The exercise in this part will not be graded, and only the discussion question will be graded. ",
    "url": "/2024/labs/formal.html#part-2-find-the-adder-bug-5",
    "relUrl": "/labs/formal.html#part-2-find-the-adder-bug-5"
  },"54": {
    "doc": "CPU Verification",
    "title": "Part 3: Find the Backdoor Instruction",
    "content": "Honestly, you have merely written any code so far in this lab, but just exploring the capability of the starter code. But now, it’s your turn to do some work. Recall in the Fuzzing Lab, the backdoor instruction is an instruction with illegal encoding. Based on the specification, this illegal instruction should cause an exception. However, the implementation does something different – it is executed as a nop or even silently changes the privilege level. In this part, you will try to describe the behavior of illegal instructions (i.e., causing exceptions) in the specification and automatically find that a backdoor instruction mismatches this behavior. For simplicity, you do not have to find when this backdoor instruction will change the privilege level. Simplications on the Original PSP Processor . The original PSP processor supports tens of instructions as well as many CSRs. It could be tedious for you to implement all of them in the specification. So we have simplified the Verilog code of the PSP processor and we list a summary of it: . | Only support 10 instructions: LUI, BEQ, LW, SW, ADDI, SRLI, ADD, ECALL, CSRRW, and MRET. The encodings of these instructions have been provided in param/inst.rkt. But you need to check the ISA Specifications for the expected behavior for each of them. | Only support 3 CSRs: mtvec, mepc, and mpp. They are all zero after reset. Recall we have explained these CSRs here. Writing to any other CSRs will have no effect and reading from any other CSRs will return 0. Writing or reading to any other CSRs also will not check the privilege level or trigger exceptions. | Only support 2 privilege levels: User Mode and Machine Mode. A 2-bit register stores the mode: 0 as User Mode and 3 as Machine Mode. The processor is in the Machine Mode after reset. | When loading from or storing to an address that is misaligned (i.e., lower 2 bits are not zero), treat it as if the address is aligned (i.e., pretend the lower 2 bits are zero). This is the case for both instruction and data memories. | . Part 3A: Add Exceptions in the Specification (20%) . The first step is to specify the behavior of Exceptions in the specification. The expected behavior of exceptions can be complex when many CSRs are involved. Thankfully, we only need to support 3 CSRs. Instead of pointing you to the official document of exceptions, which contains many CSR names that might scare you, here is a short summary of the expected behavior of exceptions in our simplified processor: . | Store the current pc to mepc and jump to the location stored in mtvec. | Store the current (zero-extended-to-32-bit) privilege level to mpp and set the privilege level to Machine Mode. | The current instruction will not be committed. | . 3-1 Exercise . Look at the step-spec! function in spec.rkt. When having an illegal (or currently unsupported) instruction, instead of doing (assume #f), trigger the exception as described above. Some CSR-related codes are provided in array/csr.rkt. Test your code by adding an illegal (or currently unsupported) instruction to the init-debug-imem function in array/imem.rkt, run racket src/spec.rkt, and check the output. Part 3B: Find the Backdoor Instruction (40%) . Only adding the exception is unlikely to be enough to find the backdoor instruction because our specification has not matched the implementation yet – it only supports 5 out of 10 instructions. But this might still be a good time to just go and try the verification, and to see what we can find. Try to run the verification with racket src/veri.rkt. What have you observed? You probably will see the same adder bug! . Assume the Adder Bug is not Triggered . It actually can be annoying during the formal verification that even if the design has many bugs, the formal verification framework might only be able to find one of them. This happens because as long as a program uses the add instruction and triggers the bug, it will cause the assertion to be false. The SMT solver will just become lazy and stop exploring other possible violations of the assertions. One normal solution is just fixing the existing bugs – No one wants so many bugs lying in the code base. However, sometimes, it would also be nice to find multiple bugs and do the fix together. We could achieve so by adding an (assume #f) on the execution path triggering the bug. 3-2 Exercise . Go to the step-spec! function in spec.rkt. Add an (assume #f) to the path executing the ADD and ADDI instructions. Then run racket src/veri.rkt and you should see no counterexample found (with the minimal param-simuCycle that gave you the adder bug). Find the Backdoor Instruction, Finally . Now is the final time to find the backdoor instruction. 3-3 Exercise . Increase the value of param-simuCycle in param/veri.rkt and redo the verification, until you can find a counterexample generated by the solver. If lucky enough, you might directly find the backdoor instruction even without changing the code. Then you could just skip the following Exercise 3-4. (Though we still hope you could try it a bit.) . Otherwise, you will find one of the 10 legal instructions (listed here) will trigger the assertion false – it will trigger an exception on the specification (because we have not supported it yet) while executing normally on the implementation. In this case, you need to add the support of this legal instruction and try the verification again until you can find the backdoor instruction. 3-4 Exercise . In the specification, gradually add the support of the legal instructions that trigger the assertion false until you can find the backdoor instruction. If needed, you could change the spec-archState and impl-archState functions to include CSRs and the Privilege level and check whether they match. 3-5 Discussion . What is the backdoor instruction you found? Take a screenshot of the terminal output at the cycle when this backdoor instruction is committed and include it in the report. Reproducibility . Unless you support all 10 instructions, we might not be able to reproduce your result because the SMT solver might just decide to find a different counterexample when we run it. This is fine as long as you have the screenshot! However, we do encourage you to support more instructions. 3-6 Discussion . Based on your experience in lab6.A and lab6.B, how would you compare the pros and cons of fuzzing and formal verification techniques? . Grading . For Exercise 3-1/2/3, please finish them by following the instructions. For Exercise 3-4 you will get a full grade as long as you show the correct backdoor instruction being found through the screenshot in Discussion 3-5. ",
    "url": "/2024/labs/formal.html#part-3-find-the-backdoor-instruction",
    "relUrl": "/labs/formal.html#part-3-find-the-backdoor-instruction"
  },"55": {
    "doc": "CPU Verification",
    "title": "That’s All, Folks!",
    "content": "That’s all we have for you this semester. Congrats on completing Secure Hardware Design!! We sincerely hope you enjoyed this class and found the labs to be worthwhile. If there’s anything we can do to improve the course for future students, please let us know! (Anonymous feedback here.) . Have a great summer! . ",
    "url": "/2024/labs/formal.html#thats-all-folks",
    "relUrl": "/labs/formal.html#thats-all-folks"
  },"56": {
    "doc": "CPU Verification",
    "title": "Acknowledgements",
    "content": "Made by Yuheng Yang. ",
    "url": "/2024/labs/formal.html#acknowledgements",
    "relUrl": "/labs/formal.html#acknowledgements"
  },"57": {
    "doc": "CPU Verification",
    "title": "CPU Verification",
    "content": " ",
    "url": "/2024/labs/formal.html",
    "relUrl": "/labs/formal.html"
  },"58": {
    "doc": "CPU Fuzzing",
    "title": "CPU Fuzzing Lab",
    "content": "Due Date: May 7; Last Updated Date: Apr 3 . ",
    "url": "/2024/labs/fuzz.html#cpu-fuzzing-lab",
    "relUrl": "/labs/fuzz.html#cpu-fuzzing-lab"
  },"59": {
    "doc": "CPU Fuzzing",
    "title": "Table of Contents",
    "content": ". | Overview: Pretty Secure Processor | Part 1: Mystery of the Faulty CPU (10%) | Part 2: Fuzzing for Faulty Inputs (30%) | Part 3: Fuzzing for a Hidden CPU Backdoor (45%) | Part 4: Using the Backdoor to Exploit a Remote System (15%) | Part 5: Bug Bounty (Optional, 10% Bonus) | Part 6: Challenge Problem (Optional, No Credit) | . ",
    "url": "/2024/labs/fuzz.html#table-of-contents",
    "relUrl": "/labs/fuzz.html#table-of-contents"
  },"60": {
    "doc": "CPU Fuzzing",
    "title": "Lab Details",
    "content": "Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . Log in to our lab machine with ssh username@unicorn.csail.mit.edu. The username and initial password are the same as previous labs, though you should have changed your password on unicorn (when you use it as a jumper) in previous labs. We will not email you again about this information but feel free to ask TA if you forget it. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2024/labs/fuzz.html#lab-details",
    "relUrl": "/labs/fuzz.html#lab-details"
  },"61": {
    "doc": "CPU Fuzzing",
    "title": "Warning: Start Early!",
    "content": "This lab is a potpourri of many systems level programming tasks, including writing low-level RISC-V assembly and C and automating tasks with Python. As there are a large number of open-ended things to do in this lab, we highly encourage you start early on this one. ",
    "url": "/2024/labs/fuzz.html#warning-start-early",
    "relUrl": "/labs/fuzz.html#warning-start-early"
  },"62": {
    "doc": "CPU Fuzzing",
    "title": "Overview: Pretty Secure Processor",
    "content": ". In this lab we will explore utilizing CPU fuzzing techniques to discover RTL bugs in a pipelined RISC-V CPU. Specifically, we will be executing all of our attacks on a modified version of Pretty Secure Processor, a CPU designed by your CA Joseph. This modified CPU was custom built specifically for this lab. This page contains a complete description of the PSP platform – we highly encourage you to refer to it. Specifically, the sections on CSRs and serial IO will be useful. ",
    "url": "/2024/labs/fuzz.html#overview-pretty-secure-processor",
    "relUrl": "/labs/fuzz.html#overview-pretty-secure-processor"
  },"63": {
    "doc": "CPU Fuzzing",
    "title": "What am I building in this lab?",
    "content": "In this lab you will implement a number of low-level CPU tasks in C and RISC-V assembly to build a CPU fuzzing engine. Your code will run on the simulated CPU bare metal. That is, you have complete control of the hardware, and your code runs inside the CPU being tested. Your job is to write code that tests the hardware and reliably reports whether the hardware (which may have CPU bugs) is operating correctly or not. At the end of the lab, you will use the CPU bugs you have discovered and the knowledge of return-oriented programming from the ASLR lab to build an end-to-end exploit on a remote Pretty Secure Processor. ",
    "url": "/2024/labs/fuzz.html#what-am-i-building-in-this-lab",
    "relUrl": "/labs/fuzz.html#what-am-i-building-in-this-lab"
  },"64": {
    "doc": "CPU Fuzzing",
    "title": "What happens when I run my code?",
    "content": "All of your lab code runs on Pretty Secure Processor, a 5-stage pipelined RISC-V CPU. When your code is built, we send it to a cycle-accurate simulated Pretty Secure Processor core and let it run. By “simulated”, we mean that the RTL (the SystemVerilog that defines the CPU) itself is simulated in a cycle-accurate simulator. Your code is not running in an emulator (like Qemu) nor an ISA simulator – we are simulating everything down to the cycle level! That means that microarchitectural properties like pipelining, hazard forwarding, etc., are all in play for this lab. The entire CPU pipeline is simulated at a cycle accurate level: no emulation here! . (Note that this diagram is for demonstrative purposes only and does not show the entire pipeline. You do not need to understand this diagram in detail, it is provided purely to illustrate the core from a bird’s eye view). ",
    "url": "/2024/labs/fuzz.html#what-happens-when-i-run-my-code",
    "relUrl": "/labs/fuzz.html#what-happens-when-i-run-my-code"
  },"65": {
    "doc": "CPU Fuzzing",
    "title": "Running your code",
    "content": "From the top directory of the lab code, there are two scripts – run.sh and gdb.sh. To run a given part, first cd into the part and compile it with make. You will need to rebuild each part with make whenever you change any of the code. Then, from the lab root directory, you can run a given part with ./run.sh partX. Adding Code . Our Makefile will automatically build and link any extra files you create. You can create new C files with the .c extension and assembly source files with the .s extension. There is one restriction that you cannot create two files having the same name but one has .c and the other has .s extension, e.g., fuzz.c and fuzz.s. Note that for symbols to be exported from an assembly file they need to be marked .global. Debug Mode . To enable debug mode, edit debug.sh and fill in SHD_DEBUG_PORT with the debug port that was emailed to you. Then, you can add --debug to the end of the run.sh invocation to start debug mode. You should see something like the following: . $ cd part1 &amp;&amp; make &amp;&amp; cd .. $ ./run.sh part1 --debug Waiting for debugger on port XXXX... You can now open a new terminal window and run gdb.sh. You should see Debugger attached! printed in the original terminal, and GDB should give you a session like the following: . $ ./gdb.sh ... Remote debugging using localhost:XXXX start () at bringup.s:44 44 la x1, exception_handler_entry (gdb) . Now you are in a GDB session running on PSP. You can set breakpoints, inspect registers, and step through the assembly to see how your code is behaving. In case you have forgotten the GDB commands, you can refer to the RISC-V System Programming Recitation cheat sheet (link will be available later). ",
    "url": "/2024/labs/fuzz.html#running-your-code",
    "relUrl": "/labs/fuzz.html#running-your-code"
  },"66": {
    "doc": "CPU Fuzzing",
    "title": "Part 1: Mystery of the Faulty CPU (10%)",
    "content": "Congratulations! You landed your dream job as a CPU design engineer at the Pear Computer Company. Your manager has tasked you with using Pretty Secure Processor as the CPU for the next Pear Phone Pro. The PearPhone Pro . You sent an early version of your phone out to the Maps test team so they could test the navigation algorithms. To your surprise, they reported that the new phone was producing different shortest paths than expected. The Maps team conducted a thorough review of their software, and found no possible errors – they have concluded it must be a hardware bug, and your manager agrees with them. The Maps team provided the following example graph and expected output: . The expected output: . Distance of node 1=0x400 Path=1&lt;-0 Distance of node 2=0x500 Path=2&lt;-1&lt;-0 Distance of node 3=0x600 Path=3&lt;-2&lt;-1&lt;-0 . The output from the faulty CPU: . Distance of node 1=0x400 Path=1&lt;-0 Distance of node 2=0x500 Path=2&lt;-1&lt;-0 Distance of node 3=0x1000 Path=3&lt;-0 . The team is using Dijkstra’s Algorithm to find the shortest path between the nodes. They have tracked the bug to happening at this line in the code: . if(mindistance+cost[nextnode][i]&lt;distance[i]) . In this part, we will analyze the CPU to figure out what is going wrong. ",
    "url": "/2024/labs/fuzz.html#part-1-mystery-of-the-faulty-cpu-10",
    "relUrl": "/labs/fuzz.html#part-1-mystery-of-the-faulty-cpu-10"
  },"67": {
    "doc": "CPU Fuzzing",
    "title": "Getting Familiar with the Codebase",
    "content": "Before we dig into the CPU internals, let’s get familiar with the lab infrastructure. In this part, you will be asked to navigate the codebase and answer several questions. No need to write any code. 1.1 Building and Running the Starter Code . | Checkout the lab codebase into your account on Unicorn. | cd into the part1 directory and build it with make | Run the code with ./run.sh part1 from within the top level directory. You should see the incorrect output as shown above. | . Now, open the part1 folder in your favorite code editor, and answer the following questions about the starter code in your report. These questions are intended to help guide you through the starter code – feel free to explore the code on your own too! . 1-1 Discussion Question . | Open bringup.s and read through the start method. What is the name of the C method that start jumps to when it finishes by running mret? Which CSR is used to hold that address? | start specifies an exception handler by writing to CSR_MTVEC. What is the name of the handler? What file is it implemented in? | linker.ld defines the memory map of the binary built by the build system. What section is the stack located in? How large is the stack? | Open asm_offsets.h. This file is automatically generated when you compile the project. What is the offset of the mepc field of saved_regs_t? Where is saved_regs_t defined? | Which RISC-V register is used as the return address in the calling convention? Which register is used as the stack pointer? (Hint: Refer to Table 18.2 of the RISC-V Calling Convention) | What privilege mode does the starter code run the CPU in, after mret in bringup.s? | . 1.2 Debugging the CPU . Let’s inspect the code from the Maps team to learn why the CPU is not finding the correct shortest path. Open dijkstra.c and navigate to line 55. 1-2 Exercise . Let’s debug the CPU using the basic approach: using printf. Insert printf statements into dijkstra.c before line 55 to print the values of the operations performed by the if statement. Print all information relevant to the operation – that is, print the value of mindistance, cost[nextnode][i], their sum as computed by the CPU, and distance[i]. Look at the CPU reported output of mindistance+cost[nextnode][i] and see whether you can capture the bug. We will not grade the coding for this part, since they are just a few printf. The %d option in printf is not supported in our code base. Please use %x instead. 1-3 Discussion Question . Based on the printf result, record what are the inputs (eg. values of mindistance and cost[nextnode][i]) that cause the addition instruction to return an incorrect sum? Does the operation fail for all inputs or just specific ones? . (Note: You do not need to exhaustively test the input space, just report the ones you observe from running the starter program). Submission and Grading . Write the answers to the questions in your report. No code for this part. ",
    "url": "/2024/labs/fuzz.html#getting-familiar-with-the-codebase",
    "relUrl": "/labs/fuzz.html#getting-familiar-with-the-codebase"
  },"68": {
    "doc": "CPU Fuzzing",
    "title": "Part 2: Fuzzing for Faulty Inputs (30%)",
    "content": "Impressed with your ability to understand incorrect CPU behavior, your boss has assigned you a new task – to write a program that can automatically test a given CPU to see if the addition bug is present, and if so, return what inputs cause the sum to fail. In the industry, we call such a program a regression test used to ensure that known bugs do not accidentally get reintroduced to the RTL before tapeout (when the CPU design is sent to the factory). We assume a bug is a set of inputs a and b that, when added together, produces an output that is not equal to a+b, just like we saw with the faulty results running Dijkstra’s algorithm above. We assume that the order of operands does not matter (that is, if a+b fails, then b+a fails too). We limit the search space of operands to [0x100,0x1FF] for both a and b (that is, only consider values of a and b from 256 to 511 inclusive). Your task is to check the addition operator for all operands in the search space, and print out any operands that fail. Note that you cannot trust the CPU to perform the add instruction correctly (you can assume all other arithmetic instructions are bug-free). How do you know if the CPU made a mistake? Or alternatively, how do you implement the specification for the add instruction in your code? This is an open-ended problem with multiple possible solutions. 2-1 Discussion Question . What is your approach for finding the operands that can trigger the bug with the add instruction? Briefly describe it. Starting from this point, you are free to modify any C or assembly file you’d like! . Additionally, you can add as many source files as you want – the build system will automatically build and link them for you! . 2-2 Exercise . Navigate into the part2 folder and create two new files – fuzz.c and fuzz.h. Create a method void part2_fuzz_inputs() and modify shd.c to call your new method from shd_main. You also need to #include \"fuzz.h\" and define a function signature for your new method. Your method should analyze all possible sums for operands between 256 and 511 (inclusive). If it finds any inputs that fail to produce the correct sum, it should print the input pair and what the erroneous sum was. When you want to call printf(), include our own printf from utils.h. The printf from stdio.h, which you were using in previous labs, is implemented to run on standard Linux, not on our psp, which has no operating system. For interacting with our grading scripts, you should use the following format specifier to print out failing operands: printf(\"0x%X+0x%X=0x%X,0x%X\\n\",a,b,a+b,expected) (where a and b are the buggy inputs, and expected is what they should have added up to). It is ok if the same inputs appear twice in swapped order (eg. if you print both a,b,a+b,expected and b,a,b+a,expected). Your output should look like: . +------------------+ | MIT SHD Fuzz Lab | Part 2 | +------------------+ 0x10+0x10=0x30,0x20 0x15+0x15=0x16,0x2A ... We will grade your lab on a CPU with random bugs! . Do not assume the bugs present on the lab handout CPU will be the same that your code is graded against – your code should exhaustively search the input space to find and report all bugs! . You should assume there can be zero or multiple addition bugs (inputs that cause the addition to fail) with randomly distributed operands. 2-3 Discussion Question (optional) . After completing part 2, please share with us: Did you encounter any bugs while implementing the fuzzer? How did you handle the possibility of add instructions being incorrect during control flow instructions (e.g., loop condition checks)? . Suggested Strategies / Hints . | You could test your code by running it on the host Linux machine and use that as a “Gold” CPU model. (You probably need to change to include header files that are supported by the host linux and write another main function specifically for the host linux.) On the Linux host your code should report no bugs, and on Pretty Secure Processor it should report some bugs. | Note that you cannot trust the CPU hardware to perform addition correctly. What happens if your loop logic requires a sum that is computed incorrectly? | . You can use Python or a shell script to automate generation of your test cases. If you do, please commit these scripts to your repository as well, and include instructions for how to use them in your report. Submission and Grading . git add all the new files you created for Part 2, including any Python or shell scripts you wrote to automate generation of your code. Running ./run.sh part2 should create a printout of the bugs your fuzzer found. Your code should run for no longer than 10 minutes. ",
    "url": "/2024/labs/fuzz.html#part-2-fuzzing-for-faulty-inputs-30",
    "relUrl": "/labs/fuzz.html#part-2-fuzzing-for-faulty-inputs-30"
  },"69": {
    "doc": "CPU Fuzzing",
    "title": "Part 3: Fuzzing for a Hidden CPU Backdoor (45%)",
    "content": "Bad news! This morning, a news report came out describing in the wild cases of PearPhone kernels being compromised by a new strain of malware. This malware is somehow capable of elevating the CPU privilege level from PSP_PRIV_USER to PSP_PRIV_MACHINE, bypassing all OS restrictions. While the CPU design team believes this is impossible, your boss has a suspicion – that someone inserted a malicious backdoor into the CPU itself! . Whenever the CPU attempts to execute an undefined instruction, it is supposed to throw an exception with mcause set to EXCEPTION_CAUSE_INVALID_INST (see defines.h:51). Your boss believes the CPU backdoor is a single instruction encoded in an undefined region of the RISC-V ISA instruction encoding space that, when executed, does not throw an exception, but instead sneakily switches the privilege mode of the pipeline. An attacker who knows the encoding of this hidden instruction can use this to bypass the PearPhone OS security mechanisms. In this part, you will write a hidden instruction fuzzer to search automatically for backdoors in the CPU that elevate your privilege level to machine mode. We will start with searching for undocumented instructions, and then study their behavior. The following provides an overview of the intended approach for finding undocumented instructions: . Whenever the CPU encounters an instruction it cannot execute, it will throw an invalid instruction exception. For every instruction in the search space, we attempt to execute it, and watch for an exception. If any of them don’t generate an exception, we know that the CPU “understands” it as a valid opcode, and therefore it is a good candidate for being a CPU backdoor. 3.1 Writing an Exception Handler . Before we can search for undefined instructions, we need to be able to handle exceptions. For actually undefined instructions, trying to run them will cause the exception handler to run. For any backdoors, the exception handler will not be called (as the backdoor is decoded as a valid instruction). Here is a description of a possible exception handler for you to implement. It saves all registers (x1-x31 and mepc, which holds the pc value of the faulting instruction), handles the exception logic (possibly changing the values of some of the saved registers), and then loads the new CPU state before finally executing mret. Recall that you have found the file that should implement the exception handler in part1. Our implementation in the starter code only includes the first half of the exception handling that 1) creates space on the stack for a new saved_regs_t, 2) stores the registers into it, and 3) passes the address of this struct to exception.c. You can use our test method named exception_test() (defined in exception_test.s) to test your exception handler. The test method generates an illegal instruction exception and checks whether your exception handler is saving and restoring the CPU state correctly. Start by modifying shd_main to call exception_test(). You should see something like the following, telling you the exception handler in the starter code is incomplete: . +------------------+ | MIT SHD Fuzz Lab | Part 3 | +------------------+ Triggering exception... ============================= Exception! pc: 0x000005F0 x1: 0x11111111 x2: 0x00002FD0 x3: 0x33333333 x4: 0x44444444 x5: 0x55555555 x6: 0x66666666 x7: 0x77777777 x8: 0x88888888 x9: 0x99999999 x10: 0x10101010 x11: 0x11111111 x12: 0x12121212 x13: 0x13131313 x14: 0x14141414 x15: 0x15151515 x16: 0x16161616 x17: 0x17171717 x18: 0x18181818 x19: 0x19191919 x20: 0x20202020 x21: 0x21212121 x22: 0x22222222 x23: 0x23232323 x24: 0x24242424 x25: 0x25252525 x26: 0x26262626 x27: 0x27272727 x28: 0x28282828 x29: 0x29292929 x30: 0x30303030 x31: 0x31313131 TODO: You need to write the exception handler return code! . 3-1 Exercise . Read through the starter code in exception_entry.s. Your task is to implement the second half of the exception handler assembly in exception_entry.s, and fill in exception.c with any logic your code needs. First, remove the code that causes the handler to print TODO: You need to write the exception handler return code! and halt. Next, you should fill in the TODO’s in exception_entry.s to restore the saved state (the opposite of what the starter code does). Finally, fill in the TODO in exception_handler in exception.c (the C method called by the handler entry assembly) to properly handle the fault. If the exception cause was an illegal instruction, at minimum this means incrementing the saved mepc by one RISC-V instruction length to resume execution at the next assembly instruction after the undefined one. You will add more logic here in the later parts. If implemented correctly, exception_test() should print Passed exception test!. 3-2 Discussion Question . Why does the exception handler restore x2 after all the other registers? . Here is how RISC-V exception returns are handled by the Linux kernel. Note that the starter code is just a suggested approach – feel free to remove it and rewrite it however you want! . This part is considered complete if exception_test reports your exception handler passed. In later parts, you are allowed to modify your exception handler in any way you want, including in ways that make exception_test fail. exception_test will report a failure if any register x1-x31 is changed by the exception handler. For this lab, you may actually want to modify registers in the saved_regs_t, which is acceptable! . You will not lose points if exception_test says your code fails. It is just a guideline to help you implement Part 3. We recommend starting with an exception handler that passes exception_test to ensure your assembly is correct, and adjusting it later in the lab as you want. For this reason, we also recommend git commit‘ing your code at this current state, in case you later break your exception handler and want to restore it to the previously working version. 3.2 Searching for Undocumented Hidden Instructions . Now that we can catch illegal instruction exceptions, it’s time to scan for backdoors. Your boss wants you to only consider the custom-0 subspace of the instruction encoding space. custom-0 has an opcode of 0001011, or 0x0B (See Table 24.1 in Volume I of the RISC-V ISA Specification on page 129). The CPU does not officially support any custom-0 instructions, so if you find one that doesn’t throw an illegal instruction exception, it is a hidden instruction! . Your boss said that while the opcode is probably custom-0, the decode stage of the pipeline is likely stealthily rejecting all instructions with this opcode whose upper immediate bits do not match some secret. You should treat this backdoor instruction as a U type RISC-V instruction, where the upper immediate bits (bits 31 to 12) are a secret, and the opcode is custom-0. Recall the RISC-V 32I instruction encodings (Volume I Figure 2.2 on Page 16): . In this part, you will loop over all custom-0 instructions with different possible upper immediate bits. That is, you should generate all instructions where the opcode field (bits 6:0) is set to custom-0, and the upper bits (31:12) are set to a guessed secret value. You will execute each instruction, and then check if a CPU illegal instruction exception occurred. If it did not, you should print out the full encoding that caused no exception. You can calculate a single instruction encoding with the following: . OP_CUSTOM0 = 0x0B # See Table 24.1 in Volume I of the ISA Spec. def encode_instruction(secret): return OP_CUSTOM0 | (secret &lt;&lt; 12) . For this lab, only consider the cases where the upper immediate bits (secret value) are between 0 and 65535 inclusive. High-level Guideline . You will need to test all possible instruction encodings in this region. If an instruction is invalid, it will trigger the execution of the invalid opcode exception handler. After executing the handler, we will return to the test code. If it is a hidden instruction, the code will just run through without executing the handler. Your key task to identify a hidden instruction will be to distinguish between the case when an exception has happened and the case when an exception has not happened. At a high level, you will need to figure out a way for the invalid opcode exception handler to communicate information to the test code. This can be done via setting flags in memory or in specific registers or many other ways. You can pick the one you like to implement. It is ok if your design decision causes your exception handler to fail exception_test as long as you are able to discover the backdoor opcode. Note that a key challenge in this part is that you will need to test many instructions. You will not want to write the code manually. Possible solutions include generating the test code automatically with Python, or making use of self-modifying code. If you write automation scripts, make sure to commit them to your repo, and include documentation of how they work in your report. (Only submitting a massive auto-generated assembly file is unacceptable). For now, your test code runs with PSP_PRIV_MACHINE privileges (see bringup.s). 3-3 Discussion Question . Describe your design decisions for the exception handler. What does it do while trying to find the undocumented instruction? How does your exception handler communicate with the test code? . 3-4 Exercise . Write a method that tries all 65536 possible custom-0 instructions, with the upper bits (bits 31 to 12) set to a value between [0,65535] inclusive. If it finds an instruction that does not throw an illegal instruction exception, it prints the opcode to serial with printf. If no instruction is found, it prints that it could not find any hidden instructions. 3-5 Discussion Question . Include the hidden backdoor instruction found by your code/script in the report. This is an open ended programming task! . You are allowed to modify any and all parts of the starter code. You can implement this method in assembly or in C. You can create as many extra files as you need to. You will likely need to modify the exception handler as well to support your code. A Few Assembly Tips . Here are a few assembly tips that may come in handy. Note that you do not necessarily need to use any or all of them. Shared variables between C and ASM . Recall that assembly symbols can be exported to C with the .global keyword. So, to create a variable that is shared between C and assembly, I can write the following in assembly: .global shared_var shared_var: .word 0x1234 . And then in C refer to it with the extern keyword: . extern uint32_t shared_var; . Emitting Arbitrary Instructions . You can emit an arbitrary encoding for an instruction with the .word keyword. For example, here is how to add the instruction encoded by 0x41414141 to the program: . some_asm_method: add sp, sp, -4 .word 0x41414141 add sp, sp, 4 . See exception_test.s:111 for an example! . Inline Assembly . You may find the inline assembly gcc features to be useful. Hints/ Warnings . | Recall that the CPU does have bugs with the add instruction, so be careful if your opcode enumeration code requires addition! | If your approach makes use of self modifying code, insert 5 nop instructions after your write instruction to flush the CPU pipeline. (If you try to write to an instruction and then immediately run it, a stale opcode may be in the pipeline.) | Don’t forget to commit any extra files you add to your git repo! | You can automate parts of your solution by writing Python code to produce assembly in bulk (eg. print(f\"la a0, {test_case}\") will emit the assembly code to load a0 with the Python variable test_case). If you write Python code, commit the Python code to your repo. | If your assembly code is too long, you might see relocation truncated to fit: R_RISCV_JAL error during the compilation. Here is what happens: JAL instruction can only jump to a range of [-1MB, 1MB]. If some function in your code is too long, this range might not be enough. To solve this, you could change your JAL instructions to JALR. | Your exception handler needs to communicate with your test code in some way to report when exceptions occur. How this works is up to you. | . This part is considered complete if your code finds and prints the opcode of the hidden backdoor instruction. 3.3 Elevating Privileges to Kernel Mode . Congrats on finding a hidden instruction! Your boss, amazed at your skills, wants to see if you can figure out how to activate the backdoor. You may have noticed that even after running the backdoor, you still cannot access privileged CSRs from PSP_PRIV_USER (try it!). Attempting to load a privileged CSR when the core is booted in PSP_PRIV_USER should throw a EXCEPTION_CAUSE_ILLEGAL_ACCESS (mcause=0x00000001) exception, even if the backdoor instruction is run first. So, why doesn’t the backdoor work? . It seems that the authors of the backdoor were even sneakier than we thought, and added another condition that must be satisfied before the backdoor instruction elevates your privileges. Your boss took the CPU to a focused-ion beam (FIB), and found a wire connecting the decode stage to register x10 that wasn’t in the original design. Your boss suspects that x10 must be loaded with a secret value before the backdoor is called. So far, your code has been running in PSP_PRIV_MACHINE. Before continuing, update bringup.s to start your code with PSP_PRIV_USER instead. This way, we can check to see if we gained any extra privileges by running the backdoor instruction. Additionally, for Part 3.3, you can hard-code the opcode you discovered in Part 3.2. 3-6 Discussion Question . Describe your approach for finding the correct x10 value. Does the exception handler behave differently when searching for the correct x10 value of that instruction compared to searching for hidden instructions? . 3-7 Exercise . Write some code to try and load a privileged CSR (pick any CSR you want!) and run it without running the backdoor instruction. You should see that the load succeeds if bringup.s starts your code in PSP_PRIV_MACHINE mode, and throws an exception if it starts in PSP_PRIV_USER. Now, while running in PSP_PRIV_USER, add a call to the backdoor instruction before the CSR read. You should still see an exception being thrown, even if you ran the backdoor instruction. This is because the backdoor is not called with the correct value for x10, and so it does not change the privilege level. Modify your code to set x10 to values between [0,65535] inclusive before calling the backdoor. For each value in [0,65535], set x10 to the value, run the backdoor instruction discovered in Part 3.2, and then try to load a CSR. If the CSR load succeeds, print the value of x10 out. If it fails, try another value of x10. You may need to modify your exception handler code to detect when CSR loads cause faults. When complete, your code should be able to start in PSP_PRIV_USER, call the backdoor with different x10 values until the CPU privilege level changes, and then read the contents of a privileged CSR. 3-8 Discussion Question . Include the correct x10 value found by your code/script in the report. When a CSR load fails, the CPU throws a different kind of exception- EXCEPTION_CAUSE_ILLEGAL_ACCESS (0x00000001) (see defines.h:48). You can use this to distinguish CSR load failures from illegal instruction exceptions. 3.4 Putting it All Together . Now we will combine your code to discover hidden instructions with your code to fuzz those instructions. Your combined code should, in one go, search the undocumented instructions to find the backdoor instruction, fuzz the backdoor instruction for the correct x10 value, and then print both the correct opcode and x10 value to standard out. 3-9 Exercise: Putting it All Together . Combine your code from Parts 3.2 and 3.3, printing both the discovered opcode and x10 value to standard out. 3-10 Discussion Question (optional) . After completing part 3, please share with us: . Did you encounter any challenges while building the code? How did you overcome the challenges of the add instruction occasionally producing an incorrect result? Did you try anything that failed? . When grading Part 3 we will run your code on a different CPU with a different backdoor opcode and x10 encoding, so do not assume anything about the value of these constants besides they are within the bounds specified in this document. You can assume that at most one backdoor instruction exists with exactly one correct x10 value corresponding to it. Submission and Grading . git add all the new files you created for Part 3, including any Python or shell scripts you wrote to automate generation of your code. When we build and run the contents of your part3 directory, your code for Part 3.4 should immediately begin running, and report the correct opcode and x10 value discovered on the hardware (which again, will have different values when we grade than they are on your assigned CPU). Your part 3 output should follow the following format (printf(\"backdoor=0x%X\\n\",backdoor) and printf(\"x10=0x%X\\n\",x10_val)): . +------------------+ | MIT SHD Fuzz Lab | Part 3 | +------------------+ backdoor=0x????00B x10=0x???? . ",
    "url": "/2024/labs/fuzz.html#part-3-fuzzing-for-a-hidden-cpu-backdoor-45",
    "relUrl": "/labs/fuzz.html#part-3-fuzzing-for-a-hidden-cpu-backdoor-45"
  },"70": {
    "doc": "CPU Fuzzing",
    "title": "Part 4: Using the Backdoor to Exploit a Remote System (15%)",
    "content": "For this final part, you will combine all of the bugs you have discovered so far to exploit a remote secure server. There is a Pretty Secure Processor running on the network hosting a C application running in unprivileged mode (PSP_PRIV_USER). This application is correctly written and suffers from no buffer overflow bugs during normal execution. However, the CPU suffers from the add bug as you have seen in the earlier parts of this lab. It also has the backdoor present which can be used to elevate your privileges to PSP_PRIV_MACHINE once code execution has been obtained. The source code for this secure server is found in the part4 directory. We will begin by testing our exploit on a local CPU where we can run with PSP_PRIV_MACHINE privileges and use gdb for testing. First, we will manipulate the CPU to cause a buffer overflow by feeding it inputs that cause the add instruction to malfunction, bypassing the bounds check. Next, we will write some RISC-V assembly to dump a hidden secret from the CPU by reading from some special CSRs – this assembly is the code we want to run on the remote processor. Finally, we will implement a return to shellcode attack, storing the assembly we wrote in the input buffer and tricking the CPU into jumping to it by overwriting the saved return address. This will allow us to send code to the remote CPU to run and cause it to be executed, granting us full control of the remote CPU. This part will introduce you to several commonly used CTF tools. You have also seen these tools in recitation. We will guide you through the process of using these tools to implement a software-hardware exploit on a remote server. Getting Started . First, cd into part4, build it with make, and run it. You should see something like the following: . +------------------+ | MIT SHD Fuzz Lab | Part 4 | +------------------+ inputbuf is at 0x2CD4 How long is your first name: 7 How long is your last name: 5 Ok, tell me your first name: Joseph And your last name: Ravi Your username is JosephRavi . Play around with the inputs and get a feel for how the application works. Note that the length inputs require you to add 1 byte for the newline character. That is, if your name is Joseph (6 chars), you would need to add a 7th character for the newline. See if you can overflow the buffer by typing in a large name. You should be unable to cause a crash (if you did, let us know on Piazza!) . 4.1 Redirecting Control Flow . Our primary objective of this part is to modify pc to point to an arbitrary address. We will accomplish this using a buffer overflow. Open shd.c and take a look at the code. You should see the following bounds check: . if (fname_len + lname_len &gt; sizeof(inputbuf)) { printf(\"Error: Your name is too large!\\n\"); return; } . This bounds check prevents the buffer from being overflown by normal inputs. As we control both fname_len and lname_len, we can skip this bounds check by feeding in inputs that should fail the check, but instead pass (their sum is less than sizeof(inputbuf)) because of a bug in the add instruction. Revisit the bugs you found in Part 2 and pick a set of inputs that satisfy this condition and try them here. Can you bypass the name length check? (Try it in the terminal!) . Once you have found input lengths that bypass the bounds check, see if you can get the CPU to crash by feeding in a really long username. You should be able to achieve something like the following: . +------------------+ | MIT SHD Fuzz Lab | Part 4 | +------------------+ inputbuf is at 0x2CD4 How long is your first name: {REDACTED} How long is your last name: {REDACTED} Ok, tell me your first name: AAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA ... AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA And your last name: Your username is AAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA ... AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA ============================= Exception! pc: 0x41414141 x1: 0x41414141 x2: 0x00002FF0 x3: 0x00000000 x4: 0x00000000 x5: 0x00000000 x6: 0x00000000 x7: 0x00000000 x8: 0x41414141 x9: 0x00000000 x10: 0x0000000A x11: 0x00002CD4 x12: 0x00000000 x13: 0x00000000 x14: 0x0000000A x15: 0x00000000 x16: 0x00000000 x17: 0x00000000 x18: 0x00000000 x19: 0x00000000 x20: 0x00000000 x21: 0x00000000 x22: 0x00000000 x23: 0x00000000 x24: 0x00000000 x25: 0x00000000 x26: 0x00000000 x27: 0x00000000 x28: 0x00000000 x29: 0x00000000 x30: 0x00000000 x31: 0x00000000 TODO: You need to write the exception handler return code! . Notice how we crashed with pc=0x41414141. 0x41 is the ASCII encoding for the character A. This is great news! It means that our input somehow made its way into the pc register by overwriting the saved ra on the stack somewhere. shd_main stores the return address on the stack, and restores it before exiting. Since we bypassed the buffer size check, our string was so large that it overwrote this value on the stack, meaning that when shd_main tried to return, it instead treated our input as an address and tried to jump to it. You will see 0x41414141 in a lot of security blog posts as a “proof-of-concept” that a bug is exploitable. Now open solve_part4.py. This is a Python script that uses the pwntools library to automate interacting with the processor. This script will allow us to easily send non-printable characters (like assembly bytes) into the CPU. We have filled in a starter skeleton for you to use to build your exploits. Feel free to write your exploit however you want, the starter skeleton is simply a guide. We will use this script to automate overflowing the buffer and precisely redirecting code flow to our controlled data on the stack. Note that while our earlier proof-of-concept (filling the buffer with AAAAAAA...) proved that we can gain control of pc, it did not tell us which part of our input eventually made its way into pc. That’s because every byte of our input is identical! (That is, we don’t know if it was the first A, one of the A’s in the middle, or the last A that made it into pc since they are all the same). pwntools provides the method cyclic that allows us to fix this issue in a really efficient way. cyclic returns what’s called a de Bruijn sequence. The output of this is a series of unique 4 byte chunks that do not repeat (for a very long time, anyways). Give it a try: . &gt;&gt;&gt; cyclic(100) b'aaaabaaacaaadaaaeaaafaaagaaahaaaiaaajaaakaaalaaamaaanaaaoaaapaaaqaaaraaasaaataaauaaavaaawaaaxaaayaaa' . Generate a long username with cyclic and use that as your username. You should see a new crash pc value. This pc value will be the ASCII encoding of some unique part of the de Bruijn sequence. Since each 4 byte chunk is different, we now know exactly where in the input sequence pc is being read from. For example pc could be 0x6161616F. Using this feedback, pwntools quickly allows you to look up the offset in the input string that controls pc with cyclic_find. &gt;&gt;&gt; cyclic_find(0x6161616F) 56 . In this example, the offset 56 bytes into my overflow was what controlled pc. 4-1 Exercise . Open solve_part4.py. Fill in FIRSTNAME_LEN and LASTNAME_LEN with the inputs you found above. Fill in the argument to cyclic_find with the pc value you found using cyclic. This will fill in buf with enough A’s to stop right before what gets filled into pc. Now, the next 4 bytes input into buf will be put into pc when shd_main returns. These bytes must be packed as a 32 bit integer (little endian), which the p32 method will handle for you. Fill in some hex number into the p32 call, send the buf to the processor as the first and last names, and run the script – you should see a crash with pc set to that hex number. Once you can reliably use solve_part4.py to change pc to an arbitrary address, you are done with Part 4.1! . 4.2 Dumping the Flag . Now, we will write some assembly to read the flag from a sequence of CSRs. CSRs 0xFC0 to 0xFF0 contain a hidden secret flag that requires PSP_PRIV_MACHINE to read. The first ASCII char of the flag is stored in CSR 0xFC0, the next in 0xFC1, and so on. 4-2 Exercise . Create a new C or assembly file with a method that reads CSRs starting at 0xFC0 and ending at 0xFF0. If you are using assembly, don’t forget to mark your method as global with .global. For each CSR, write the value read to CSR 0x202 (the softserial output port) to display it in the terminal. To test your code, modify bringup.s to boot the CPU with PSP_PRIV_MACHINE, modify shd.c to call your method (add a call to it somewhere in shd_main), and run the processor. You should see an example flag printed out to the terminal. Once that is working, modify back bringup.s to boot the CPU with PSP_PRIV_USER. Your flag dumper should no longer work. Add a call to the backdoor instruction you discovered in Part 3 to your flag dump routine, and try it again – the flag dumper should once again work. 4-3 Discussion Question . This part is complete once your flag dump routine can dump CSRs 0xFC0 to 0xFF0 to the console, even when bringup.s boots the CPU in PSP_PRIV_USER mode. You should see an example flag of the form MIT{...} printed. Include this flag in your report. We recommend using assembly for this part. We also recommend automatically generating your assembly code with a Python script. Create a Python script called gen_dump_flag.py and fill it with print commands to output the assembly instructions you need to dump the flag. Make sure to output a symbol and mark it as global so you can find it from C. (eg.global flag_dump and flag_dump: before your instructions). Refer to serial_csr.s for a refresher on how to read/ write CSRs! (Specifically, the serial port). You may also find referring to the psp documentation page useful. 4.3 Writing the Exploit . We will now combine the primitives from parts 4.1 and 4.2 to exploit the remote CPU. To recap, in Part 4.1 we discovered how to modify control flow (e.g., change the pc register) by causing a buffer overflow when the CPU miscomputes a bounds check with the buggy add instruction. In Part 4.2 we wrote some assembly code (called “shellcode”) that is able to elevate its own privileges using the CPU backdoor and dump the contents of some privileged CSRs to the console. In Part 4.3, we will use the ability to control pc to cause the CPU to jump to our own input buffer (where the username field goes). We will fill that input buffer with the code from Part 4.2 and send it to the CPU over serial. Then, we will use the buffer overflow to trick the CPU into jumping to the buffer, running the shellcode and granting us machine privileges. The following figure provides an overview of this attack: . There is a remote Pretty Secure Processor attached to the network running this same program in PSP_PRIV_USER mode. You can attach to it by hand with the following command: . nc localhost 31337 . Give it a try! You should see the same app you are already familiar with. The difference is that nc connects to a remote CPU that you do not have access to, so you cannot change the code or dump the CSRs without writing an exploit. We are going to fill out the rest of solve_part4.py to automate sending the shellcode you wrote in 4.2 to the CPU. We will use this script to send this payload over the network to exploit the remote CPU and reveal a privileged flag. 4-4 Exercise . Uncomment lines 24 and 25 in solve_part4.py. These lines read in a binary file called dump_flag.bin and write it into a variable called shellcode. dump_flag.bin should contain the binary values (the assembled bytes) of the code you wrote in 4.2. You can use the following to convert the object file (.o) into a binary dump (.bin) to be used in the exploit. Assuming your assembly file containing the flag dump routine is called dump_flag.s: . make # Assemble the assembly file into a .o object riscv64-unknown-elf-objcopy -O binary dump_flag.o dump_flag.bin # Dump the .o into a .bin . Now, in Python, you can use the following to read your assembly code in as a bytestring: . shellcode_f=open('part4/dump_flag.bin', 'rb') shellcode=shellcode_f.read() . We want to set buf (the Python bytestring we send to the CPU) to begin with shellcode, followed by padding to make it the correct length, followed by p32(&amp;inputbuf). This way, the CPU will attempt to execute starting at the first byte of inputbuf, which contains our shellcode variable (the flag dumper). The starter code handles most of this for you: . buf = shellcode buf += b'A' * (cyclic_find(0) - len(buf)) # cyclic_find() should have been filled in in 4.1 buf += p32(0) # Replace 0 with the location of inputbuf as displayed by the program . Now, run solve_part4.py and you should see the flag printed to the console. Finally, at the top of the program, comment out io=process(['./run.sh', 'part4']) and uncomment: . # Uncomment this to try on the remote CPU: # io=remote('127.0.0.1', 31337) . Try solve_part4.py again and it should dump the flag of the remote CPU! This flag should be different to the one you see when running on the local CPU. Once you have leaked the flag from the remote CPU, you are done with this lab. 4-5 Discussion Question . Include the flag leaked from the remote CPU in your report. Do not worry about cleaning up after your exploit – if the CPU crashes after dumping the flag, that is fine, as long as there is not an unreasonable amount of extra text generated after. To clean your exploit up, you can add a j . instruction at the end of your flag dumper which will trigger an infinite loop, preventing any crashes or extra text generation. Submission and Grading . git add all the new files you created for Part 4, including any Python or shell scripts you wrote to automate generation of your code. In your report, include the flag you leaked from the remote CPU. Also include in your report where to find the flag dumper method in your part4 directory. Your solve_part4.py code should attempt to connect to the remote CPU and dump the flag to the console when run. ",
    "url": "/2024/labs/fuzz.html#part-4-using-the-backdoor-to-exploit-a-remote-system-15",
    "relUrl": "/labs/fuzz.html#part-4-using-the-backdoor-to-exploit-a-remote-system-15"
  },"71": {
    "doc": "CPU Fuzzing",
    "title": "Part 5: Bug Bounty (Optional, 10% Bonus)",
    "content": "Did you find something wrong with the lab? Were you able to break the CPU in an unintentional way? (Eg. cause a deadlock, found a bug or race condition in other instructions, etc.). Did you find a way to crash our GDB server or a bug in the simulator? . Find a bug in the lab materials, let us know about it, and you may be rewarded with bonus points! . There is no intended solution for this part – we do not know of any bugs in our lab code. However, we encourage you to try and find some! . Non-exhaustive list of possible bugs: . | Deadlock condition that causes the CPU to stop executing instructions. | Memory corruption vulnerability in our GDB server implementation. | Incorrect pipeline hazard forwarding for system control instructions (eg. ecall, csrrw, mret, and the backdoor). | Incorrect handling of privilege level for instructions at different privilege levels simultaneously in the pipeline. | Simulator errors or incorrect reading of system state (single stepping causes multiple instructions to be executed instead of one, register state read by GDB is incorrect at a given instruction, memory contents as seen by GDB are incorrect or delayed by a few cycles). | Vestigial features (such as secure calls/ pointer HMACs, features the core used to support but we disabled – see the GitHub page) were incorrectly disabled and cause bugs. | System Management Core exploits (the IPI generator/ IPI ring) – what happens if userspace code triggers a self-IPI? | . We are most interested in unintentional breaks of the RISC-V specification or issues where the core fails to comply with our stated documentation. An example of a non-issue is how some of our CSRs do not comply with the specification – we intentionally break the ISA in some limited documented situations. Note that what issues qualify for the bonus is at the sole discretion of the instructor. ",
    "url": "/2024/labs/fuzz.html#part-5-bug-bounty-optional-10-bonus",
    "relUrl": "/labs/fuzz.html#part-5-bug-bounty-optional-10-bonus"
  },"72": {
    "doc": "CPU Fuzzing",
    "title": "Part 6: Challenge Problem (Optional, No Credit)",
    "content": "Was this lab too easy for you? Here’s an optional for-fun challenge problem to further test your exploitation skills. There’s another Pretty Secure Processor running on the network, except this time it has a different set of CPU bugs. You’ll need to port your fuzzer into your exploit payload. But how do you even get an exploit payload to run in the first place…? . nc localhost 31338. 6-1 Exercise (Optional) . Fill in your exploit in solve_part6.py. ",
    "url": "/2024/labs/fuzz.html#part-6-challenge-problem-optional-no-credit",
    "relUrl": "/labs/fuzz.html#part-6-challenge-problem-optional-no-credit"
  },"73": {
    "doc": "CPU Fuzzing",
    "title": "Acknowledgements",
    "content": "Made by Joseph Ravichandran and Mengjia Yan. ",
    "url": "/2024/labs/fuzz.html#acknowledgements",
    "relUrl": "/labs/fuzz.html#acknowledgements"
  },"74": {
    "doc": "CPU Fuzzing",
    "title": "CPU Fuzzing",
    "content": " ",
    "url": "/2024/labs/fuzz.html",
    "relUrl": "/labs/fuzz.html"
  },"75": {
    "doc": "Home",
    "title": "Secure Hardware Design (Spring 2024)",
    "content": "Learn to attack processors… and learn to defend them! . ",
    "url": "/2024/#secure-hardware-design-spring-2024",
    "relUrl": "/#secure-hardware-design-spring-2024"
  },"76": {
    "doc": "Home",
    "title": "Welcome to 6.5950/6.5951 (previously 6.S983 and 6.888)!",
    "content": "6.5950/6.5951 is a research-oriented course on secure hardware design. 6.5950/6.5951 will help you understand the critical security problems in modern hardware and common limitations of existing security solutions. Through a mix of lectures and paper discussions, we will learn the principles of various attacks and how to design effective hardware mitigations and hardware/software co-design solutions. Previous years’ website . Feel free to post your anonymous feedback here during the semester. ",
    "url": "/2024/#welcome-to-6595065951-previously-6s983-and-6888",
    "relUrl": "/#welcome-to-6595065951-previously-6s983-and-6888"
  },"77": {
    "doc": "Home",
    "title": "Meeting Location and Times",
    "content": "Required Lectures: Mondays and Wednesdays from 1:00pm to 2:30pm in Room 56-114. Note that participation is required at scheduled time; take this course only if you will generally be able to participate! . We will use Piazza for all course-related discussion. ",
    "url": "/2024/#meeting-location-and-times",
    "relUrl": "/#meeting-location-and-times"
  },"78": {
    "doc": "Home",
    "title": "Assignments and Grading",
    "content": "6.5950/6.5951 will have no midterm or final exams. There are three required assignments: . | Lab Assignments (85% for graduate version, 97% for undergraduate version): There will be 6 lab assignments. Students will be asked to implement their own attacks that work on real machines (not simulators). | Lab Check-offs(3%): Over the course of the term, we will randomly select one of your labs for an in-person check-off. During a check-off you will discuss your submission with the TA, describing your implementation, and elaborating on your written answers. | Paper Discussion (12% for graduate version): Each student taking graduate version will be asked to select a topic from the 3 discussion sessions, review relevant materials, write a presentation, and lead the class discussion for that topic. To facilitate a fruitful exchange, all students (taking either graduate or undergraduate versions) are expected to read the papers prior to the session and engage in class discussion. Although we will not be formally tracking attendance, we expect regular attendance and participation. | . ",
    "url": "/2024/#assignments-and-grading",
    "relUrl": "/#assignments-and-grading"
  },"79": {
    "doc": "Home",
    "title": "Staff",
    "content": "Professor Mengjia Yan Email: mengjia at csail.mit.edu Office: 32-G840 Office Hours (32-G840): Fridays 2:30pm-3:30pm . TA Yuheng Yang, William Liu, Peter Deutsch Email: shd-staff at mit.edu Office: 32-G786 Office Hours (32-G7 Lobby): Mondays 4pm-6pm; Wednesdays 10am-noon; Lab Due Dates 10am-noon &amp; 6pm-8pm . Infra Joseph Ravichandran Email: shd-staff at mit.edu Office: 32-G786 . ",
    "url": "/2024/#staff",
    "relUrl": "/#staff"
  },"80": {
    "doc": "Home",
    "title": "Prerequisites",
    "content": "6.5950/6.5951 is primarily intended for seniors, M.Eng, and PhD students who want to learn about how to design hardware processors with security as the primary goal. You should have a good understanding of basic computer architecture (i.e., a strong grasp of the material taught in 6.004). 6.5950/6.5951 is a 12-unit (3-0-9) subject. It is listed as an AUS/AAGS and TQE course. ",
    "url": "/2024/#prerequisites",
    "relUrl": "/#prerequisites"
  },"81": {
    "doc": "Home",
    "title": "Late Policy",
    "content": "Late lab submissions within 5 late days are subject to a 10% penalty per late day, with a maximum penalty of 50%. After spending 5 late days on a single lab, no credit will be given for that lab. Throughout the semester, you have 5 free late days, to be used as whole days. It means that the above penalty is automatically waived for your first 5 late days during the semester. You can use these free late days if you are sick, you are having a busy week, or you need more time to complete the lab. Long weekends (i.e., Feb 17-19, Apr 13-15) and the spring break (i.e., Mar 23-31) do not count into late days. For example, if you had a lab4 submission that would normally earn 100% if turned in on-time on Apr 11 by 11:59 PM, and you had used up free late days, it would earn 90% if turned in on Apr 12 by 11:59 PM, earn the same 90% if turned in on Apr 15 by 11:59 PM due to the long weekend, and earn no credit if turned in on or after Apr 20. In addition, extensions without penalty may be granted on a case-by-case basis with support from S3. Please email the staff or post a private note on Piazza to request an extra extension. If there are medical issues that require further accommodation, please contact the staff. ",
    "url": "/2024/#late-policy",
    "relUrl": "/#late-policy"
  },"82": {
    "doc": "Home",
    "title": "Collaboration Policy",
    "content": "Laboratory exercises should be completed individually, and the work you hand in must be your own. Copying another person’s work or allowing your work to be copied by others is a serious academic offense and will be treated as such. As a general rule, follow the MIT Academic Integrity Policy and, when in doubt, ask the course staff. Violations of this policy will be treated severely. Examples of permitted collaboration . | Allowed: Talk to a friend about a lab assignment and discuss at a high level how to go about completing the assignment. | Allowed: Ask a staff member for help if you are confused or stuck. | Allowed: After you’ve completed and submitted your own lab, help a friend debug their code solely by looking at their code and trying to identify problems with it. | . Examples of prohibited collaboration . | Not Allowed: Help a friend debug their code by bringing up your solution and comparing the two to identify differences. | Not Allowed: Using code from a friend who previously took the class as a starting point for completing your labs and then making some modifications to that code. | Not Allowed: Working together so closely that you are basically typing in your solutions side by side. | Not Allowed: Copying any portion of someone elses work even if you make some modifications to it. | Not Allowed: Sharing any portion of your code with someone else. | Not Allowed: Get help from a friend who is looking at their solutions while helping you. | . See the MIT Academic Integrity Policy. ",
    "url": "/2024/#collaboration-policy",
    "relUrl": "/#collaboration-policy"
  },"83": {
    "doc": "Home",
    "title": "Warning",
    "content": "You’ll learn how to attack computer systems in this class in order to better understand how to design defenses. Please don’t attack other people’s computers or information without their prior permission. As well as being a bad idea, it may be illegal or a violation of MIT network rules and can get you into serious trouble. ",
    "url": "/2024/#warning",
    "relUrl": "/#warning"
  },"84": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/2024/",
    "relUrl": "/"
  },"85": {
    "doc": "Labs",
    "title": "Labs",
    "content": "There will be 6 laboratory exercises given throughout the semester related to lecture content. | Lab | Difficulty | Due On | . | 1. Website Fingerprinting (10%) | Easy | Thu, Feb 15 | . | 2. Cache Attacks (15%) | Hard | Thu, March 7 | . | 3. Spectre Attacks (12%) | Easy | Thu, March 21 | . | 4. Rowhammer (12%) | Hard | Thu, Apr 11 | . | 5. ASLR Bypasses (12%) | Easy | Thu, Apr 18 | . | 6.A CPU Fuzzing (12%) | Hard | Tue, May 7 | . | 6.B CPU Verification (12%) | Easy | Tue, May 14 | . In total, your lab grade contributes 85% (for graduate version, as shown in the table above) or 97% (for undergraduate version, by scaling up the numbers in the table above) to your total grade in the course. Each lab is due at 11:59 PM. ",
    "url": "/2024/labs.html",
    "relUrl": "/labs.html"
  },"86": {
    "doc": "Labs",
    "title": "Lab Check-Offs",
    "content": "Over the course of the term, we will randomly select one of your labs from lab 2, 4, and 6.A for an in-person check-off (worth 3% of your total course grade). We will inform you whether you are selected for a lab on the day after the due of that lab. And you can pick a check-off time slot for the following week. During a check-off you will discuss your submission with the TA, describing your implementation and elaborating on your written answers. ",
    "url": "/2024/labs.html#lab-check-offs",
    "relUrl": "/labs.html#lab-check-offs"
  },"87": {
    "doc": "Labs",
    "title": "Submission Instructions",
    "content": "Labs will be submitted via GitHub Classroom, and accompanying reports will be submitted via Gradescope. GitHub . To access and submit lab materials, you will need to have a github.com account. For each lab, we will create a new repository for you on GitHub Classroom. To access the repository: . Check Piazza posts for the invitation link of Github Classroom. To clone the starter code from the repository: . git clone &lt;GITHUB CLASSROOM REPOSITORY LINK&gt; . However, if you have never used github on the machine you are running (i.e., either your own machine or our servers), you need following steps to authorize the machine to access GitHub: . | If you are using our server, connect using ssh (i.e., ssh username@&lt;servername&gt;.csail.mit.edu) | ssh-keygen -t rsa -b 4096 (note that if you already have an ssh key, you can skip this) | Press return until the command finishes. | cat ~/.ssh/id_rsa.pub (feel free to use an existing key if you have one) | Copy this and create a new ssh key on your GitHub account (instructions if you need help). | git clone &lt;GITHUB CLASSROOM REPOSITORY LINK&gt; | . To push your changes (submitting your work): . git add FILES_YOU_CHANGED git commit -m \"WHAT YOU CHANGED\" git push . GitHub classroom will snapshot the state of your repository at the due date (at 23:59:59), which we will use to grade your submission. Your repository will not be locked after that point, feel free to continue to push if we have allowed an extension for you. Gradescope . Each lab contains exercises and discussion questions. Type your answers to discussion questions in the markdown template provided in the starter code of each lab (report.md). Convert the markdown file to PDF (e.g., you can simply open the file on github.com and print it to PDF with your web browser) and upload the PDF file to Gradescope (prior to the submission deadline). ",
    "url": "/2024/labs.html#submission-instructions",
    "relUrl": "/labs.html#submission-instructions"
  },"88": {
    "doc": "Labs",
    "title": "Development Environment",
    "content": "For all our labs (and recitations, except lab 1), we will setup a user account for you on our lab machines, where the development environment has been properly setup. Check the email to get your username and the password. Alternative Docker Environment . Most our labs highly depend on the configurations of our physical machines (e.g., cache organization, DRAM model) and cannot be done locally on your own machine. However, for some labs, it is possible run the lab locally and we will provide a docker file in the repository to setup your environment. To use docker, you need to first understand two concepts: . | Docker Image: An image file storing all the pre-installed libraries (e.g., compilers, python libraries). | Docker Container: A running environment that is provisioned with a docker image and contains all the modifications you have made (e.g., install a new library). | . Then, you can use docker with follwing steps: . | Download the docker engine here. | In the root folder of a repository, where file Dockerfile and docker-compose.yml exist, use the command below to build the docker image, use the image to create a container, and run the container: docker compose up -d . | Enter the container and run bash with (env below is the name of the container that we specify in docker-compose.yml): docker compose exec env bash . | For your convenience, we mount the repository folder on your host machine into a folder named /gitRepo in the container (defined in docker-compose.yml). You could enter the folder and start to run the code: cd /gitRepo . | If you want to continue with the lab in another time, you could exit the container with ctrl-d. Then, pause and resume the container with: docker compose stop # Pause docker compose up -d # Resume . | When you are done with the lab, you could delete the container and the image with (Both commands will delete any modification you made to the container): docker compose down # Delete container but keep the image docker compose down --rmi all # Delete both container and image . | . You can find more document on using Docker Compose to manage docker images and containers here. ",
    "url": "/2024/labs.html#development-environment",
    "relUrl": "/labs.html#development-environment"
  },"89": {
    "doc": "Lecture Readings",
    "title": "Lecture Readings",
    "content": "* Indicates the resource requires MIT library login . | | Background Reviews and Related Books | Research Papers (mentioned in class) | Fun Readings and Videos | . | L01: Overview | 6.191 [6.004] slides: . | L01 The Digital Abstraction | L12 Memory Hierarchy | L13 Caches | L15 Pipelined Processors: Data and Control Hazards | L16 Operating Systems | L17 Virtual Memory 1 | L18 Virtual Memory 2 | L22 Modern Processor Architecture | . | | . | USENIX ATC '21/OSDI '21 Joint Keynote Address-It's Time for Operating Systems to Rediscover Hardware | . | . | L02: Side Channel Overview | | . | DAWG: A Defense Against Cache Timing Attacks in Speculative Execution Processors (Section I) | A retrospective on the VAX VMM security kernel. 1991 (Section VI-E) | . | . | Side Channel Security Youtube Channel | . | . | L03: Deep Dive of Cache Side Channels | | . | FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack | Last-Level Cache Side-Channel Attacks are Practical | Attack Directories, Not Caches: Side Channel Attacks in a Non-Inclusive World | . | . | EntryBleed: Breaking KASLR under KPTI with Prefetch | . | . | L04: Transient Execution Side Channels | . | 6.5900 [6.823] L06 Complex Pipelining Scoreboarding (Recording) (covered in the lecture, but if want to get more details about out-of-order execution) | . | . | On the Spectre and Meltdown Processor Security Vulnerabilities | Meltdown: Reading Kernel Memory from User Space | Spectre Attacks: Exploiting Speculative Execution | Speculative Load Hardening: A Spectre Variant #1 Mitigation Technique | MDS: Microarchitectural Data Sampling | . | | . | L05: Hardware-Software Contracts | | . | Hardware-Software Contracts for Secure Speculation | ARM. DIT, Data Independent Timing | Intel. Data Operand Independent Timing Instruction Set Architecture (ISA) Guidance | FaCT: A DSL for Timing-Sensitive Computation | Secure, Precise, and Fast Floating-Point Operations on x86 Processors | BearSSL. Constant-time Crypto | . | | . | L06: Side-channel Mitigations | | . | Complete Information Flow Tracking from the Gates Up | New Attacks and Defense for Encrypted-Address Cache | Speculative Taint Tracking (STT): A Comprehensive Protection for Speculatively Accessed Data | . | | . | L07: Hardware Security Module (HSM) | . | Intel SGX Explained (Section 3.1-3.3, 4.1, 4.4-4.5) | Principles of Secure Processor Architecture Design* (Chaper 5 Hardware Root of Trust) | . | . | Building the IBM 4758 Secure Coprocessor. 2001 | Apple Platform Security (Page 5-96) | . | | . | L08: Physical Attacks (by Joseph Ravichandran) | . | 6.191 [6.004] L01 The Digital Abstraction | 6.191 [6.004] L06 Sequential Circuit | The Hardware Hacking Handbook* (Chapter 1, 5, 8, 13; The whole book includes many practical tips on how to carry out physical attacks by yourself) | Hacking the Xbox | . | . | Power Analysis Attacks: Revealing the Secrets of Smart Cards. 2007* | Building a high-performance, programmable secure coprocessor. 1999 (Section 4) | . | . | Talk on Supply Chain Attacks &amp; Verifiability | . | . | L09: Rowhammer Attacks | . | Memory systems: cache, DRAM, disk.* (Chapter 10 DRAM Memory System Organization) | . | . | Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors | Flip Feng Shui: Hammering a Needle in the Software Stack | CLKSCREW: Exposing the Perils of Security-Oblivious Energy Management | Hertzbleed: Turning Power Side-Channel Attacks Into Remote Timing Attacks on x86 | The Story of Rowhammer - Keynote at Secure Hardware, Architectures, and Operating Systems Workshop (SeHAS) at the HiPEAC 2021 Conference | . | . | Exploiting the DRAM rowhammer bug to gain kernel privileges. Google Project Zero | . | . | L10: Rowhammer Mitigation + Reliability Solutions | | . | Graphene: Strong yet Lightweight Row Hammer Protection | REGA: Scalable Rowhammer Mitigation with Refresh-Generating Activations | Hydra: Enabling Low-Overhead Mitigation of Row-Hammer at Ultra-Low Thresholds via Hybrid Tracking | Revisiting Residue Codes for Modern Memories | OpenTitan Website | OpenTitan Github | OpenTitan Talk in CHES 2022 | . | | . | L11: Hardware Support for Software Security | . | SoK: Eternal War in Memory | . | . | Smashing the Stack for Fun and Profit | An Introduction to CHERI | The Arm Morello Board | Virtual memory primitives for user programs. 1991 | Memory protection keys | Qualcomm. Pointer Authentication on ARMv8.3 Design and Analysis of the New Software Security Instructions | Armv8.5-A Memory Tagging Extension | Intel. Control-flow Enforcement Technology Specification (Section 1-3) | Control-flow integrity principles, implementations, and applications. 2005 | . | . | xkcd. HeartBleed Explanation | . | . | L12: Fuzzing and Bug Finding | | . | Computational aspects of the Pentium affair. 1995 | Fuzzing Hardware Like Software | SPECS: A Lightweight Runtime Mechanism for Protecting Software from Security-Critical Processor Bugs | Bug Attacks | HardFails: Insights into Software-Exploitable Hardware Bugs | The Art, Science, and Engineering of Fuzzing: A Survey | Branch History Injection: On the Effectiveness of Hardware Mitigations Against Cross-Privilege Spectre-v2 Attacks | SiliFuzz: Fuzzing CPUs by proxy | . | . | Breaking the x86 Instruction Set. BlackHat | Intel Pentium FPU glitch. 1994 | A Stitch In Time Saves Nine: A Stitch In Time Saves Nine: A Case Of Multiple OS Vulnerability | Riding the Fuzzing Hype Train (RAID'21 Keynote) | . | . | L13: Formal Verification for Hardware Security | | . | The Complexity of Theorem-Proving Procedures. 1971 | A Machine Program for Theorem-Proving. 1962 | GRASP: A Search Algorithm for Propositional Satisfiability. 1999 | End-to-End Verification of ARM Processors with ISA-Formal. 2016 | . | | . | L14: Trusted Execution Environment (TEE) | . | Intel SGX Explained (Section 5 SGX Programming Model) | . | . | SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments | AMD Secure Encrypted Virtualization (SEV) | Protecting VM Register State With SEV-ES | AMD SEV-SNP | Keystone: An Open Framework for Architecting Trusted Execution Environments | RISC-V Privileged Instructions (Section 3.6) | Arm Confidential Compute Architecture (Arm Website) | Intel Trust Domain Extensions (TDX) | . | | . ",
    "url": "/2024/lectureReadings.html",
    "relUrl": "/lectureReadings.html"
  },"90": {
    "doc": "Lecture Readings",
    "title": "Lecture Readings",
    "content": " ",
    "url": "/2024/lectureReadings.html",
    "relUrl": "/lectureReadings.html"
  },"91": {
    "doc": "Paper Discussion",
    "title": "Paper Discussion",
    "content": "In each discussion session, we will discuss 5 papers around a same topic. The discussion of each paper will be led by 2 students (who take the graduate version of the course, i.e., 6.5950). Throughout the semester, each student will only lead the discussion once. The papers to be discussed are selected from top security and computer architecture conferences, covering broad hardware security topics representing the state of the art. For the presenters, please check Piazza posts for knowing when you will present which paper. As you prepare for the presentation, make sure to refer to our detailed paper reading guidance for how to read a hardware security paper, what is required for the presentation, and how your presentation will be graded. For the audience, we encourage you to pick a paper to read before each discussion session and ask questions during the Q&amp;A of that paper, as well as other papers. Based on the quality of the questions, we will give bonus points toward your final grades. Audience and presenters will also be invited to vote how much you like each paper (e.g., should it get a “Best Paper Award”?). It would be fun and we are curious about your opinions on them! . ",
    "url": "/2024/paperDiscussion.html",
    "relUrl": "/paperDiscussion.html"
  },"92": {
    "doc": "Paper Discussion",
    "title": "Papers",
    "content": "Recent Microarchitecture Attacks (March 4) . | Hertzbleed: Turning Power Side-Channel Attacks into Remote Timing Attacks on x86 | Last-Level Cache Side-Channel Attacks are Practical | Port Contention for Fun and Profit | Opening Pandora’s Box: A Systematic Study of New Ways Microarchitecture Can Leak Private Data | An Analysis of Speculative Type Confusion Vulnerabilities in the Wild | . More Physical Attacks (April 8) . | Flip Feng Shui: Hammering a Needle in the Software Stack | CLKSCREW: Exposing the Perils of Security-Oblivious Energy Management | SRAM Has No Chill: Exploiting Power Domain Separation to Steal On-Chip Secrets | One Glitch to Rule Them All: Fault Injection Attacks Against AMD’s Secure Encrypted Virtualization | Exploiting Correcting Codes: On the Effectiveness of ECC Memory Against Rowhammer Attacks | . Hardware Support for Software Safety (April 29) . | PACMem: Enforcing Spatial and Temporal Memory Safety via ARM Pointer Authentication | Preventing Kernel Hacks with HAKC | The CHERI capability model: Revisiting RISC in an age of risk | Speculative Probing: Hacking Blind in the Spectre Era | CHEx86: Context-Sensitive Enforcement of Memory Safety via Microcode-Enabled Capabilities | . Fuzzing and Formal Verification (May 6) . | SiliFuzz: Fuzzing CPUs by Proxy | Cascade: CPU Fuzzing via Intricate Program Generation | SpecDoctor: Differential Fuzz Testing to Find Transient Execution Vulnerabilities | SPECS: A Lightweight Runtime Mechanism for Protecting Software from Security-Critical Processor Bugs | Revizor: Testing Black-Box CPUs against Speculation Contracts | HyPFuzz: Formal-Assisted Processor Fuzzing | . ",
    "url": "/2024/paperDiscussion.html#papers",
    "relUrl": "/paperDiscussion.html#papers"
  },"93": {
    "doc": "Paper Readings Guidance",
    "title": "How to read a research paper?",
    "content": "References . | How to Read a Paper; S. Keshav; ACM SIGCOMM Computer Communication Review; 2007. | How to Read an Engineering Research Paper; William G. Griswold. | . We recommend the students use the three-pass approach by S. Keshav and read the paper while thinking about the questions listed in an article by William G. Griswold. We highly encourage you to read these two articles as they contain more content such as note-taking tips. We provide an adapted and succinct version of how to read a hardware security paper for the SHD course below. The Three-Pass Approach . The first pass: . | Read the title, abstract, introduction, section and subsection titles, related work, and conclusion. | After this pass, you should be able to answer the following questions: . | Category: What type of paper is this? Is it an attack paper, a defense paper, or an analysis paper? | Context (relevance to related work): Which other papers is it related to? If it is an attack paper, what are the other existing attacks that target the same threat model? If it is a defense paper, what are the other existing defenses that share a similar security goal as this paper? | Contributions: What are claimed as the paper’s main contributions? | . | . The second pass: . | Read the paper with greater care, but ignore details such as proofs. Look carefully at the figures, diagrams and other illustrations in the paper. The goal is to grasp the key content of the paper. | As you read through the paper, attempt to answer the following questions (from Griswold’s article and adapted for hardware security papers): . | What are the motivations for this work? For a security research paper, there is an expectation that the paper either discovers a new security threat or solves a security problem that no one else has published in the literature. | To derive the motivation of the paper, you need to consider why the security problem has not been discovered or why it does not have a trivial solution. | There is also an implication that previous attacks or solutions to the problem are inadequate. What are the previous attacks/solutions and why are they inadequate? | Finally, the motivation and statement of the problem are distilled into a research question, the question that the paper sets out to answer. | . | What is the proposed attack or defense? . | This is also called the idea of the paper. This is the proposed answer to the research question. | There should also be an answer to the question of why it is believed that this attack/defense will work, and be better than previous work. | There should also be a discussion about how the attack/defense is achieved (designed and implemented) or is at least achievable. | . | What is the work’s evaluation of the proposed solution? . | An idea alone is usually not adequate for the publication of a research paper. The evaluation is the concrete engagement of the research question. | What argument, implementation, and/or experiment makes the case for the value of the ideas? What benefits or problems are identified? | . | What is your analysis of the identified problem, idea and evaluation? . | Is this a good idea? What flaws do you perceive in the work? What are the most interesting points made? What are the most controversial ideas or points made? | For work that has practical implications, you also want to ask: Is this attack/defense really going to work, who can pull off the attack, and who would want the defense solution? | . | What are the contributions? . | The contributions in a paper may be many and varied. Beyond the insights on the research question, a few additional possibilities include: ideas, software, experimental techniques, or an area survey. | . | What are future directions for this research? . | Not only what future directions do the authors identify, but what ideas did you come up with while reading the paper? Sometimes these may be identified as shortcomings or other critiques in the current work. | . | What questions are you left with? . | What questions would you like to raise in an open discussion of the work? What do you find confusing or difficult to understand? By taking the time to list several, you will be forced to think more deeply about the work. | . | What is your take-away message from this paper? . | Sum up the main implication of the paper from your perspective. This is useful for very quick review to refresh your memory. It also forces you to try to identify the essence of the work. | . | . | . The third pass (optional for this course): . | The key to the third pass is to attempt to virtually re-implement the paper: that is, making the same assumptions as the authors, re-create the work. By comparing this re-creation with the actual paper, you can easily identify not only a paper’s innovations, but also its hidden failings and assumptions. This is usually needed when you are reviewing the paper as a program committee member. | You should identify and challenge every assumption in every statement. During this pass, you should also jot down ideas for future work. | . ",
    "url": "/2024/paperReadingGuidance.html#how-to-read-a-research-paper",
    "relUrl": "/paperReadingGuidance.html#how-to-read-a-research-paper"
  },"94": {
    "doc": "Paper Readings Guidance",
    "title": "How will we run the discussion session?",
    "content": "During each paper discussion session, we will keep track of the time for each paper. If you run out of time, you will be interrupted and end up not finishing your presentation. So make sure to practice your presentation ahead of time. | Presentation: 12 min . | Paper summary (motivation, proposed idea, evaluation): ~8 min | Paper critiques (strengths, weaknesses, your thoughts, future work): ~4 min | . | Class Q&amp;A: 2 min | Class vote: 1 min | . Timing is very tight – please come to class on time! . ",
    "url": "/2024/paperReadingGuidance.html#how-will-we-run-the-discussion-session",
    "relUrl": "/paperReadingGuidance.html#how-will-we-run-the-discussion-session"
  },"95": {
    "doc": "Paper Readings Guidance",
    "title": "How will your presentation be graded?",
    "content": "Your presentation will be graded based on the clarity of the articulation of the paper content and your critiques of the paper. Your presentation will be rigorously graded by four persons: the instructor and the three TAs. The detailed rubric is shown below. For each item in the rubric, every grader will give a score between 0-5. For example, when grading for “Clearly articulate motivation”, a score of 0 will be given if the presenter does not mention the motivation of the paper, a score of 5 will be given if the presenter precisely and concisely describes the motivation to the point. We will calculate the average score across the four graders for each item and then compute the weighted sum score as the final score. If a paper discussion is led by two presenters, the two presenters will get the same final score. | Aspect of the Presentation | Weight | . | Clearly articulate motivation | 1 | . | Clarity of identification of paper idea and contributions | 5 | . | Quality of articulations of evaluations, comparison, tradeoffs, etc. | 2 | . | Extensions or comments from own background | 1 | . | Critiques of the Paper (strengths and weaknesses) | 3 | . ",
    "url": "/2024/paperReadingGuidance.html#how-will-your-presentation-be-graded",
    "relUrl": "/paperReadingGuidance.html#how-will-your-presentation-be-graded"
  },"96": {
    "doc": "Paper Readings Guidance",
    "title": "Paper Readings Guidance",
    "content": " ",
    "url": "/2024/paperReadingGuidance.html",
    "relUrl": "/paperReadingGuidance.html"
  },"97": {
    "doc": "CTF of Physical Attacks",
    "title": "CTF of Physical Attacks",
    "content": "Exploiting an insecure memcmp implementation on a real microcontroller to leak a secret. Image: Adafruit . ",
    "url": "/2024/recitations/physical.html#ctf-of-physical-attacks",
    "relUrl": "/recitations/physical.html#ctf-of-physical-attacks"
  },"98": {
    "doc": "CTF of Physical Attacks",
    "title": "Table of contents",
    "content": ". | Introduction | Prizes | Before Class: Software Development Environment Setup | In Class: Hardware Setup . | What is UART? | Test the Communication with ESP32 | Wire Up the Attack Setup | . | Warm Up: Program the Attacker Board | Get to Know the Victim: the memcmp Vulnerability | Attack Time . | Suggested Attack Strategy | Provided Code | Measuring and Communicating with the Victim | Useful methods | . | . ",
    "url": "/2024/recitations/physical.html#table-of-contents",
    "relUrl": "/recitations/physical.html#table-of-contents"
  },"99": {
    "doc": "CTF of Physical Attacks",
    "title": "Introduction",
    "content": "In this recitation, we will attack an ESP32 chip. ESP32 is a Wifi and Bluetooth enabled microcontroller unit (or called MCU) built on the Xtensa architecture. We will be using two of them today. One is the victim (a password checker from which we will leak the correct password), and the other is the attacker board (which you fully control). You will be writing an ESP32 program on the attacker board to leak the secret from the victim by exploiting a timing side channel. To participate in the CTF, you will bring: . | A USB-A capable laptop setup (that is, bring your USB-C to USB-A converters!) | The Arduinio toolchain installed (see Software Development Environment Setup) | . TA will bring: . | 2x ESP32 boards, one programmed with the victim code, and one for the students to write attacker code on | 2x USB-A to USB-Micro B cables | A bundle of jumpers for students to use as needed | . All attacks are fair game . | You can do whatever you want to these boards. | Please try to leave them at least functional though for next year. | Our intended bug is probably the easiest way to exploit them, but feel free to do whatever and explore! | . ",
    "url": "/2024/recitations/physical.html#introduction",
    "relUrl": "/recitations/physical.html#introduction"
  },"100": {
    "doc": "CTF of Physical Attacks",
    "title": "Prizes",
    "content": "The first 3 teams to finish will get 1 ESP32 board per group member (the same kind we used in class today). ",
    "url": "/2024/recitations/physical.html#prizes",
    "relUrl": "/recitations/physical.html#prizes"
  },"101": {
    "doc": "CTF of Physical Attacks",
    "title": "Before Class: Software Development Environment Setup",
    "content": "You need to install the appropriate board programmer files to your local PC to program the attacker microcontroller with your attack. We are using this esp32 board. It is identified in Arduino as an esp32/Node32s. Follow the installation procedure described here. A brief summary of what you need to do: . | Download the Arduino IDE 2.0.4 | Open Preferences | Add https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json to Additional Boards Manager URLs | Close and reopen the Arduino app | Open Boards Manager from Tools &gt; Board &gt; Board Manager… | Search esp32 | Install esp32 Espressif Systems | Close and Reopen the Arduino app | Make sure Tools &gt; Board is set to ESP32 Arduino/Node32s | . Note . For windows users, you need to also install and configure PuTTY and the FTDI Drivers as seen here. ",
    "url": "/2024/recitations/physical.html#before-class-software-development-environment-setup",
    "relUrl": "/recitations/physical.html#before-class-software-development-environment-setup"
  },"102": {
    "doc": "CTF of Physical Attacks",
    "title": "In Class: Hardware Setup",
    "content": "As a physical attack recitation, you will need to interact with hardware devices physically. Read below to understand how we communicate with the ESP32 chip using UART, and follow the instructions to wire things up. What is UART? . How does the esp32 board communicate with the external world? Using the serial port. Serial, or UART, is an asynchronous protocol commonly used for communicating data between devices. Many consumer devices ship with exposed UART pads that transmit and receive data, which can cause many physical security vulnerabilities. Serial consists of 3 pins: RX, TX, and ground. Ground is the same for both devices (as a general rule of thumb, ground is always common amongst everything in a system). One device’s RX connects to the other’s TX, and vice versa. RX is used for receiving, and TX is used for transmitting. See the figure below. The most important parameter for a serial port is the baud rate, i.e., the speed at which serial communication runs. Our boards are configured to use the standard baud rate of 115200. Test the Communication with ESP32 . Let’s first test the victim’s connection with our PC to make sure everything’s working. You can attach an ESP32 to your PC using a USB cable. See detailed information here. The first step is to find the port name on your computer. | Open the Arduino app with no boards connected. | Go to Tools &gt; Port and look at the available ports. | On macOS / Linux you will see something like /dev/cu.Bluetooth-Incoming-Port (or maybe nothing). | On Windows you will probably see nothing, maybe a few COMX ports (X is a number). | . | Plug in the victim board and reload Tools &gt; Port and look for the new port. | On macOS / Linux, it will be a dev file like /dev/cu.usbserial-0001/. | On Windows, it will be something like COM4. | . | Make note of the port name so we can connect to it later. | . Now you can see what the victim boar is doing! . | If you’re on macOS / Linux, we can use the screen command to talk to the victim. | screen {name from above} 115200 will give you a terminal. | Press control + A, then K, and then Y when you want to exit. | . | If you’re on Windows, follow the PuTTY instructions. | . At first your terminal will be blank. Press the EN button on the board to reset it. You should now see some terminal output. ____ ____ _____ _________ |_ \\ / _||_ _|| _ _ | ______ | \\/ | |_/ | \\_| ______ |______| |\\ /| | | |______| _|_\\/_|_ _|_ _|_ |_____||_____||_____|_____| ___ _ _ _ ___ _ / __| ___ __ _ _ _ _ ___ ||__ _ _ _ __|_ __ ____ _ _ _ ___ | \\ ___ __(_)__ _ _ _ \\__ \\/ -_) _|| '_/ -_) | __ / _` | '_/ _` \\ V V / _` | '_/ -_) |) / -_|_-&lt; / _` | ' \\ |___/\\___\\__|\\_,_|_| \\___|_||_\\__,_|_| \\__,_|\\_/\\_/\\__,_|_| \\___|___/\\___/__/_\\__, |_||_|___/ Ravi's Super-Secure Password Checker(TM) Enter your Password &gt; . You can type in guessed passwords, and it will tell you if you are correct or not. You should see the light flash and a result printed to the console. Here’s an example if the correct password is MIT{this_is_a_secret}: . Enter your Password &gt; MIT{incorrect_guess} Try again. Enter your Password &gt; MIT{this_is_a_secret} Correct! Enter your Password &gt; . Wire Up the Attack Setup . In our attack, we will use another ESP32 board as the attack board to interact with the victim board and monitor the victim’s timing behaviors. Here’s a diagram of the setup we will build: . We are going to attach the attacker and victim together via their secondary serial ports. Both MCUs can also attach to your laptop via USB, to power them up and to see the results of the attack. We will also attach the LED pin of the victim to the attacker so it can measure when the light turns on (more information later). The precise connnections to make depend on which type of the board you get, as follows. (Two types of board we bring label the pins differently.) . If your board has a USB-C port, connect: . | Attacker.G17 (G17 is TX) to Victim.G16 (G16 is RX). | Attacker.G16 to Victim.G17. | Attacker.G2 to Victim.G2 (G2 is the LED pin). | Attacker.GND to Victim.GND. | Attach the attacker’s and victim’s USB ports to your computer. | . If your board has a USB-Micro port, connect: . | Attacker.TX2 to Victim.RX2. | Attacker.RX2 to Victim.TX2. | Attacker.D2 to Victim.D2 (D2 is the LED pin). | Attacker.GND to Victim.GND. | Attach the attacker’s and victim’s USB ports to your computer. | . ",
    "url": "/2024/recitations/physical.html#in-class-hardware-setup",
    "relUrl": "/recitations/physical.html#in-class-hardware-setup"
  },"103": {
    "doc": "CTF of Physical Attacks",
    "title": "Warm Up: Program the Attacker Board",
    "content": "Now you have some rough ideas about your attack plan, let’s learn how to write and upload programs to the attacker board. Below is an example “Hello World” program for ESP32. void setup() { // Runs once Serial.begin(115200); } void loop() { // Runs forever Serial.println(\"Hello, 6.5950!\"); } . The setup method runs once when the board is reset. The loop method runs forever after setup completes. We will post the starter code on Piazza before the class. The provided attacker code handles setting up both serial to the computer, serial to the victim, and configuring the GPIO pins. How to Upload Programs . | Attach the attacker MCU to your PC using a USB cable (as shown in the hardware setup). | Ensure the correct port and board (Node32s) are selected in Tools &gt; Port and Tools &gt; Board. Do not accidentally reflash the victim board. | Note that port are assigned by order of connection to the laptop, so the port name may change if you unplugged the boards and replugged them in later. | To be safe you can make it a rule to always flash while only the attacker board is plugged in. | . | Press the Upload button (it is a rightward pointing arrow). | Watch the output window at the bottom. | If there are any errors, let the TA know. | You may see the output is stuck doing Connecting........_____....._____....._____. forever. If you see that, try holding down the BOOT button and trying again. | . | . Take care to only program the attacker board. The victim board should NOT be reprogrammed ever, otherwise the secret will be lost! . Warmup Exercise . If it is the first time you program embedded systems, try upload the hello-world program to the attacker board and see the output. With all the setup and preparation above, we can now take a close look at our victim program and start the attack! . ",
    "url": "/2024/recitations/physical.html#warm-up-program-the-attacker-board",
    "relUrl": "/recitations/physical.html#warm-up-program-the-attacker-board"
  },"104": {
    "doc": "CTF of Physical Attacks",
    "title": "Get to Know the Victim: the memcmp Vulnerability",
    "content": "The victim board reads user-supplied passwords over serial, and tells you if the password was correct or not. Your job is to determine the correct password! . When the Super-Secure Password Checker first prototype was shown to customers, they didn’t like the fact that you cannot tell when passwords are being checked. The vendors added this light to provide feedback to the user that computation is going on internally. Specifically, a light is turned on while the password is being checked, and is turned off after the check finishes. However, this light inadvertently leaks the time the MCU takes to check the password. Internally, the microcontroller is using a vulnerable definition of memcmp to compare your input against the password. Here is the memcmp definition and invocation: . /* * memcmp_unsafe * Compares buffers buf1 and buf2. * Returns true if they are exactly equal, false otherwise. */ bool memcmp_unsafe(uint8_t *buf1, uint8_t *buf2, size_t len) { for (size_t i = 0; i &lt; len; i++) { if (buf1[i] != buf2[i]) { return false; } } return true; } /* * check_passwords * Checks the global user input buffer against the global secret. */ bool check_passwords(void) { turn_on_light(); // The users complained that there was no feedback, so we added a light bool result = memcmp_unsafe((uint8_t *)userbuf, (uint8_t *)SECRET, strlen(SECRET)); turn_off_light(); return result; } . Notice that memcmp will quit early when it detects an incorrect character in your input. This means that passwords that contain more correct characters will take slightly longer to check than those with fewer correct characters at the beginning. ",
    "url": "/2024/recitations/physical.html#get-to-know-the-victim-the-memcmp-vulnerability",
    "relUrl": "/recitations/physical.html#get-to-know-the-victim-the-memcmp-vulnerability"
  },"105": {
    "doc": "CTF of Physical Attacks",
    "title": "Attack Time",
    "content": "Suggested Attack Strategy . | Start by determining how to time an individual victim memcmp (How do you know when it starts? How do you know when it ends?) . | For simplicity, you can start by only timing guesses issued manually via USB connection to the victim. (AKA type into the victim terminal yourself and have the attacker watch for the light). | Then move onto having the attacker itself issue guesses. | . | Move onto parsing the reply from the victim. (Did it say Correct! or did it say Try again. ? Do you care…?) | Now combine the two to leak the entire secret… | . Provided Code . | You will fill in run_attacker just like in the spectre lab. (You have started the spectre lab, haven’t you? :D) | The provided code will take care of guess generation, you take care of determining which guess was best. | You will implement do_guess which issues one guess and returns the time it took. | You will then handle cleanup and state synchronization so that the victim and attacker stay in sync. | We provide sync_victim that may help with this. | Be careful not to deadlock. | . | . Measuring and Communicating with the Victim . When we hooked the boards up in the wiring part of the experiment setup, we connected the victim’s LED pin to an attacker input pin (pin D2). So, by calling digitalRead(2), we can see what the status of the victim light is. It will either be HIGH or LOW (macros defined for you to use by the Arduino toolchain). You can use the esp_timer_get_time method to read the current timestamp counter. By timing how long the light is on, you can time how long the victim spends in memcmp. Use Serial2 to talk to the victim. You can use our wrapper methods send_to_victim and read_byte_from_victim or just use the Serial2 device with the Serial API. Useful methods . Here is a laundry list of useful methods you may want to use. | uint64_t esp_timer_get_time(): Reads from the processor high resolution timer register. Similar to the rdtsc instruction on x86. | Serial.println(anything): Print this thing to the serial port. Can handle numbers, char arrays, Strings, etc. Just like on Arduino. | digitalRead(pin number): Returns the state of a given input pin (either HIGH or LOW). | delay(time in ms): Delay for some number of milliseconds. Useful for syncing up between the two devices/ allowing transfers to finish. | Helper functions in the starter code: send_to_computer, send_to_victim, read_byte_from_computer, and read_byte_from_victim. These are wrappers around the excellent Arduino libraries. | Variable Serial talks to the computer, and Serial2 talks to the victim. | More references: Arduino String Reference, Arduino Serial Reference | . Hints . | If you are sending data too fast, the victim may not see it. Adding some delay()s while testing and then removing them later can’t hurt. | You can use Serial2.availableForWrite() to check if the write buffer is busy. This might be able to help you stop sending data too fast. | Take a look at the Arduino serial API, it helps a lot with implementing a serial protocol. | Valid solutions have a 100% success rate and mine takes 1 minute 30 seconds to run. | . ",
    "url": "/2024/recitations/physical.html#attack-time",
    "relUrl": "/recitations/physical.html#attack-time"
  },"106": {
    "doc": "CTF of Physical Attacks",
    "title": "Image Credits",
    "content": "Apple, Adafruit, Espressif, Mouser, Bhphoto . ",
    "url": "/2024/recitations/physical.html#image-credits",
    "relUrl": "/recitations/physical.html#image-credits"
  },"107": {
    "doc": "CTF of Physical Attacks",
    "title": "CTF of Physical Attacks",
    "content": " ",
    "url": "/2024/recitations/physical.html",
    "relUrl": "/recitations/physical.html"
  },"108": {
    "doc": "Pretty Secure Processor",
    "title": "Frequently Asked Questions",
    "content": ". | What is Pretty Secure Processor? | How do I debug my code on Pretty Secure Processor? | What memory resources are available within Pretty Secure Processor? | What are CSRs? | How does Pretty Secure Processor communicate with the outside world? | Privilege Modes | Documentation: Where do I learn more? | . ",
    "url": "/2024/labs/psp.html#frequently-asked-questions",
    "relUrl": "/labs/psp.html#frequently-asked-questions"
  },"109": {
    "doc": "Pretty Secure Processor",
    "title": "What is Pretty Secure Processor?",
    "content": "Pretty Secure Processor is a fully-featured synthesizable RISC-V CPU and simulator framework. It has a lot of features that we will not use in this lab. This section provides an overview of the platform for providing background context for how the lab works, but is not needed to solve the lab. You can skip ahead to debugging if you are not interested in the CPU/ simulator internals. Pretty Secure Processor is an rv32i CPU that supports two privilege modes – user (PSP_PRIV_USER) and machine (PSP_PRIV_MACHINE). It supports parts of the privileged RISC-V specification (although it deviates from the spec in a number of ways), meaning the CPU has support for Control and Status Registers (CSRs), privileged instructions like mret, and exceptions, interrupts, and system calls (with the ecall instruction). Under the hood, Pretty Secure Processor is a single core that exists as part of a bigger multicore system (called “Pretty Secure System”). Every Pretty Secure Processor core (referred to as “PSP core” for short) supports a private split L1I/ L1D cache and unified L2 cache. These cores all communicate on a shared memory ring where a variety of memory-mapped peripherals exist as nodes, such as the shared L3 cache, graphics memory, and VGA style text memory. An overview of the Pretty Secure System. Your code runs on Pretty Secure Core 0. Pretty Secure System is centered around a fully featured simulation framework that allows for in-depth debugging and analysis. This testbench is implemented as a Verilator C++ testbench, allowing the simulated core to communicate over the network and interact with you, the user, like any other program. For this lab, you will use two features in this framework: the emulated serial device and GDB server for debugging. Your code runs on core 0 and should ignore any other cores present. Note that we have turned off the CPU caches to make this lab simpler, so the memory ring is unused in this lab. For the CPU fuzzing lab we have disabled CPU caching, making it easier for you to write self-modifying code if you wish (as you do not need to worry about flushing the instruction cache after modifying the code). The IPI ring is also not used in this lab. IPI stands for inter-processor interrupt and is used as a mechanism for triggering exceptions on remote cores (thus allowing cores to wake each other up and send messages back and forth). As all non-bringup cores are unused in this lab, you do not need to use IPIs. An IPI can be triggered by writing to a special memory address that maps to what we call the System Management Core, which causes an IPI packet to be sent to a remote core, triggering an interrupt exception. The memory ring is disabled as this ring is only used by the cache hierarchy. In the CPU fuzzing lab, each CPU core has a completely private single-cycle “magic” SRAM region that is used in place of the caches. ",
    "url": "/2024/labs/psp.html#what-is-pretty-secure-processor",
    "relUrl": "/labs/psp.html#what-is-pretty-secure-processor"
  },"110": {
    "doc": "Pretty Secure Processor",
    "title": "How do I debug my code on Pretty Secure Processor?",
    "content": "Pretty Secure Processor supports a custom GDB server that allows you to debug the simulated RTL itself using familiar GDB commands. Our GDB integration will allow you to set breakpoints, step through code, inspect registers, and dump memory. It does not allow you to modify any CPU state; it is a read-only view of the CPU architectural state. You can run the simulator in debug mode by calling it with --debug and then connecting a GDB to the simulator using ./gdb.sh (which internally runs GDB’s target remote command). You only need to manually specify the debug port through which simulator and GDB communicate with each other: Edit debug.sh and fill in SHD_DEBUG_PORT with the debug port that was emailed to you. In one window: . $ cd part1 &amp;&amp; make &amp;&amp; cd .. $ ./run.sh part1 --debug Waiting for debugger on port XXXX... In another window: . $ ./gdb.sh ... Remote debugging using localhost:XXXX start () at bringup.s:44 44 la x1, exception_handler_entry (gdb) . Moving back to the first window, you should see: . Debugger attached! . Now you are in a GDB session running on PSP! You can set breakpoints, inspect registers, and step through the assembly to see how your code is behaving. Why is GDB read-only on PSP? . The GDB server passively observes the writeback port of the pipeline for completed instructions, reading the CPU architectural state by inspecting the core’s register file and reading control words from the end of the writeback stage. As the Pretty Secure System utilizes multiple levels of caching across multiple cores, for simplicity the GDB server provides a read-only view of memory implemented by a per-core non coherent shadow SRAM that observes all CPU reads/ writes. Modifying architectural state would require the debugger to be capable of modifying controlwords and hazard dependencies of in-flight instructions and injecting data into the caches (and updating the replacement policy state accordingly). As the debugger was originally built to verify the RTL is functioning correctly, we did not build these features into it. ",
    "url": "/2024/labs/psp.html#how-do-i-debug-my-code-on-pretty-secure-processor",
    "relUrl": "/labs/psp.html#how-do-i-debug-my-code-on-pretty-secure-processor"
  },"111": {
    "doc": "Pretty Secure Processor",
    "title": "What memory resources are available within Pretty Secure Processor?",
    "content": "The Pretty Secure Processor memory map contains both an emulated SRAM region and a variety of memory-mapped IO (MMIO) peripherals. For the sake of this lab, you should ignore all of the MMIO devices, and only worry about the SRAM main memory region. SRAM is read/ write/ execute enabled and begins at 0x00000000 and ends at 0x04000000. All of your code and data will be placed within SRAM automatically by the build system. The system stack will also be located within SRAM. If your program requires more memory than is available, you will get a linker error when you try to compile it. While all of memory is RWX (meaning that you can write code that modifies it self), writing self-modifying code is tricky. In-flight instructions in the pipeline may not have observed all memory writes, meaning they may be executing older versions of the instructions that were just changed. As PSP does not support any memory fencing instructions, you must take care to flush the pipeline before executing any modified instructions. You can do this by running 5 nop instructions after writing to instructions you intend to run. All PSP cores in a system begin execution at reset by fetching the first instruction from 0x00000000. Note that all cores execute this first instruction together, so system software should begin by initializing all system registers (eg. the exception handler, interrupt state, etc.) and then put all cores to sleep but the bringup core. Core bringup (including putting non-boot cores to sleep) is handled for you in bringup.s, and linker.ld tells the linker where SRAM is. When your C/ ASM code is built, it is automatically linked and loaded into SRAM properly by the linker script linker.ld. There is no virtual memory support or memory protection on PSP. You will need to very carefully monitor all memory usage by your program. For example, if your stack overflows, it will just start writing data everywhere! . ",
    "url": "/2024/labs/psp.html#what-memory-resources-are-available-within-pretty-secure-processor",
    "relUrl": "/labs/psp.html#what-memory-resources-are-available-within-pretty-secure-processor"
  },"112": {
    "doc": "Pretty Secure Processor",
    "title": "What are CSRs?",
    "content": "Control and Status Registers (CSRs for short) are special privileged CPU registers that configure how the CPU behaves. They can be read/ written with the csrr, csrw, and csrrw instructions while operating in PSP_PRIV_MACHINE mode. | Instruction | Example | Usage | . | csrr- CSR Read | csrr x1, SOME_CSR | Read SOME_CSR into register x1. | . | csrw- CSR Write | csrw SOME_CSR, x1 | Write x1 into SOME_CSR. | . | csrrw- CSR Read and Write | csrrw x1, SOME_CSR, x2 | Read SOME_CSR into register x1 and simultaneously write x2 into SOME_CSR. | . Pretty Secure Processor features some of the CSRs defined by the RISC-V privileged specification, simplified for a classroom setting. Here is a brief listing of the CSRs you will find relevant for this lab. | Address | Name | Meaning | . | 0x037 | utimer | Current Time (cycles) | . | 0x200 | SOFTSERIAL_FLAGS_CSR | Returns whether data is available for reading on the serial port. | . | 0x201 | SOFTSERIAL_IO_CSR_IN | Softserial data entering the CPU. | . | 0x202 | SOFTSERIAL_IO_CSR_OUT | Softserial data leaving the CPU. | . | 0x305 | mtvec | Machine Trap Vector Table Pointer | . | 0x340 | mscratch | Scratch Register | . | 0x341 | mepc | Exception Saved PC | . | 0x342 | mcause | Exception Cause | . | 0x399 | mpp | Previous Privilege Level | . | 0xf14 | mhartid | Hardware Thread (core) ID | . CSRs with a u in front of them are accessible in userspace (and machine mode), and those with an m in front of them are accessible from machine mode (high privilege mode). More information on the privilege modes can be found below. Here is a description of each of these CSRs: . utimer . This is a cycle counter, analogous to tsc on x86_64. Read it to get a high resolution cycle count! This one is accessible from all privilege levels, as it is a userspace CSR. Softserial . These CSRs correspond to the softserial device, which is described in the IO section. mtvec . The Machine Trap Vector Table Pointer points to where the CPU jumps to during an exception condition. When an exception occurs, pc is loaded with the contents of mtvec (essentially jumping the CPU to mtvec). It is set to the address of the exception handler entrypoint in bringup.s. mscratch . Do whatever you want with this! It’s just a free register. mepc . When the CPU enters an exception, it records the pc of the faulting instruction in mepc. It essentially performs the same role as the return address register (ra) (AKA x1) does during a regular function return. When mret is executed to leave an exception context, the CPU loads pc with mepc to return to the faulting instruction. An exception handler can increment mepc before executing mret to skip over the faulting instruction. mcause . When the CPU enters an exception, the hardware automatically populates this CSR with the reason for the exception. mpp . When the CPU enters an exception, the CPU records its previous privilege level here. On mret to exit the exception, the CPU restores the privilege level to whatever mpp contains. mhartid . This is 0 for core 0, 1 for core 1, etc. mie / mpie . mie specifies whether interrupts are enabled or not, and mpie is the saved value of mie to be restored at mret. In this lab, these CSRs can be ignored (as no interrupt-generating devices are attached to the simulated SoC). You will see these set in bringup.s, they can be left as is (you don’t need to change them). ",
    "url": "/2024/labs/psp.html#what-are-csrs",
    "relUrl": "/labs/psp.html#what-are-csrs"
  },"113": {
    "doc": "Pretty Secure Processor",
    "title": "How does Pretty Secure Processor communicate with the outside world?",
    "content": "In this lab, the only form of IO will be through an emulated serial port we call softserial. You have seen serial ports in the Physical Attacks lecture and recitation, and you can think of this serial port in the same way. This serial port is implemented as a set of CSRs that the CPU can read/ write to perform IO operations, defined as followed: . | CSR | Address | Function | . | SOFTSERIAL_FLAGS_CSR | 0x200 | Returns whether data is available for reading. | . | SOFTSERIAL_IO_CSR_IN | 0x201 | Data entering the CPU. | . | SOFTSERIAL_IO_CSR_OUT | 0x202 | Data leaving the CPU. | . When data is ready for the CPU to read, SOFTSERIAL_FLAGS_CSR is set to SOFTSERIAL_FLAGS_WAITING. The CPU can poll this register to learn when data is ready to be read. If there is data available, when SOFTSERIAL_IO_CSR_IN is read, the ASCII code for that character will be returned. The CPU then sets SOFTSERIAL_FLAGS_CSR to SOFTSERIAL_FLAGS_CLEAR to indicate it has read and received the available byte. The CPU can output data at any time by writing to SOFTSERIAL_IO_CSR_OUT, which will output text to the terminal. We have provided a full serial driver for you in the starter code distribution in serial.c and serial_csr.s, allowing you to use the serial port without needing to implement these low-level details. However, we encourage you to read through the serial driver and understand it, as understanding it will help with understanding how to read CSRs for later parts of the lab. In utils.c we have implemented a version of printf that you can use to print debug information. printf utilizes the softserial driver to display information in the terminal. Note that our starter printf only supports %x, %c, and %s– NOT %d or any advanced formatter codes! (Feel free to add support for any other format strings if you want though!) . ",
    "url": "/2024/labs/psp.html#how-does-pretty-secure-processor-communicate-with-the-outside-world",
    "relUrl": "/labs/psp.html#how-does-pretty-secure-processor-communicate-with-the-outside-world"
  },"114": {
    "doc": "Pretty Secure Processor",
    "title": "Privilege Modes",
    "content": "The RISC-V Privileged ISA specification defines four privilege modes that a CPU can support – User, Supervisor, [Reserved], and Machine. Of these four, Pretty Secure Processor implements two – User and Machine, which we call PSP_PRIV_USER and PSP_PRIV_MACHINE. You can think of them like ring 3 and ring 0 (userspace and kernelspace) on x86_64 machines, like we saw in the spectre lab. | Mode | Code | Restrictions | . | PSP_PRIV_USER | 0x0 | Cannot read machine CSRs. | . | PSP_PRIV_MACHINE | 0x3 | None. | . During bringup, the CPU begins executing in PSP_PRIV_MACHINE and has access to all CSRs. When the CPU transitions into PSP_PRIV_USER, certain CSRs will be blocked. In this lab, one of your tasks is to find a backdoor in the CPU allowing you to elevate your privilege level from user mode to machine mode to dump privileged CSRs that cannot be read from user mode. Note that there is no way to read the current achitectural privilege level on Pretty Secure Processor as it is not stored in a CSR (it is saved in an architecturally transparent register). The privilege level can be inferred by attempting to read a privileged CSR. Privilege Transitions – Exception Entry . Privilege transitions happen in one of two ways – exception entry (an interrupt, system call, or exception occurred), or exception exit (the CPU ran mret). First, if the CPU encounters an exception, it will immediately switch into PSP_PRIV_MACHINE mode to handle it. The CPU will also save a few CSRs by writing them into their “previous” counterparts so they can be restored later. For example, the privilege level is recorded into mpp (Machine previous privilege) as we always move to high privilege mode during exceptions, and need to know which mode to return to when we execute mret (see Exception Exit). Here is the actual RTL that is executed on an exception condition: . csr[mepc] &lt;= exception_saved_pc; // Save address of the instruction that caused the exception csr[mpp] &lt;= psp_priv_level; // Save current CPU privilege level csr[mcause] &lt;= exception_cause; // Load reason for the exception psp_priv_level &lt;= PSP_PRIV_MACHINE; // Transition to machine (privileged) mode . Privilege Transitions – Exception Exit . After handling the exception, system software can execute the special mret instruction to return from the exception context. This is the only way for the CPU to move from PSP_PRIV_MACHINE to PSP_PRIV_USER. This undoes what happens during exception entry. Here is a pseudocode for the RTL that is executed on mret: . psp_priv_level &lt;= csr[mpp]; // Set the privilege level to what is in mpp pc &lt;= csr[mepc]; // Jump to wherever mepc points . You do not need to be in an exception context to use mret! . That is, you can run mret at any time if you are in machine mode – you don’t have to have just begun an exception to use it. For example, in bringup.s, we execute mret early on to jump into the main C code. We do this because using mret (again, even though we aren’t in an exception!) is the only way to change the CPU privilege level to PSP_PRIV_USER. Essentially, it is a convenient way to set the privilege level and execute ret all in one. ",
    "url": "/2024/labs/psp.html#privilege-modes",
    "relUrl": "/labs/psp.html#privilege-modes"
  },"115": {
    "doc": "Pretty Secure Processor",
    "title": "Documentation: Where do I learn more?",
    "content": "Throughout this lab, it may be helpful to refer to the RISC-V specification to refresh yourself on the RV32I instruction encoding. You do not need to read the specification cover to cover! We will link to specific chapters and pages to refer to when you need to. You might find exploring them useful regardless. RISC-V ISA Volume I: Unprivileged Specification (regular instructions) . This walks through the RISC-V instructions. The rv32i ISA is described in Chapter 2 (page 13). All instruction encodings are listed on page 130. RISC-V ISA Volume II: Privileged Specification (system instructions and CSRs) . This walks through the privileged ISA. It is a good resource to refer to if you are confused on how certain CSRs work. RISC-V assembly format of instructions directly implemented by the hardware and pseudo instructions . When you try to write assembly code of RISC-V instructions, These documents summarize their formats. RISC-V Calling Convention . This document walks through how to call C methods from assembly. Table 18.2 will be useful! . RISC-V Assembly Programmer’s Manual . This provides an overview of what the RISC-V assembler is doing “under the hood” – demystifying various pseudoinstructions. Pretty Secure Processor Complete Documentation . Chapters 3 and 4 describe the Pretty Secure Processor hardware and how to write software for it. Deviations from the RISC-V Specification . Pretty Secure Processor makes a number of simplifications to make it easier to write software for. It does not implement the full privileged specification, for example there is no mstatus register. It also includes some non standard CSRs such as utimer and the softserial device. In general, concepts from the RISC-V Privileged ISA will be applicable on PSP, but refer to the CSRs and behavior listed here as the primary resource on how to use PSP. ",
    "url": "/2024/labs/psp.html#documentation-where-do-i-learn-more",
    "relUrl": "/labs/psp.html#documentation-where-do-i-learn-more"
  },"116": {
    "doc": "Pretty Secure Processor",
    "title": "Pretty Secure Processor",
    "content": ". Pretty Secure Processor is the CPU used in the CPU fuzzing lab this semester. Specifically, the version of the CPU is a fork of the open-source CPU created by Joseph Ravichandran with intentional CPU bugs and backdoors added for students to discover and exploit. Pretty Secure Processor supports advanced debugging capabilities allowing you to debug your code on the CPU. This page provides an overview of the Pretty Secure System – Pretty Secure Processor plus the simulation and runtime features. ",
    "url": "/2024/labs/psp.html",
    "relUrl": "/labs/psp.html"
  },"117": {
    "doc": "Recitations",
    "title": "Recitations",
    "content": "Here are some resources for our various recitation activities throughout the semester. ",
    "url": "/2024/recitations.html#recitations",
    "relUrl": "/recitations.html#recitations"
  },"118": {
    "doc": "Recitations",
    "title": "CTF of C Programming",
    "content": "Capture the flag competition to solve some beginner/advanced C and C++ language problems. ",
    "url": "/2024/recitations.html#ctf-of-c-programming",
    "relUrl": "/recitations.html#ctf-of-c-programming"
  },"119": {
    "doc": "Recitations",
    "title": "Guidance on Paper Discussion Sessions + Cache Review",
    "content": "The research paper (and slides) behind the Website Fingerprinting Lab, guidance on paper presentation in discussion sessions, and walking through the cache organization of our lab machine (Figure 1&amp;2 in this paper). ",
    "url": "/2024/recitations.html#guidance-on-paper-discussion-sessions--cache-review",
    "relUrl": "/recitations.html#guidance-on-paper-discussion-sessions--cache-review"
  },"120": {
    "doc": "Recitations",
    "title": "CTF of Physical Attacks",
    "content": "Capture the flag competition to exploit an insecure memcmp implementation on a real microcontroller to leak a secret. ",
    "url": "/2024/recitations.html#ctf-of-physical-attacks",
    "relUrl": "/recitations.html#ctf-of-physical-attacks"
  },"121": {
    "doc": "Recitations",
    "title": "Binary Exploitation and RISC-V Warmup",
    "content": "Review the RISC-V architecture and introduce the privileged ISA specification. Hands on RISC-V assembly and memory corruption (buffer overflow) exercises. ",
    "url": "/2024/recitations.html#binary-exploitation-and-risc-v-warmup",
    "relUrl": "/recitations.html#binary-exploitation-and-risc-v-warmup"
  },"122": {
    "doc": "Recitations",
    "title": "Formal Verification Toolchain",
    "content": "Learn to use a hardware verification framework. Hands-on exercise to find bugs in a toy CPU. ",
    "url": "/2024/recitations.html#formal-verification-toolchain",
    "relUrl": "/recitations.html#formal-verification-toolchain"
  },"123": {
    "doc": "Recitations",
    "title": "Recitations",
    "content": " ",
    "url": "/2024/recitations.html",
    "relUrl": "/recitations.html"
  },"124": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "Binary Exploitation and RISC-V Warmup",
    "content": " ",
    "url": "/2024/recitations/riscv.html",
    "relUrl": "/recitations/riscv.html"
  },"125": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "Table of Contents",
    "content": ". | Instruction Reference Table | Calling Convention | GDB Debugging | Binary Exploitation and CTF Tools | Privileged Extensions | Hands-on Puzzles | . In case your RISC-V assembly is a bit rusty, here’s a quick guide to the rv32i ISA, standing for RISC-V 32-bit Base Integer Instruction Set. We will also go through a few recitation exercises to get you familiar with binary exploitation that will come in handy in the fuzzing lab. In RISC-V, there are 32 general-purpose registers (x0 to x31) and a program counter (pc). All the registers have the bit-length of 32. x0 is hardcoded to always be zero when read, and the remaining registers (x1-x31) are free for programmer use. The program counter pc points to the current instruction being executed. Each instruction is 32-bits long (4 bytes) and is always byte aligned. For things not covered in this recitation, you should refer to . | The list official RISCV document | . ",
    "url": "/2024/recitations/riscv.html#table-of-contents",
    "relUrl": "/recitations/riscv.html#table-of-contents"
  },"126": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "Instruction Reference Table",
    "content": "In the assembly code, you could write instructions that are directly implemented by the hardware. You could also write pseudo instructions, which are just convenient syntactic sugar and the assembler could translate them into instructions directly implemented by the hardware. Here is a reference of these instructions and their assembly code format: . | RISC-V assembly format of instructions directly implemented by the hardware and pseudo instructions | . ",
    "url": "/2024/recitations/riscv.html#instruction-reference-table",
    "relUrl": "/recitations/riscv.html#instruction-reference-table"
  },"127": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "Calling Convention",
    "content": "The RISC-V ISA defines a calling convention (application binary interface, or ABI), assigning meanings to the general purpose registers. The following is a breakdown of all of the registers and their meanings. Note how each register (x1-x31) has a corresponding ABI name. In assembly, you can refer to the register using either. For example, x2 means exactly the same register as sp (one is simply more readable than the other). The reference file is: . | RISC-V Calling Convention | . Table 18.2 from the RISC-V Calling Convention: RISC-V calling convention register usage. Caller-saved vs. Callee-saved Registers . Since functions tend to modify registers as part of their execution, the ABI splits the registers into two kinds: callee-save or caller-save. Registers that are defined to be callee-saved need to be saved and restored by the callee (the function being called). That is, functions need to save and restore these registers. On the other hand, registers defined to be caller-saved are allowed to be changed freely by a function being called (you don’t need to save and restore these). However, a function that calls other functions should not assume these registers hold their value across method calls. In RISC-V, all arguments are passed via registers (and the stack if there aren’t enough registers). Refer to the calling convention document for the specifics, but at a high level, arguments are passed via a0, a1, a2, and so on. When a function is complete, the return value is passed via a0 (and a1 if needed). Function Call Linkage . The RISC-V instruction to call a method is jal (Jump and Link). jal allows the program to jump to a function (setting pc to the function to execute), and records the next instruction after jal (pc+4) into the return address register ra. When a function is ready to exit, it executes the ret instruction. This is not a “real” instruction, rather, ret is a shorthand way of writing jalr x0, ra to jump to the return address (effectively undoing the original jalr that brought us into the function!) . Stack Management . The function must save and restore any registers it uses to the stack. In the beginning, a function will make some space on the stack (by subtracting from sp, the stack pointer), and save any necessary registers in the new space. At the end, the function will teardown its stack frame by restoring any saved registers, and resetting sp to its original value before executing ret. A function can also use the stack for storing local variables. Level 1 . Let’s start with solving our Hands-on Puzzle level 1 to get familiar with commonly used RISCV instructions and the calling convention. ",
    "url": "/2024/recitations/riscv.html#calling-convention",
    "relUrl": "/recitations/riscv.html#calling-convention"
  },"128": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "GDB Debugging",
    "content": "If you are experiencing crashes and don’t know why when working with C or assembly code, you can use GDB to help figure out where your exploit is going wrong. We will go through an example of running GDB on the starter code of level 1.3 (after level 1.1 and 1.2 are done) on unicorn. Set DEBUG_PORT in config.sh using the debug port we emailed you for lab6.A, it should be within [5100, 5300]. Run the level 1.3 code with --debug enabled: . $ ./run.sh level1 --debug Waiting for debugger on port XXXX... Open another terminal and run gdb with: . $ ./gdb.sh level1 ... Reading symbols from build/level1... Remote debugging using localhost:XXXX 0x00001000 in ?? () (gdb) . It will pause the execution right before the program starts. Now, for debugging, you probably want to pause the execution at a specific point in the program, which is called “breakpoint”. To do so, you first create a breakpoint, at the label of problem_3 for example: . (gdb) b problem_3 Breakpoint 1 at 0x80000540: file src/level1_asm.s, line 115. Then “coninute” run the program and it will automatically pause right before the breakpoint you just set: . (gdb) c Continuing. Breakpoint 1, problem_3 () at src/level1_asm.s:116 116 mv a0, zero # &lt;- Replace this with your code =&gt; 0x80000548 &lt;problem_3+0&gt;: 00000513. li a0,0 . The output means the next instruction to execute is at line 116 of level1_asm.s, which is assembly code mv a0, zero. In the binary, this line of code is compiled to a li a0, 0 instruction. We can then execute instruction one-by-one with “next” command: . (gdb) n 119 call problem3_target =&gt; 0x8000054c &lt;problem_3+4&gt;: 1d4000ef jal 0x80000720 &lt;problem3_target&gt; . When the next instruction is a function call, “next” command will directly execute all instructions in the function until the function returns (You could try that!). However, we sometime might want to look into the body of function, which can be achieved with “step”: . (gdb) s problem3_target (str=0x0) at src/level1.c:86 86 puts(\"Checking Problem 3\\r\\n\"); =&gt; 0x80000734 &lt;problem3_target+20&gt;: 800017b7 lui a5,0x80001 0x80000738 &lt;problem3_target+24&gt;: 0dc78513 add a0,a5,220 # 0x800010dc 0x8000073c &lt;problem3_target+28&gt;: 965ff0ef jal 0x800000a0 &lt;puts&gt; . Note that, sometime, it stops only at the next line of C code in the function (instead of the next instruction in the binary), which is already the pc at &lt;problem3_target+20&gt;. To see what are the instruction between &lt;problem3_target+0&gt; and &lt;problem3_target+20&gt; that have been executed, use command x/8i problem3_target, where x means “examine memory”, 8 means “printing following 8 entries”, i means “format it as instructions”, and problem3_target is the address to print: . (gdb) x/8i problem3_target 0x80000720 &lt;problem3_target&gt;: add sp,sp,-32 0x80000724 &lt;problem3_target+4&gt;: sw ra,28(sp) 0x80000728 &lt;problem3_target+8&gt;: sw s0,24(sp) 0x8000072c &lt;problem3_target+12&gt;: add s0,sp,32 0x80000730 &lt;problem3_target+16&gt;: sw a0,-20(s0) =&gt; 0x80000734 &lt;problem3_target+20&gt;: lui a5,0x80001 0x80000738 &lt;problem3_target+24&gt;: add a0,a5,220 0x8000073c &lt;problem3_target+28&gt;: jal 0x800000a0 &lt;puts&gt; . Now, to debug your solution of level 1.3, you might be curious what is the state (e.g., regfile, stack) of the processor and check whether you have filled the values correctly. You can do check regfile with “info registers”: . (gdb) info registers ra 0x80000550 0x80000550 &lt;problem_3+8&gt; sp 0x80101fd0 0x80101fd0 ... a0 0x0 0 a1 0x0 0 ... pc 0x80000734 0x80000734 &lt;problem3_target+20&gt; . You can see the stack pointer sp is 0x80101fd0. Then, you can print the value stored in this location with x/16w 0x80101fd0, where w means “format as a word”: . (gdb) x/16w 0x80101fd0 0x80101fd0: 0x00000000 0xf1e57fcd 0xdeadc0de 0x00000000 0x80101fe0: 0x00000000 0x00000000 0x80102000 0x80000550 0x80101ff0: 0x80102000 0x80000010 0x00000000 0x00000000 0x80102000: 0x00000000 0x00000000 0x00000000 0x00000000 . Alternatively, x/8 $sp could print the same thing, saving you a Ctrl-c/Ctrl-v: . (gdb) x/16w $sp 0x80101fd0: 0x00000000 0xf1e57fcd 0xdeadc0de 0x00000000 0x80101fe0: 0x00000000 0x00000000 0x80102000 0x80000550 0x80101ff0: 0x80102000 0x80000010 0x00000000 0x00000000 0x80102000: 0x00000000 0x00000000 0x00000000 0x00000000 . Now, you could start to modify the code for level 1.3 and check how the stack value is changed by your code. You can quit gdb with q. Below summarize the commands we have used in gdb. | Commands | Explanation | . | b label | Set a breakpoint at the label. | . | c | Continue until the next instruction is a breakpoint. | . | n | Step over a single instruction (skip function calls). | . | s | Step over a single instruction. | . | info registers | Examine register values. | . | x/8i addr | Examine memory starting from addr for 8 instruction entries. | . | x/16w addr | Examine memory starting from addr for 16 data word entries. | . | q | Quit gdb. | . You can learn more about GDB here or by googling some functions you expect from GDB. ",
    "url": "/2024/recitations/riscv.html#gdb-debugging",
    "relUrl": "/recitations/riscv.html#gdb-debugging"
  },"129": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "Binary Exploitation and CTF Tools",
    "content": "Level 2-5 . Level 2-5 guides you to build off from a buffer overflow to a return-to-win attack and then a ROP attack. These exercises will be useful in the fuzzing lab. When you get confused about what the assembly code is doing, refer to the GDB debugging section above. GDB is also needed for getting the stack pointer in level 5. ",
    "url": "/2024/recitations/riscv.html#binary-exploitation-and-ctf-tools",
    "relUrl": "/recitations/riscv.html#binary-exploitation-and-ctf-tools"
  },"130": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "Privileged Extensions",
    "content": "We now provide additional materials for getting warm up for the fuzzing lab. Take a look at the RISC-V ISA Volume II. This manual provides an overview of the privilege modes available to RISC-V systems and how to transition between them. As you will recall from earlier labs, the OS kernel runs in a higher privilege level than user programs – this volume describes that mechanism on RISC-V. In the fuzzing lab, you will be writing programs that run with higher privilege levels, and will write code to handle privilege transitions (AKA exceptions). Privilege Levels . There are 4 privilege levels in the RISC-V ISA, of which two of them we will use in our labs. Table 1.1 from the RISC-V ISA Volume II: RISC-V privilege levels. For the sake of this class, we will use the convention that level 0 (U mode) is userspace, and level 3 (M mode) is kernelspace. In the fuzzing lab, these privilege modes will be referred to as PSP_PRIV_USER and PSP_PRIV_MACHINE, respectively. Levels 1 and 2 are not used in this class. Control and Status Registers (CSRs) . Control and Status Registers (CSRs for short) are special privileged CPU registers that configure how the CPU behaves. They can be read/ written with the csrr, csrw, and csrrw instructions while operating in M mode. | Instruction | Example | Usage | . | csrr- CSR Read | csrr x1, SOME_CSR | Read SOME_CSR into register x1. | . | csrw- CSR Write | csrw SOME_CSR, x1 | Write x1 into SOME_CSR. | . | csrrw- CSR Read and Write | csrrw x1, SOME_CSR, x2 | Read SOME_CSR into register x1 and simultaneously write x2 into SOME_CSR. | . One of the most important CSRs is mepc (CSR address 0x341). When an exception occurs, the current PC of the faulting instruction will be written into mepc. mepc can be read by system software using the csrr instruction. mepc will contain whatever the PC was at the exception, regardless of what mode the CPU was previously in. Exception Conditions . Whenever a RISC-V CPU encounters an exception condition (perhaps dividing by zero, a usermode program attempts to perform an illegal access, or an undefined instruction is executed), the CPU will execute a privilege transition into machine mode. Recall in lecture when Mengjia introduced the SYSRET bug on x86_64 machines: . This is how x86_64 machines perform privilege transitions (specifically, when a system call is requested). On RISC-V, there exists a very similar mechanism for privilege transitions! . The exception handler is the code in the kernel that is executed on an exception condition. In the fuzzing lab, you will write one! . ",
    "url": "/2024/recitations/riscv.html#privileged-extensions",
    "relUrl": "/recitations/riscv.html#privileged-extensions"
  },"131": {
    "doc": "Binary Exploitation and RISC-V Warmup",
    "title": "Hands-on Puzzles",
    "content": "Check out the hands-on puzzle repository for 5 introductory RISC-V programming activities. These exercises will get you familiar with writing RISC-V assembly and the calling convention, as these topics will be useful in the fuzzing lab. ",
    "url": "/2024/recitations/riscv.html#hands-on-puzzles",
    "relUrl": "/recitations/riscv.html#hands-on-puzzles"
  },"132": {
    "doc": "Rowhammer",
    "title": "Rowhammer Lab",
    "content": "Due Date: Apr 11; Last Updated Date: Mar 26 . ",
    "url": "/2024/labs/rowhammer.html#rowhammer-lab",
    "relUrl": "/labs/rowhammer.html#rowhammer-lab"
  },"133": {
    "doc": "Rowhammer",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 0: Lab Infrastructure . | Debug HTCondor | . | Part 1: Bridging the Virtual and Physical Address Spaces (10%) . | Translating Virtual to Physical Addresses | Translating in the Other Direction | . | Part 2: Observing Bitflips in the Wild (40%) | Part 3: DRAM Geometry (20%) . | Bonus: Implementing the Bank-conflict Side Channel (5%) | . | Part 4: Mitigation using Error Correcting Codes (30%) . | Understanding ECC: Types and Design Choices | Implementing ECC: Hamming(22,16) | . | Behind the Scene: How this lab infrastructure was developed? | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . You will complete this lab primarily in C and C++. Refer to the recitation materials if needed. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2024/labs/rowhammer.html#table-of-contents",
    "relUrl": "/labs/rowhammer.html#table-of-contents"
  },"134": {
    "doc": "Rowhammer",
    "title": "Introduction",
    "content": "In this lab, you will complete two tasks: . | Mount a Rowhammer attack on a real machine, taking the theory we learned in class to practice. | Study what we can do to protect against Rowhammer. | . To begin, imagine DRAM as a matrix of cells. The core of Rowhammer is to access the cells that are adjacent to each other in a specific pattern. In lecture, we studied how to design a reasonable access pattern to perform double-sided Rowhammer, and you may think the attack sounds easy to pull off. Unfortunately, it is not. The most tricky part of the attack is dealing with address translations, and figuring out how exactly we can access the bit cells needed. Note that all the addresses that a programmer (e.g., you) can manipulate are virtual addresses, which need to be translated to physical addresses, and then to DRAM cell coordinates. Virtual Address → Physical Address → DRAM Cell Coordinate . Since each step isn’t trivial, we’ve designed the lab to guide you to build your attack step by step, handling one of the translations at a time. At the end of this lab, you will not only have a working Rowhammer attack, but also gain a deeper understanding of the complex addressing mechanism that is widely used in modern systems. ",
    "url": "/2024/labs/rowhammer.html#introduction",
    "relUrl": "/labs/rowhammer.html#introduction"
  },"135": {
    "doc": "Rowhammer",
    "title": "Part 0: Lab Infrastructure",
    "content": "Due to the intrinsic physical requirements of the Rowhammer vulnerability, your experiments will be run on our special lab machines. These machines have been verified to reliably be vulnerable to Rowhammer, and your lab answers will be specific to these machines’ configuration. The experiments also require to exclusively use the whole DRAM. To achieve this, we will use HTCondor to time-shared the lab machines, running one experiment at a time. You will ssh to arch-sec-1.csail.mit.edu (with a jump server as previous labs), develop and build your code on it, and use HTCondor on it to remotely launch your code on one of the vulnerable machines (csg-exp{6,7,9,10} and arch-sec-{5-8}). Note that you will not be directly accessing these vulnerable machines, since this may interfere with another student’s experiments. Configuration . Your assigned machine information has been emailed to you. Before moving past this point, edit launch.condor and update the Requirements line to match the specific machine assigned to you. Make sure you exclude the .csail.mit.edu suffix when filling it. Use HTCondor . You will use HTCondor to launch your attack code, using the following commands to interact with HTCondor: . | ./launch.sh [BINARY FILE]: run the specified binary file bin/[BINARY FILE] on your assigned remote machine. The output will be placed in log/[BINARY FILE].out, and any errors generated by your code will be placed in log/[BINARY FILE].error. | cat log/[BINARY FILE].out: Check the output of your job by opening the corresponding output file. | cat log/[BINARY FILE].error: Print all the errors experienced by your job by opening the corresponding error file. | . Here is an example of using HTCondor to run a program that prints Hello World. $ make $ ./launch.sh part0 Submitting job(s). 1 job(s) submitted to cluster XX. All jobs done. $ cat log/part0.out Hello World! . Before continuing, run the Condor commands as above, and ensure that you can interact with your assigned machine correctly. If things do not work as expected, read the next subsection for debugging tips or reach out to TAs. Debug HTCondor . By defualt, ./launch.sh will wait for the binary finishing the execution. However, it might hang forever either because the binary itself hangs forever or becuase condor fails to schedule the binary to remote machines. In either case, you can type Ctrl+c to exit from ./launch.sh and using following commands to figure out what’s going wrong: . | condor_q: Check the status of your job, including its ID and its Status. You can see more debugging information with the condor_q -better-analyze [ID] or cat log/[BINARY FILE].log. | condor_rm [ID]: Kill your job specified by the ID. Make sure you killed (or finished) all your jobs before launching new ones. Note that we config Condor to kill your jobs automatically after they have executed for 10 minutes, to allow other students to use the machine. | . Here is an example that Condor cannot schedule a job becuase you forget to fill your machine name into launch.sh. $ make $ ./launch.sh part0 Submitting job(s). 1 job(s) submitted to cluster 6522. ^C $ condor_q -- Schedd: arch-sec-1.csail.mit.edu : &lt;128.30.65.18:9618?... @ 02/19/24 18:42:02 OWNER BATCH_NAME SUBMITTED DONE RUN IDLE TOTAL JOB_IDS shd24-xxx ID: 6522 2/19 18:41 _ _ 1 1 6522.0 $ condor_q -better-analyze 6522 ... No successful match recorded... $ condor_rm 6522 . ",
    "url": "/2024/labs/rowhammer.html#part-0-lab-infrastructure",
    "relUrl": "/labs/rowhammer.html#part-0-lab-infrastructure"
  },"136": {
    "doc": "Rowhammer",
    "title": "Part 1: Bridging the Virtual and Physical Address Spaces (10%)",
    "content": "We start with bridging the gap between the virtual and physical address spaces. Specifically, you will implement two functions: Firstly, a function that translates a virtual address to its corresponding physical address. Secondly, a function translating in the opposite direction, i.e., given a physical address, determining its corresponding virtual address. Code Skeleton . The source code for this lab can be found in src/, and is separated into folders corresponding to different parts of the lab. | src/params.hh: Defines several key parameters, including the size of a hugepage (e.g. 2MB), the size of a DRAM row, etc. | src/verif.hh: Contains declarations for functions which will help you check your solutions, and will be used for grading. The implementation of these functions are in bin/verif.o. | src/shared.hh and src/shared.cc: Contain functions which are shared across different parts of the lab. You will complete these functions in Part 1. | . You can compile the code by running the command make at the root of the repository, which will create five executable files (part[0-4]) in the bin/ folder. Note that you will need to re-run make each time you change your code to re-compile it. For example, observe the initial behavior of the initial codebase: . $ make $ ./launch.sh part1 Submitting job(s). 1 job(s) submitted to cluster XX. All jobs done. $ cat log/part1.out virt_to_phys test failed! . Before continuing, run make and make sure your codebase compiles successfully and returns the same output as above. Linux’s pagemap interface . The machines in this lab used paged virtual memory (if you need a refresher on this topic, check out 6.191’s (6.004’s) lectures on Virtual Memory 1 and Virtual Memory 2). Linux provides the pagemap interface that allows userspace programs to examine page tables and related information. For a running process, its pagemap can be accessed by reading the file /proc/self/pagemap. This pagemap file is binary-encoded, containing a sequence of 64-bit values. Each 64-bit value corresponds to a virtual page (assuming a page size of 4KB), where the N-th 64-bit value corresponds to the N-th virtual page. The figure below indicates the semantics for each page entry. Example Page Map Entry . Bit 63 indicates whether the page presents in memory or not. If the page is present in memory, Bits 0-54 of the entry is the physical page number (PPN). The remaining (metadata) bits have their own meaning, which are not relevant for this lab. If you’re curious, more information can be found in the corresponding Linux kernel documentation page. Note . As a countermeasure of Rowhammer, /proc/self/pagemap is not allowed to be accessed by non-sudo user since Linux 4.0 (released in 2015). However, we definitely do not want to give you sudo permission on our lab machine! Thankfully (for us), our TA, William Liu, developed a workaround through a kernel module, detailed in the section at the end of this handout. Translating Virtual to Physical Addresses . We can leverage the pagemap interface to perform the virtual address to physical address translation. In the virt_to_phys function in shared.cc, you will translate a given virtual address to its corresponding physical address. You will implement this function assuming the page size is 4KB. At a high-level, your virt_to_phys function will do the following: . | Given a virtual address, derive the address’ virtual page number (VPN). | (provided) Read pagemap to find the corresponding page table entry. | (provided) Extract the physical page number (PPN) from the page table entry. | Compute the physical address from the physical page number (PPN). | . 1-1 Exercise . Complete the virt_to_phys function in src/shared.cc assuming 4KB page size. Test your code by running ./launch.sh part1. You should see virt_to_phys test passed! . When you bit-shift the 55-bit PPN, you may notice that the upper bits cannot fit in a 64-bit address. You can ignore this effect, since the upper three bits of the PPN field are unused on our system. Translating in the Other Direction . You will find it handy if you can perform address translation in the opposite direction, from physical to virtual addresses. The idea is to construct a reverse page table, i.e., a map that records the mapping relationship from physical page numbers (PPN) to virtual page numbers (VPN). In shared.cc, PPN_VPN_map serves as the reverse page table. It is a dictionary implemented using C++’s std::map syntax, with physical page numbers as keys and virtual page numbers as values. For more information related to C++ and examples of how to use the std::map object, refer to the recitation materials. Your task is to complete the function setup_PPN_VPN_map (in shared.cc) to populate the PPN_VPN_map data structure. You can assume the page size is 2MB as opposed to 4KB. The populated reverse page table should cover a 2GB region following the pointer mem_map. 1-2 Discussion Question . In a 64-bit system using 4KB pages, which bits are used to represent the page offset, and which are used to represent the page number? . How about for a 64-bit system using 2MB pages? Which bits are used for page number and which are for page offset? . In a 2GB buffer, how many 2MB hugepages are there? . Demystifying 2MB vs. 4KB Page Sizes . You are asked to use 4KB page to probe the pagemap interface, but 2MB page to build the reverse page table. You may wonder – why do we use inconsistent page sizes and will it not introduce bugs? . In our setup, we ask the OS to give us the 2GB region using hugepages (2MB page size) inside the allocate_pages function. We use hugepages to simplify the address translation step (using 2MB pages allows us to more easily determine the DRAM bank of an address later on in this lab). The pagemap interface is designed, however, to assume 4KB pages, with each 64-bit entry corresponding to one 4KB page. As we know that for address translation, we take the VPN and translate it to PPN, but keep the page offset unchanged. So a virtual address and its corresponding physical address always have the same page offset. When considering 2MB and 4KB pages, we can consider a 2MB page to consist of 512 4KB pages. For these 4KB pages, the lower 9 bits of their VPNs are counted as page offset for a 2MB page. Therefore, when being translated between virtual and physical address, these 9 bits do not need to be changed. One quirk with C++ maps is that C++ will return 0 (i.e., NULL) instead of throwing an error if you try to retrieve a value which isn’t in the map. You will only encounter addresses with non-zero virtual page numbers in this lab, so you may want to check for lookups which return zero! . 1-3 Exercise . Complete the setup_PPN_VPN_map function in src/shared.cc to populate the reverse page table. Test your code by running ./launch.sh part1. You should see PPN_VPN test passed! . 1-4 Exercise . Complete the phys_to_virt function in src/shared.cc: given a physical address, determine its corresponding virtual address. You will need to use the reverse page table PPN_VPN_map that you have constructed. Test your code by running ./launch.sh part1. You should see phys_to_virt test passed! . Submission and Grading . Relevant files to submit to GitHub: src/shared.cc . ",
    "url": "/2024/labs/rowhammer.html#part-1-bridging-the-virtual-and-physical-address-spaces-10",
    "relUrl": "/labs/rowhammer.html#part-1-bridging-the-virtual-and-physical-address-spaces-10"
  },"137": {
    "doc": "Rowhammer",
    "title": "Part 2: Observing Bitflips in the Wild (40%)",
    "content": "Good news, you will get a working Rowhammer on a real machine by the end of Part 2 (potentially earlier than you might have expected!). As we mentioned before, to make Rowhammer work, we need to manipulate addresses to go through two translation steps: Virtual Address → Physical Address → DRAM Coordinates. To save your effort in reverse engineering the second translation step, we have pre-profiled the lab machines and located victim and attacker rows, and we directly provide the physical addresses of the startings of these rows to you (see table below, as well as file src/part2/part2.hh). With these information, you can use your reverse page table PPN_VPN_map to find the corresponding virtual addresses. Your task in this part is to implement a double-sided Rowhammer attack and try the attack on these addresses. | Victim | Row Above (A) | Row Below (B) | Distant Row (C) | Same Row ID, Diff. Bank (D) | . | 0x75380000 | 0x753A2000 | 0x7536E000 | 0x75308000 | 0x75382000 | . Attack Outline . You will implement the Rowhammer attack strategy inside the hammer_addresses function (in src/part2/part2.cc). The main function (in part2.cc) contains code to call your hammer_addresses function to perform the attack, collect statistics and report the number of observed bitflips. You should not modify the main function. Getting Rowhammer to work can be quite tricky. When writing your code in C/C++, you have to think very carefully about what DRAM operations will be triggered by the code and what cells are being accessed with your code. For our specific DRAM configuration, a row is of size 2^13 = 8KB and its physical address is aligned at 8KB. Here is a high-level description of the attack you will implement. | Prime the victim and attacker rows. Set the victim row to all 0’s, and set the attacker rows to all 1’s. | Theoretically, Rowhammer works when we access neighboring rows with a specific pattern and should work regardless of the content inside the attacker and victim rows. However, according to prior work, setting the attacker’s rows to all 1’s and victim’s row to all 0’s can result in a higher probability of triggering bitflips. | When priming rows, ensure that you’re writing the values to the entire row, and not priming outside of row boundaries. If you’re observing bit-flips in your victim row 100% of the time, it is likely that you accidentally wrote 1’s to the victim row when you meant to prime the attacker row. | . | Hammer two rows, repeatedly alternatively accessing two attack rows in DRAM 5 million times. | To access a row, you only need to access one address belonging to that row. Think about how the row buffer works. | Once you access a row, it will be fetched in the cache and later accesses will hit the cache. Thus, you will need to come up with a way to ensure that accesses to these two rows always reach DRAM. | . | Probe the victim row, compare the read results with the primed values (aka, all 0’s), and check whether any bit in the row has been flipped to a 1. | It can be tricky to determine whether a bitflip is observed due to an implementation bug or the actual Rowhammer effect. You should test your code to make sure that without the hammering step (e.g., only priming), the probe observes no bitflips. | . | . Tips for Programming in C/C++ . | Be cautious when you try to set every bit in a row to 1. You need to pay extra attention to the size of the variable. For example, uint8_t x = 1 means x=8'b00000001, consisting of seven 0s and only one 1s. | When you are writing your code, you may need to convert between integers (uint64_t) and pointers (uint8_t *) and vice-versa. You may find C++’s reinterpret_cast useful in performing these conversions: uint64_t addr = 0xDEADBEEF; // A 64bit integer // Cast the 64bit integer to a pointer volatile uint8_t * addr_ptr = reinterpret_cast&lt;volatile uint8_t *&gt;(addr); uint8_t tmp = *addr_ptr; // Read using the casted pointer . | Throughout your code, we suggest always using uint64_t rather than int, since ints can result in silent overflows when shifted by large values. | Be mindful that the order of operations in C++ may not be what you expect. For instance, a &lt;&lt; 12 - 1 is different from (a &lt;&lt; 12) - 1. If in doubt, use parenthesis. | . 2-1 Exercise . Complete the hammer_addresses function in src/part2/part2.cc. The main function in part2.cc will use hammer_addresses to hammer 3 attacker row pairs (i.e., A/B, A/C, and A/D, the address of A, B, C, and D are showned in the table above) 100x, and report how often the attack succeeds (i.e. observes at least one bit flip in the victim row). 2-2 Discussion Question . Include the bitflip observation statistics in the table below. Then answer the following questions: . Do your results match your expectations? Why might some attacker pairings result in more flips than others? Do you expect any of the pairs to never cause a flip? . | Hammering Pairs | A/B | A/C | A/D | . | Number of Successes (100 trials) |   |   |   | . Submission and Grading . Relevant files to submit to GitHub: src/part2/part2.cc. ",
    "url": "/2024/labs/rowhammer.html#part-2-observing-bitflips-in-the-wild-40",
    "relUrl": "/labs/rowhammer.html#part-2-observing-bitflips-in-the-wild-40"
  },"138": {
    "doc": "Rowhammer",
    "title": "Part 3: DRAM Geometry (20%)",
    "content": "Congratulations for making Rowhammer work. However, we slightly cheated in Part 2 since a real hacker does not have access to the information that you had, i.e., the physical addresses of the victim rows and attacker rows. Instead, they need to locate attacker rows via reverse engineering the physical address to DRAM coordinate mapping. You may have noticed from above that adjacent rows might not be a constant stride apart in the physical memory space. For instance, the difference between the victim row and the row above it (A) is 0x22000, while the difference between the victim row and the row below it (B) is 0x12000. So what is happening here? . This added complexity is introduced due to the geometry of the DRAM. Consider a DRAM coordinate of a bit cell is a tuple of &lt;DIMM id, Channel id, Rank id, Bank id, Row id, Column id&gt; (see details in the lecture slides). Recall that for two rows to be physically adjacent to one another in a DRAM chip, they must have the same &lt;DIMM id, Channel id, Rank id, Bank id&gt;, and their &lt;Row id&gt; should differ by 1. In most DRAMs, each of the &lt;DIMM id, Channel id, Rank id, Bank id&gt; is derived by XORing a selection of bits from the physical address. These XOR functions, i.e., which bits are used to perform the XOR operation, are proprietary information and are not typically provided by CPU vendors. In our lab machines, the &lt;DIMM id, Channel id, Rank id&gt; are determined by higher bits and the addresses in a 4GB region share the same of these ids. Our lab machines have 16 banks, making the &lt;Bank id&gt; a 4-bit value. Each bit in these 4 bits is computed by XORing some of the bits 13-16 with some of the bits 17-20. The bits involved in the derivation of the &lt;Row id&gt; and &lt;Bank id&gt; are listed below and also visualized in the figure. | &lt;Row id&gt;: bits 17-31 | &lt;Column id&gt;: bits 0-12 | &lt;Bank id&gt;: (unknown) each bit comes from XORing some of bits 13-16 (the exact number of bits being XORed can range from 0 to 4) with some of bits 17-20 | . Physical address bits involved in Row/Bank ID generation . 3-1 Discussion Question . Given a victim address 0x752C3000, what is the value of its &lt;Row id&gt;? The value of its &lt;Column id&gt;? . For this same victim address, when the exact XOR function being used for computing the &lt;Bank id&gt; is unknown, list all possible attacker addresses that stays in the row below the victim address (i.e., the attacker’s &lt;Row id&gt; is 1 more than the victim’s) while sharing the same &lt;Column id&gt; and &lt;Bank id&gt;. Hint: there should be 16 such addresses total. Bank-conflict Side Channel . How can we determine whether two addresses map to the same bank or not without knowing the proprietary XOR function? The answer is to use our favorite tool in 6.5950: timing side channels! . As discussed in the lecture, a DRAM bank can only serve one memory request at a time, but multiple accesses to different banks can be served simultaneously, allowing for bank-level parallelism. So, if you issue two memory requests to the same bank back-to-back, one of the requests needs to wait for the other to complete before being served, resulting in longer latency. In contrast, if the two memory requests target two different banks, they can be served in parallel, resulting in a shorter latency. As such, we can use the timing of these accesses to determine whether or not they reside in the same bank. 3-2 Discussion Question . Write a short code snippet (psuedocode) to implement a program that takes two addresses addr_A and addr_B as input and outputs a boolean value to indicate whether they map to the same bank or not. The style of your psuedocode can either be C-style, or can follow the single-sided Rowhammer assembly code example from the lecture slides: . loop: mov (A), %eax mov (A_dummy), %ecx clflush (A) clflush (A_dummy) mfence jmp loop . The XOR function can also be reverse-engineered via other types of timing side channels. If curious, you can read DRAMA to see how this can be done. The XOR Function . It is a bonus if you can implement the bank-conflict side channel and reverse engineer the XOR function. For now, we just give you the XOR function and ask you to answer a discussion question based on it. Bank ID XOR Formula for our lab Machines . 3-3 Discussion Question . Based on the XOR function described above, determine which of the 16 candidate addresses you derived in Discussion Question 3-1 maps to the same bank. Bonus: Implementing the Bank-conflict Side Channel (5%) . 3-4 Exercise (Bonus) . In src/part3/part3.cc implement measure_bank_latency, which measures a (potential) bank collision between two addresses. The staff-provided main function in part3.cc will call your measure_bank_latency with two different address pairs. The first address pair will map to the same bank, and the second address pair will map to different banks. 3-5 Discussion Question (Bonus) . Report the statistics produced by your code when running part3, and describe how you can use the difference in these statistics to distinguish between the pairs. Submission and Grading . Submitting src/part3/part3.cc is only required if you complete the bonus component. ",
    "url": "/2024/labs/rowhammer.html#part-3-dram-geometry-20",
    "relUrl": "/labs/rowhammer.html#part-3-dram-geometry-20"
  },"139": {
    "doc": "Rowhammer",
    "title": "Part 4: Mitigation using Error Correcting Codes (30%)",
    "content": "Now that we’ve learned how to cause bit-flips in the wild, let’s now explore a potential defense to Rowhammer: Error Correcting Codes (ECC). Error correcting codes, as the name suggested, can help correct errors. More precisely, they are encoding schemes that add redundancy to stored data and use the redundancy to detect and correct errors when they occur. There exist variety of ECCs with different capabilities and storage overhead. For this part, you do not need to use condor. You can run your code on the CSG server or simply on your own machine by directly running ./bin/part4. Understanding ECC: Types and Design Choices . We study the three most commonly seen ECCs. | Repetition Codes: The simplest code is the repetition code, which duplicates each bit in the data multiple times. | Examples: a 2-repetition code protecting the value 1011 is stored as 1011 1011, and a 3-repetition code would be stored as 1011 1011 1011. | Error detection: straightforward. | . | Single Parity Bit: If we’re concerned about storage overhead, we can detect errors by calculating the parity of the data by XORing the data bits together. | Examples: the parity bit for 1011 is 1, and the parity bit for 1001 is 0. | Error detection: A single bit flip in the data results in the parity bit changing. To detect bit flips, we can re-calculate the corrupted data’s parity and compare it against the previously calculated parity bit stored with the data. If more than one bit flips, this scheme may or may not detect it. | . | Hamming Codes: Hamming codes use multiple parity bits to deal with bit errors. Given a scheme protecting N bits with K parity bits, we call it Hamming(N+K, N). | Examples: The most common Hamming code is Hamming(7,4), i.e., 4 data bits protected by 3 parity bits. A graphical depiction of the parity encoding (p1 to p3) for the 4 data bits (d1 to d4) is shown below. As indicated by the green circle, the first parity bit p1 considers the parity of data bits 1, 2, and 4, and is calculated by XORing d1,2,4 together. Similarly, the purple circle indicates that the second parity bit p2 is calculated by XORing d1,3,4. You can infer how the last parity bit p2 is calculated from the red circle. | Error detection: Within each circle, we can perform the same parity check as in the “Single Parity Bit” scheme. By using parity bits in such an overlapping fashion, the Hamming(7,4) code can detect one or two bit flips (even though it cannot tell exactly how many bits flip). By assuming only one bit flips, it can further correct it. | . Hamming(7,4) Code Example (Source) . | . 4-1 Discussion Question . Given the ECC type descriptions listed above, fill in the following table (assuming a data length of 4). For detection/correction, answer “X” only if it can always detect/correct X number of erorrs, with no corner case exceptions. For detecting more than 1 error, the scheme is not required to tell exactly how many errors exist. We’ve filled in the first column for you. |   | 1-Repetition (No ECC) | 2-Repetition | 3-Repetition | Single Parity Bit | Hamming(7,4) | . | Code Rate (Data Bits / Total Bits) | 1.0 |   |   |   |   | . | Max Number of Errors Can Detect | 1 |   |   |   |   | . | Max Number of Errors Can Correct | 0 |   |   |   |   | . Implementing ECC: Hamming(22,16) . Let’s try to implement a Hamming coded ECC that is used in real hardware for protecting DRAMs. These ECCs are introduced primarily to defend against soft errors. Hamming(22,16) can correct single errors and detect double errors (SECDED). It uses six parity bits (P0-P5) to protect sixteen data bits (D0-D15). The equations for the first five parity bits (P0-P4) are shown below (and also described on Page 2 of this hardware documentation). P0 = D15 ⊕ D13 ⊕ D11 ⊕ D10 ⊕ D8 ⊕ D6 ⊕ D4 ⊕ D3 ⊕ D1 ⊕ D0 P1 = D13 ⊕ D12 ⊕ D10 ⊕ D9 ⊕ D6 ⊕ D5 ⊕ D3 ⊕ D2 ⊕ D0 P2 = D15 ⊕ D14 ⊕ D10 ⊕ D9 ⊕ D8 ⊕ D7 ⊕ D3 ⊕ D2 ⊕ D1 P3 = D10 ⊕ D9 ⊕ D8 ⊕ D7 ⊕ D6 ⊕ D5 ⊕ D4 P4 = D15 ⊕ D14 ⊕ D13 ⊕ D12 ⊕ D11 . The last parity bit, P5, protects both the data and the other parity bits, and is computed by XOR-ing all of the data bits (D0-D15) and the other parity bits (P0-P4). We refer to P5 as the overall parity bit. To start, implement the parity encoding operation in src/part4/part4.cc. For your convenience, we’ve provided the following helper types/functions in src/part4/part4.hh: . | struct hamming_struct: A C++ struct which contains a data and parity pair. The bit 0 (i.e., lowest bit) of data is D0, the bit 1 of data is D1, … The bit 0 of parity is P0, the bit 1 of parity is P1, … | struct hamming_result: Stores an error type (one of NO_ERROR/SINGLE_ERROR/DOUBLE_ERROR/PARITY_ERROR) and computed syndrome (explained later). | getBit(data, pos): Returns the value of the bit at position pos within data. | flipBit(data, pos): Flips the bit at position pos within data. | isParityBit(bitNum): Returns whether bitNum corresponds to a parity bit in the Hamming(22,16) encoding. | extractEncoding(encoded): Takes a 22-bit encoded ECC value, and extracts the parity and data bits (returned in a hamming_struct). | embedEncoding(hamming_struct): Takes in a hamming_struct and returns the combined ECC value. | parity_eqs array in part4.cc: Describes the parity equations in an array representation. | . 4-2 Exercise . Complete genParity() to calculate the parity bits (P0-P5) for an input piece of data that needs protection. You should see a message telling you that your parity value is correct when you run ./bin/part4 (make sure to compile your implementation using make!). Now, let’s consider how error detection and error correction are performed in Hamming(22,16). Given a single-bit error, Hamming(22,16) can detect whether the error has happened and locate the bit that has been flipped. Basically, taking a piece of 22-bit value with Hamming(22,16) protection, we can compute something called a syndrome. The encoding scheme is designed so that the syndrome corresponds to the location of the single error. The syndrome is computed by XORing two 5-bit values. The first is the “extracted parity bits” P0-P4 stored in the 22-bit value. The second is the “reconstructed parity bits” P0-P4 from the data bits D0-D15. In addition, an overall parity bit is computed by XORing all 22 bits together. Based on the syndrome and overall parity bit, Hamming(22,16) can detect and correct bit flips in both the data bits and the parity bits. See the table below for detailed information. | Syndrome | Overall Parity | Error Type | Notes | . | 0 | 0 | No Error |   | . | !=0 | 1 | Single Error | Correctable. Syndrome holdes incorrect bit position. | . | !=0 | 0 | Double Error | Uncorrectable. | . | 0 | 1 | P5 Error | P5 is in error and can be corrected. | . 4-3 Discussion Question . When a single bit flip is detected, describe what action should be conducted to correct this error with Hamming(22,16). With all the information above, let’s complete the function findHammingErrors() which takes in an encoded ECC value and determines whether there is an error. This function should return the error type and the syndrome. Finally, complete the function verifyAndRepair() which uses the information gained from findHammingErrors() to determine a good course of action. If there is no error, or an unrecoverable error, verifyAndRepair() should return the original value. If there is a single bit error (including parity errors), verifyAndRepair() returns the data with the error corrected. 4-4 Exercise . Complete findHammingErrors() and verifyAndRepair(). You should see All tests passed! reported. 4-5 Discussion Question . Can the Hamming(22,16) code we implemented always protect us from rowhammer attacks? If not, describe how a clever attacker could work around this scheme. Submission and Grading . Your src/part4/part4.cc will be graded automatically, checked against 5 random inputs. As always, submit your discussion questions as a PDF to gradescope. ",
    "url": "/2024/labs/rowhammer.html#part-4-mitigation-using-error-correcting-codes-30",
    "relUrl": "/labs/rowhammer.html#part-4-mitigation-using-error-correcting-codes-30"
  },"140": {
    "doc": "Rowhammer",
    "title": "Behind the Scene: How this lab infrastructure was developed?",
    "content": "As you have seen in Part 1, using the virtual to physical addresses mapping information provided by Linux’s pagemap interface is a critial step to make the rowhammer attack work. Without a surprise, this interface has been banned from non-sudo users since Linux 4.0 (released in 2015), as a quick countermeasure against rowahmmer attacks. However, throughout the lab, you are never granted sudo permission on the machine. Then how did you smoothly access this interface during the lab? . This comes from our special setups on the machines: A special kernel module is installed to bypass this permission check. The source code of it can be found in driver folder of the starter code of the lab. And we would be happy to give you a tour on how it is developed – how we navigate through the linux source code, identify the location of the permission check of pagemap interface, and hijack the checking result. Per documentation, one requires CAP_SYS_ADMIN capabilities on Linux to access /proc/self/pagemap. We found this permission check located at Line 1624 of fs/proc/task_mmu.c file in Linux v5.15.97 source code (code here). The code does the permission check using file_ns_capable function and saves the checking result in the show_pfn field of the pm variable (whose type is struct pagemapread). How to force this check to always return true? We could change the Linux source code and recompile it, but we do not want to – It is too muddy to config our lab machines with a Linux kernel fully compiled by ourselves. Instead, we developed the rh_driver kernel module to solve this problem, which can be installed to or uninstalled from Linux easily, while the machine is on. It uses a Linux feature known as kprobes, which allows one to “dynamically break into any kernel routine and collect debugging and performance information non-disruptively”. If we break at when the file_ns_capable function returns, we can change the return value to bypass the permission check. We use two kprobes to achieve this: . | The first kprobe (file_ns_capable_pre function in driver/rh_driver.c) determines whether file_ns_capable function is called for the permission check specifically for our pagemap interface (i.e., is called from Line 1624 of fs/proc/task_mmu.c). It checks whether the return address on the stack is within a threshold range to pagemap_read function and whether the second and third arguments match the code from source. We think this heuristic is good enough. If this check pass, we insert the second kprobe. | The second kprobe (target_post function in driver/rh_driver.c) modifies the return of file_ns_capable function to be true. | . Finally, now you can access /proc/self/pagemap without any additional privileges – exciting for us as course staff, though perhaps less exciting for a student in computer security class. ",
    "url": "/2024/labs/rowhammer.html#behind-the-scene-how-this-lab-infrastructure-was-developed",
    "relUrl": "/labs/rowhammer.html#behind-the-scene-how-this-lab-infrastructure-was-developed"
  },"141": {
    "doc": "Rowhammer",
    "title": "Acknowledgements",
    "content": "Contributors: Peter Deutsch, Miguel Gomez-Garcia, Mengjia Yan, William Liu. ",
    "url": "/2024/labs/rowhammer.html#acknowledgements",
    "relUrl": "/labs/rowhammer.html#acknowledgements"
  },"142": {
    "doc": "Rowhammer",
    "title": "Rowhammer",
    "content": " ",
    "url": "/2024/labs/rowhammer.html",
    "relUrl": "/labs/rowhammer.html"
  },"143": {
    "doc": "Spectre Attacks",
    "title": "Spectre Attacks Lab",
    "content": "Due Date: Mar 21; Last Updated Date: Feb 14 . ",
    "url": "/2024/labs/spectre.html#spectre-attacks-lab",
    "relUrl": "/labs/spectre.html#spectre-attacks-lab"
  },"144": {
    "doc": "Spectre Attacks",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 0: Lab Infrastructure | Part 1: Leaking Kernel Memory via Flush+Reload (35%) | Part 2: Basic Spectre (40%) | Part 3: Advanced Spectre (25%) | Behind the Scene: How this lab infrastructure was developed? | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . Log into your assigned machine. Your credentials and machine information have been emailed to you. It will be one of the arch-sec-[1-4].csail.mit.edu machines. To connect via ssh, run ssh username@arch-sec-X.csail.mit.edu. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2024/labs/spectre.html#table-of-contents",
    "relUrl": "/labs/spectre.html#table-of-contents"
  },"145": {
    "doc": "Spectre Attacks",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Understand how Spectre works across privilege boundaries. | Solve three CTF (capture-the-flag) puzzles with increasing difficulty levels. You will start with implementing the basic Spectre attack. We will then test your understanding of how hardware works by challenging you to implement an advanced Spectre in the last part of this lab. | . ",
    "url": "/2024/labs/spectre.html#introduction",
    "relUrl": "/labs/spectre.html#introduction"
  },"146": {
    "doc": "Spectre Attacks",
    "title": "Part 0: Lab Infrastructure",
    "content": "Interacting with Linux Kernel . The highlight of this lab is that you will implement your own version of the famous Spectre attack and use it to leak secrets from the Linux kernel, across privilege boundaries. It presents a good opportunity for you to understand the existing technique used to isolate kernelspace from userspace. Our virtual address space is divided into the kernelspace and the userspace. Unprivileged application code resides in the userspace as shown in the figure below. There are several restrictions on the userspace code. The userspace code cannot directly access kernelspace data or directly branch into the kernelspace and execute kernel code. For example, the load 0xABCD (a kernelspace virtual address) operation will trigger a page permission check failure, or segmentation fault as reported when running a C program. Similarly, executing the instruction jump 0x1234 will also panic with a segmentation fault. So how can the userspace code interact with the kernelspace and still ensure privilege isolation? The right way is to use kernelspace exposed API interface. When calling a correct kernelspace API, the code jumps to the kernelspace entrypoint (the only place in the kernel allows transition from userspace). The entrypoint code performs tons of work for context switch and then jumps to the requested API function. In our lab infrastructure, we provide a custom Linux kernel module (blue box) sitting in the kernelspace. This kernel module provided a limited interface for userspace code to call into. The module is embedded with vulnerable Spectre gadgets, operates on some secret data (red box), and uses secret data as addresses to access the shared buffer (green box). Read the section at the end of this handout for more details about how the lab infrastructure is designed. Obviously, your code, residing in the userspace, will not be able to directly access the secret buffer in the kernelspace. Fortunately, we know that the kernelspace and userspace code, when they execute, share all the microarchitectural structures. Lab Infrastructure Setup . The Secret . The secret in each part is a string of the form MIT{some_secret_value}. The string can be up to 64 bytes, including the NULL terminator. You can consider the secret complete once you leak the NULL terminator. The characters in the string may NOT be printable ASCII. Your code should be able to leak arbitrary 8-bit secrets byte by byte. Do not make any assumption about the secret other than it is a NULL terminated string of length up to 64 bytes (including the NULL terminator). The secrets will not change from run to run (they are constant for the lifetime of the kernel module). During grading, we may use different secret values to evaluate your implementation. Code Skeleton . | inc/labspectre.h and src-common/spectre_lab_helper.c provide a set of utility functions for you to use. | src-common/main.c is used in all three parts. The main function sets up a shared memory region (shared_memory corresponding to the green box in the figure above) of size SHD_SPECTRE_LAB_SHARED_MEMORY_SIZE bytes, which is shared between the userspace and kernel. It also sets up a file descriptor for communicating with the kernel module. The technique behind this communication is called procfs write handling, detailed in the section at the end of this handout. | inc/labspectreipc.h contains bindings for the interface to the kernel module from userspace. You do not need to understand this, as our provided code handles the communication with the kernel. | part1-src/attacker-part1.c is the file you will modify in Part 1. The method call_kernel_part1 can be used for calling into the kernel module. The code for Part2 and Part 3 follow the exact same pattern. | . Compile, Test, and Autograde . This lab will be autograded. After you hand in your code, we will embed different secret strings in the kernel and rerun your code to see whether it effectively leaks these strings. If your code works reliably with the autograder, you should expect no surprise with your grades. Instructions for compiling the code and running the autograder are below. From the root directory, use make to compile the project. The binaries part[1-3] will be produced in the same directory (run them by calling ./part[1-3]. The results of your code will be printed to the console – on success you should see the secret leaked from kernel memory printed to the console. An example of the expected output is below: . $ ./part1 MIT{part1_secret_value} . You can invoke the autograder with ./check.py X, where X is the part to check. An example of the expected output is below: . $ ./check.py 1 Checking part 1 ... You passed 950 of 1000 runs (95.0%) Success! Good job . You can check all parts at once with make and then ./check.py all . ",
    "url": "/2024/labs/spectre.html#part-0-lab-infrastructure",
    "relUrl": "/labs/spectre.html#part-0-lab-infrastructure"
  },"147": {
    "doc": "Spectre Attacks",
    "title": "Part 1: Leaking Kernel Memory via Flush+Reload (35%)",
    "content": "In this part you will set up a cache-based side channel to leak information from the kernel using Flush+Reload. Get to Know the Victim . The pseudocode for the kernel victim code of Part 1 is shown below. def victim_part1(shared_mem, offset): secret_data = part1_secret[offset] load shared_mem[4096 * secret_data] . The victim function takes a pointer shared_mem and an integer offset as input. Both variables are passed from the userspace and determined by the attacker, e.g., you. The variable shared_mem points to the starting of the shared memory region, the green box in the figure above. First, the code loads a secret byte from a secret array named part1_secret, located inside kernelspace. The byte to leak is chosen by the attacker-controlled offset. When the offset is 0, the first secret byte will be loaded; when offset is 1, the second byte will be loaded, and so on. Next, the victim multiplies the secret byte with 4096 and uses the result as an index into the shared memory array. For example, if the secret data was the character ‘A’ (0x41), then the first cache line of the 0x41’th page in the shared memory region will be loaded into the cache. Your Attack Plan . Recall that the secret is a string up to 64 characters long (including the NULL terminator). The attacker can leak the secret one byte at a time using Flush+Reload. Reuse your attack strategy from the Part 2 in the cache lab here, with the only difference at step 1, that is, the attacker needs to call the victim code to perform the secret-dependent memory access. Without losing generality, we summarize the attack outline for you below. | Flush the memory region from the cache using clflush. | Call the victim method using the desired offset to leak the secret byte. | Reload the memory region, measure the latency of accessing each address, and use the latency to derive the value of the secret. When the value is 0x00 (i.e. NULL), the attack is complete. | . 1-1 Discussion Question . Given the attack plan above, how many addresses need to be flushed in the first step? . Allowed Code . You can define your own helper methods as you desire. You can use any method in inc/labspectre.h as well as the provided methods in part1-src/attacker-part1.c. You should only use the provided call_kernel_part1 method to interact with the kernel module. This function takes three arguments: a file descriptor to the kernel module, a pointer to the shared memory region, and an offset. kernel_fd and shared_memory can be directly passed to this method without modification. The offset for a given invocation is up to you. Build your attack step-by-step: start by leaking one character first, then try to leak the whole string. 1-2 Exercise . Implement the Flush+Reload attack in part1-src/attacker-part1.c to leak the secret string. Build the project with make and run ./part1 from the main directory to see if you get the secret. Run ./check.py 1 from the main directory to repeat the experiment multiple (5 by defualt) times. Submission and Grading . Submit your code part1-src/attacker-part1.c to your assigned Github repo. Full credit will be awarded to solutions that report the correct secret at least 80% of the time, while partial credit will be awarded for solutions which perform worse than that. Each attempt (i.e., each run of ./part1) should take no longer than 30 seconds. ",
    "url": "/2024/labs/spectre.html#part-1-leaking-kernel-memory-via-flushreload-35",
    "relUrl": "/labs/spectre.html#part-1-leaking-kernel-memory-via-flushreload-35"
  },"148": {
    "doc": "Spectre Attacks",
    "title": "Part 2: Basic Spectre (40%)",
    "content": "Now that Flush+Reload is working, let’s move on to actually implementing a Spectre attack! . Get to Know the Victim . Below is the pseudocode for Part 2’s victim code. This victim is quite similar to Part 1, except it will only perform the load if the offset is within a specific range (e.g., offset&lt;4). part2_limit = 4 def victim_part2 (shared_mem, offset): secret_data = part2_secret[offset] mem_index = 4096 * secret_data # to delay the subsequent branch flush(part2_limit) if offset &lt; part2_limit: load shared_mem[mem_index] . 2-1 Discussion Question . Copy your code in run_attacker from attacker-part1.c to attacker-part2.c. Does your Flush+Reload attack from Part 1 still work? Why or why not? . Attack Outline . Below are the steps required to leak a single byte. You may need to alter your approach to account for system noise. | Train the branch predictor to speculatively perform the load operation (i.e., take the branch). | Flush the shared memory region from the cache using clflush. | Call the victim function with an offset beyond the limit, leaking the secret byte during speculative execution. | Reload the memory region, measure the latency of accessing each address, and use the latency to determine the value of the secret. | . As you’ve observed in previous labs, side channel attacks generally do not work on the first attempt. You should try to use the good practices you have learned from the cache lab when attempting for any microarchitectural attacks. For example, . | DO NOT measure while printing. | To improve attack precision, you can repeat measurements multiple times and use statistical methods to decode secret. | Try to avoid using systemcall-related functions during attack. Both the printf and sleep functions trigger enough noise to seriously destruct your cache state and your branch predictor state. | . In addition, here is one more hint specific to the branch predictor. Modern processors employ branch predictors with significant complexity. Branch predictors can use global prediction histories, which allow different branches to interfere each other. Besides, the branch predictor is shared between userspace and kernel space. If the speculation is not working as expected, you may need to reduce the number of branches in your attack code. 2-2 Exercise . Implement the Spectre attack in attacker-part2.c to leak the secret string. Build the project with make and run ./part2 to see if you get the secret. Run ./check.py 2 to repeat the experiment multiple (5 by defualt) times. 2-3 Discussion Question . In our example, the attacker tries to leak the values in the array secret_part2. In a real-world attack, attackers can use Spectre to leak data located in an arbitrary address in the victim’s space. Explain how an attacker can achieve such leakage. 2-4 Discussion Question . Experiment with how often you train the branch predictor. What is the minimum number of times you need to train the branch (i.e. if offset &lt; part2_limit) to make the attack work? . Submission and Grading . This part is graded in the same way as Part 1. Full credit will be awarded to solutions that report the correct secret at least 80% of the time, while partial credit will be awarded for solutions which perform worse than that. Each attempt (i.e., each run of ./part2) should take no longer than 30 seconds. ",
    "url": "/2024/labs/spectre.html#part-2-basic-spectre-40",
    "relUrl": "/labs/spectre.html#part-2-basic-spectre-40"
  },"149": {
    "doc": "Spectre Attacks",
    "title": "Part 3: Advanced Spectre (25%)",
    "content": "Now that we’ve got our Spectre attack working, let’s try a harder version of the same problem. Get to Know the Victim . Below is the pseudocode for Part 3: . part3_limit = 4 def victim_part3 (shared_mem, offset): if offset &lt; part3_limit: false_dependency = lengthy computation # the computation result is 0 secret_data = part3_secret[offset] mem_index = 4096 * secret_data load shared_mem[mem_index + false_dependency] . There are two key differences in the victim code compared to Part 2. First, the victim no longer flushes the limit variable (partX_limit) before the branch. Second, we have added a false dependency before the memory access, making the memory access start later in the speculation window. If you copy run_attacker from Part 2, you should see that your attack does not work with the new victim. This is because in the modified victim code, the memory access instruction we try to monitor may not be issued speculatively for three reasons: . | The speculation window becomes shorter. The speculation window starts at the cycle the branch (if offset &lt; part3_limit) enters the processor, and ends at the cycle when the branch condition is resolved. If the part3_limit variable is cached, it will take a very short time to obtain its value, detect it is a branch misprediction, and squash the instructions after this branch. As a result, the speculative window becomes shorter. | The issue time of the secret-dependent memory access is delayed. Due to the data dependency between the false_dependency line and the load shared_mem line, the secret-dependent memory access can only be issued after the variable false_dependency is computed. It is possible that the branch condition is resolved before the speculative load even executes. | There is a hidden source of timing delay due to TLB misses. Feel free to refer to the section at the end of this handout for more information. You do not need to understand this factor for making your attack work. | . To make your attack work, you will need to find a way to increase the speculation window such that the speculative load has a higher chance of occuring. Note that you cannot change the long latency memory address dependency. Similar as before, use the good practices for microarchitectural attacks: do not use systemcall-related functions during attack, such as printf and sleep. Note . If your implementation from Part 2 can pass the test for Part 3, congratulations and please reach out to us! We have designed this part to make basic Spectre attack implementations work ineffectively, and we’d be curious to learn how you made it work in one shot. 3-1 Exercise . Optimize the attack in attacker-part3.c to leak the secret string. Build the project with make and run ./part3 to see if you get the secret. Run ./check.py 3 to repeat the experiment multiple (5 by defualt) times. 3-2 Discussion Question . Describe the strategy you employed to extend the speculation window of the target branch in the victim. 3-3 Discussion Question . Assume you are an attacker looking to exploit a new machine that has the same kernel module installed as the one we attacked in this part. What information would you need to know about this new machine to port your attack? Could it be possible to determine this information experimentally? Briefly describe in 5 sentences or less. Submission and Grading . Full credit will be awarded to solutions that report the correct secret at least 20% of the time, while partial credit will be awarded for solutions which perform worse than that. Each attempt (i.e., each run of ./part3) should take no longer than 10 minutes. We will give partial credit if the attack can recover some part of the secret string. You can check all parts at once with make and then ./check.py all . As always, do not forget to include answers to the discussion questions in your lab report and submit the report to gradescope. ",
    "url": "/2024/labs/spectre.html#part-3-advanced-spectre-25",
    "relUrl": "/labs/spectre.html#part-3-advanced-spectre-25"
  },"150": {
    "doc": "Spectre Attacks",
    "title": "Behind the Scene: How this lab infrastructure was developed?",
    "content": "For those who are curious, here is a brief description of how this lab infrastructure was developped. The victims you are interacting with are part of a custom kernel module. You can find the source code of this kernel module in module-src/labspectrekm.c. The communication between the userspace and the kernel module is handled using a technique called procfs write handling. Specifically, whenever the userspace code writes to a file (i.e., /proc/labspectre-victim), a procfs write handler (i.e., spectre_lab_victim_write function in module-src/labspectrekm.c) in the kernel module will start to execute, using the written data (i.e., the local_cmd variable in call_kernel_partX functions) as the userbuf arguments. On the lab machine, SMAP (supervisor mode access prevention) and SMEP (supervisor mode execution prevention) are both on, which means that the kernel cannot directly read or execute userspace memory. You may wonder, in this case, how the kernel can read the shared_mem array, which is located in userspace. This is done by temporarily remapping an alias of the shared memory region into the kernel space. What we end up with is two different virtual addresses, one in the userspace and one the kernel space, both mapping to the same physical address. This is similar to what we have seen in Part 2 of the cache lab, where two virtual addresses in two processes are mapped to the same physical address. The interaction between the kernel module and the userspace code involves context switches. When the userspace code calls the kernel module (via the write syscall), the processor transitions from the userspace to the kernelspace, which will flush some microarchitecture structures, such as TLBs. The custom kernel module will then create an alias mapping for the shared memory region and execute the requested function. Before returning to the userspace, it will unmap the shared region. Therefore, every time the kernel module is called, the first accesses to each page will incur TLB misses. In Parts 2, we deliberately prevent TLB misses to make your attack easier by forcing page walks before performing any secret-dependent memory accesses. In Part 3, these redundant accesses are removed. You will need to craft an advanced Spectre attack that can succeed despite the added latency due to TLB misses. So in Part 3, in addition to the false dependency, the TLB misses also contribute to the extra latency. ",
    "url": "/2024/labs/spectre.html#behind-the-scene-how-this-lab-infrastructure-was-developed",
    "relUrl": "/labs/spectre.html#behind-the-scene-how-this-lab-infrastructure-was-developed"
  },"151": {
    "doc": "Spectre Attacks",
    "title": "Acknowledgements",
    "content": "Contributors: Joseph Ravichandran, Mengjia Yan, Peter Deutsch. ",
    "url": "/2024/labs/spectre.html#acknowledgements",
    "relUrl": "/labs/spectre.html#acknowledgements"
  },"152": {
    "doc": "Spectre Attacks",
    "title": "Spectre Attacks",
    "content": " ",
    "url": "/2024/labs/spectre.html",
    "relUrl": "/labs/spectre.html"
  }
}
